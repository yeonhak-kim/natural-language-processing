{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnnwupedFEIV"
      },
      "source": [
        "### Part 0. Google Colab Setup"
      ],
      "id": "JnnwupedFEIV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiFjTT4jFEIW"
      },
      "source": [
        "Welcome to the first full programming project for CS 4650! If you're new to Google Colab we recommend looking at [this](https://colab.research.google.com/notebooks/basic_features_overview.ipynb) intro notebook before getting started with this project. In short, Colab is a Jupyter notebook environment that runs in the cloud, it's recommended for all of the programming projects in this course due to its availability, ease of use, and hardware accessibility. Some features that you may find especially useful are on the left hand side, these being:\n",
        "\n",
        "*   Table of contents: displays the sections of the notebook made using text cells\n",
        "*   Variables: useful for debugging and see current values of variables\n",
        "*   Files: useful or uploading or downloading any files you upload to Colab or write while working on the projects\n",
        "\n",
        "\n",
        "\n",
        "**To begin this project, make a copy of this notebook and save it to your local drive so that you can edit it.**\n",
        "\n",
        "\n",
        "If you want GPU's (which will improve training times), you can always change your instance type to GPU by going to Runtime -> Change runtime type -> Hardware accelerator.\n",
        "\n",
        "If you're new to PyTorch, or simply want a refresher, we recommend you start by looking through these [Introduction to PyTorch](https://cocoxu.github.io/CS4650_spring2022/slides/PyTorch_tutorial.pdf) slides and this interactive [PyTorch Basics notebook](http://bit.ly/pytorchbasics). Additionally, this [Text Sentiment](http://bit.ly/pytorchexample) notebook will provide some insight into working with PyTorch for NLP specific problems. "
      ],
      "id": "SiFjTT4jFEIW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRdPqeMMFEIY"
      },
      "source": [
        "### Part 1. Loading and Preprocessing Data [10 points]\n",
        "The following cell loads the OnionOrNot dataset, and tokenizes each data item"
      ],
      "id": "ZRdPqeMMFEIY"
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/lukefeilberg/onion/master/OnionOrNot.csv > OnionOrNot.csv"
      ],
      "metadata": {
        "id": "YmV_uknBJA-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8391c4-fe96-4aa3-8679-7e07d92ad76a"
      },
      "id": "YmV_uknBJA-o",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1903k  100 1903k    0     0  7405k      0 --:--:-- --:--:-- --:--:-- 7405k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L3DkMDu7FEIZ"
      },
      "outputs": [],
      "source": [
        "# DO NOT MODIFY #\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# this is how we select a GPU if it's avalible on your computer or in the Colab environment.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "L3DkMDu7FEIZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1.1 Preprocessing definitions:\n",
        "The following cell define some methods to clean the dataset. Do not edit it, but feel free to take a look at some of the operations it's doing. \n"
      ],
      "metadata": {
        "id": "0Fulh0MZ8y8b"
      },
      "id": "0Fulh0MZ8y8b"
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT MODIFY THIS BLOCK\n",
        "# example code taken from fast-bert\n",
        "\n",
        "import re\n",
        "import html\n",
        "\n",
        "def spec_add_spaces(t: str) -> str:\n",
        "    \"Add spaces around / and # in `t`. \\n\"\n",
        "    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\n",
        "\n",
        "def rm_useless_spaces(t: str) -> str:\n",
        "    \"Remove multiple spaces in `t`.\"\n",
        "    return re.sub(\" {2,}\", \" \", t)\n",
        "\n",
        "def replace_multi_newline(t: str) -> str:\n",
        "    return re.sub(r\"(\\n(\\s)*){2,}\", \"\\n\", t)\n",
        "\n",
        "def fix_html(x: str) -> str:\n",
        "    \"List of replacements from html strings in `x`.\"\n",
        "    re1 = re.compile(r\"  +\")\n",
        "    x = (\n",
        "        x.replace(\"#39;\", \"'\")\n",
        "        .replace(\"amp;\", \"&\")\n",
        "        .replace(\"#146;\", \"'\")\n",
        "        .replace(\"nbsp;\", \" \")\n",
        "        .replace(\"#36;\", \"$\")\n",
        "        .replace(\"\\\\n\", \"\\n\")\n",
        "        .replace(\"quot;\", \"'\")\n",
        "        .replace(\"<br />\", \"\\n\")\n",
        "        .replace('\\\\\"', '\"')\n",
        "        .replace(\" @.@ \", \".\")\n",
        "        .replace(\" @-@ \", \"-\")\n",
        "        .replace(\" @,@ \", \",\")\n",
        "        .replace(\"\\\\\", \" \\\\ \")\n",
        "    )\n",
        "    return re1.sub(\" \", html.unescape(x))\n",
        "\n",
        "def clean_text(input_text):\n",
        "    text = fix_html(input_text)\n",
        "    text = replace_multi_newline(text)\n",
        "    text = spec_add_spaces(text)\n",
        "    text = rm_useless_spaces(text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ctNnE1Ui8oKw"
      },
      "id": "ctNnE1Ui8oKw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1.2 Clean the data using the methods above and tokenize it using NLTK"
      ],
      "metadata": {
        "id": "MiUlTSBB9Wx6"
      },
      "id": "MiUlTSBB9Wx6"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vqtdrhF8FEIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73880bbd-179e-4424-a096-06eb101806c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('punkt')\n",
        "# read data from the csv file\n",
        "df              = pd.read_csv(\"OnionOrNot.csv\")\n",
        "# tokenizing text data -> nltk.word_tokenize() deals with tokening and clean_text prunes the string data\n",
        "df[\"tokenized\"] = df[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))\n"
      ],
      "id": "vqtdrhF8FEIZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBBdVOYxFEIa"
      },
      "source": [
        "Here's what the dataset looks like. You can index into specific rows with pandas, and try to guess some of these yourself :). If you're unfamiliar with pandas, it's a extremely useful and popular library for data analysis and manipulation. You can find their documentation [here](https://pandas.pydata.org/docs/). \n",
        "\n",
        "Pandas primary data structure is a DataFrame. The following cell will print out the basic information of this structure, including the labeled axes (both columns and rows) as well as show you what the first n (default=5) rows look like"
      ],
      "id": "qBBdVOYxFEIa"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sJjScqV3FEIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "0c60daf5-fb2a-40cd-9d08-61e865d2077d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2000194-464d-4a11-9812-3e98bc9da353\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Entire Facebook Staff Laughs As Man Tightens P...</td>\n",
              "      <td>1</td>\n",
              "      <td>[entire, facebook, staff, laughs, as, man, tig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muslim Woman Denied Soda Can for Fear She Coul...</td>\n",
              "      <td>0</td>\n",
              "      <td>[muslim, woman, denied, soda, can, for, fear, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bold Move: Hulu Has Announced That They’re Gon...</td>\n",
              "      <td>1</td>\n",
              "      <td>[bold, move, :, hulu, has, announced, that, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Despondent Jeff Bezos Realizes He’ll Have To W...</td>\n",
              "      <td>1</td>\n",
              "      <td>[despondent, jeff, bezos, realizes, he, ’, ll,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For men looking for great single women, online...</td>\n",
              "      <td>1</td>\n",
              "      <td>[for, men, looking, for, great, single, women,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2000194-464d-4a11-9812-3e98bc9da353')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2000194-464d-4a11-9812-3e98bc9da353 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2000194-464d-4a11-9812-3e98bc9da353');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  ...                                          tokenized\n",
              "0  Entire Facebook Staff Laughs As Man Tightens P...  ...  [entire, facebook, staff, laughs, as, man, tig...\n",
              "1  Muslim Woman Denied Soda Can for Fear She Coul...  ...  [muslim, woman, denied, soda, can, for, fear, ...\n",
              "2  Bold Move: Hulu Has Announced That They’re Gon...  ...  [bold, move, :, hulu, has, announced, that, th...\n",
              "3  Despondent Jeff Bezos Realizes He’ll Have To W...  ...  [despondent, jeff, bezos, realizes, he, ’, ll,...\n",
              "4  For men looking for great single women, online...  ...  [for, men, looking, for, great, single, women,...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "sJjScqV3FEIb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrames can be indexed using [.iloc\\[ ]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html), this primarily uses interger based indexing and supports a single integer (i.e. 42), a list of integers (i.e. [1, 5, 42]), or even a slice (i.e. 7:42). "
      ],
      "metadata": {
        "id": "D9b4W9z1XhgS"
      },
      "id": "D9b4W9z1XhgS"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ntm8laX6FEIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27b3a3c-f6f5-4d39-e671-bf661e23df3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         Customers continued to wait at drive-thru even...\n",
              "label                                                        0\n",
              "tokenized    [customers, continued, to, wait, at, drive-thr...\n",
              "Name: 42, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.iloc[42]\n",
        "\n"
      ],
      "id": "Ntm8laX6FEIb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1.3 Split the dataset into training, validation, and testing"
      ],
      "metadata": {
        "id": "TQVT6HUA9htQ"
      },
      "id": "TQVT6HUA9htQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDI72x8XFEIc"
      },
      "source": [
        "Now that we've loaded this dataset, we need to split the data into train, validation, and test sets. A good explanation of why we need these different sets can be found in subsection 2.2.5 of [Eisenstein](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf) but at the end it comes down to having a trustworthy and generalized model. The validation set (sometimes called a development or tuning) is used to help choose hyperparameters for our model, whereas the training set is used to fit the learned parameters (weights and biases) to the task. The test set is used to provide a final unbiased evaluation of our trained model, hopefully providing some insight into how it would actually do in production. Each of these sets should be disjoint from the others, to prevent any \"peeking\" that could unfairly influence our understanding of the model's accuracy. \n",
        "\n",
        "In addition to these different sets of data, we also need to create a vocab map for words in our Onion dataset, which will map tokens to numbers. This will be useful later, since torch models can only use tensors of sequences of numbers as inputs. **Go to the following cell, and fill out split_train_val_test and generate_vocab_map.**"
      ],
      "id": "GDI72x8XFEIc"
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "from collections import Counter\n",
        "PADDING_VALUE = 0\n",
        "UNK_VALUE     = 1\n",
        "# END - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "\n",
        "\n",
        "# split_train_val_test\n",
        "# This method takes a dataframe and splits it into train/val/test splits.\n",
        "# It uses the props argument to split the dataset appropriately.\n",
        "#\n",
        "# args:\n",
        "# df - the entire dataset DataFrame \n",
        "# props - proportions for each split. the last value of the props array \n",
        "#         is repetitive, but we've kept it for clarity.\n",
        "#\n",
        "# returns: \n",
        "# train DataFrame, val DataFrame, test DataFrame\n",
        "#\n",
        "def split_train_val_test(df, props=[.8, .1, .1]):\n",
        "    assert round(sum(props), 2) == 1 and len(props) >= 2\n",
        "    train_df, test_df, val_df = None, None, None\n",
        "    \n",
        "    ## YOUR CODE STARTS HERE (~3-5 lines of code) ##\n",
        "    # hint: you can use df.iloc to slice into specific indexes or ranges.\n",
        "    df_size = len(df)\n",
        "    train_bound, val_bound, test_bound = int(props[0]*df_size), int((props[0] + props[1])*df_size), int((props[0] + props[1] + props[2])*df_size)\n",
        "\n",
        "    train_df, val_df, test_df = df.iloc[: train_bound], df.iloc[train_bound : val_bound], df.iloc[val_bound : test_bound]\n",
        "  \n",
        "    \n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    \n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "# generate_vocab_map\n",
        "# This method takes a dataframe and builds a vocabulary to unique number map.\n",
        "# It uses the cutoff argument to remove rare words occuring <= cutoff times. \n",
        "# *NOTE*: \"\" and \"UNK\" are reserved tokens in our vocab that will be useful\n",
        "# later.\n",
        "# \n",
        "# args:\n",
        "# df - the entire dataset DataFrame \n",
        "# cutoff - we exclude words from the vocab that appear less than or\n",
        "#          eq to cutoff\n",
        "#\n",
        "# returns: \n",
        "# vocab - dict[str] = int\n",
        "#         In vocab, each str is a unique token, and each dict[str] is a \n",
        "#         unique integer ID. Only elements that appear > cutoff times appear\n",
        "#         in vocab.\n",
        "#\n",
        "# reversed_vocab - dict[int] = str\n",
        "#                  A reversed version of vocab, which allows us to retrieve \n",
        "#                  words given their unique integer ID. This map will \n",
        "#                  allow us to \"decode\" integer sequences we'll encode using\n",
        "#                  vocab!\n",
        "# \n",
        "def generate_vocab_map(df, cutoff=2):\n",
        "    vocab          = {\"\": PADDING_VALUE, \"UNK\": UNK_VALUE}\n",
        "    reversed_vocab = None\n",
        "    \n",
        "    ## YOUR CODE STARTS HERE (~5-15 lines of code) ##\n",
        "    # hint: start by iterating over df[\"tokenized\"]\n",
        "\n",
        "    # compute how much each word appears in the entire dataset given\n",
        "    df_counter = Counter()\n",
        "    for sample in df[\"tokenized\"]:\n",
        "        df_counter.update(sample)\n",
        "\n",
        "    # build 'vocab' and 'reversed_vocab'\n",
        "    reversed_vocab = {}\n",
        "    \n",
        "    # word_id starts from 2 (\"vocab\" already has 2 elements in it (PADDING_VALUE & UNK_VALUE))\n",
        "    word_id = 2\n",
        "    for word in df_counter:\n",
        "        if (df_counter[word] > cutoff) and (word not in vocab):\n",
        "            vocab[word] = word_id\n",
        "            reversed_vocab[word_id] = word\n",
        "            word_id += 1\n",
        "\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    \n",
        "    return vocab, reversed_vocab"
      ],
      "metadata": {
        "id": "zeo9kX6i9pbH"
      },
      "id": "zeo9kX6i9pbH",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rcmX931OFEId"
      },
      "outputs": [],
      "source": [
        "# With the methods you have implemented above, we can now split the dataset into training, validation, and testing\n",
        "#   sets and generate our dictionaries mapping from word tokens to IDs (and vice versa).\n",
        "# Note: The props list currently being used splits the dataset so that 80% of samples are used to traing, and the \n",
        "#   remaining 20% are evenly split between training and validation. How you split your dataset is itself a major\n",
        "#   choice and something you would need to consider in your own projects. Can you think of why?\n",
        "   \n",
        "df                         = df.sample(frac=1)\n",
        "train_df, val_df, test_df  = split_train_val_test(df, props=[.8, .1, .1])\n",
        "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
      ],
      "id": "rcmX931OFEId"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CAACzA8YFEId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e32dae-f0b6-417a-80fa-92fd337f9604"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.1, 0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# This line of code will help test your implementation, the expected output is the same distribution used in 'props'\n",
        "#   in the above cell. Try out some different values to ensure it works, but for submission ensure you use \n",
        "#   [.8, .1, .1] \n",
        "\n",
        "(len(train_df) / len(df)), (len(val_df) / len(df)), (len(test_df) / len(df))"
      ],
      "id": "CAACzA8YFEId"
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df['label'])\n",
        "print(train_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asPIHbWfNJeP",
        "outputId": "c2d90e0f-80ad-46f6-d9c9-919c17991dff"
      },
      "id": "asPIHbWfNJeP",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3111     0\n",
            "18679    0\n",
            "17472    0\n",
            "21451    0\n",
            "20800    0\n",
            "        ..\n",
            "18074    1\n",
            "13304    0\n",
            "17888    1\n",
            "1806     0\n",
            "3871     0\n",
            "Name: label, Length: 19200, dtype: int64\n",
            "{'': 0, 'UNK': 1, 'scientists': 2, 'say': 3, 'smelling': 4, 'farts': 5, 'might': 6, 'prevent': 7, 'cancer': 8, 'cops': 9, 'charge': 10, 'man': 11, 'with': 12, '“': 13, 'destruction': 14, 'of': 15, 'police': 16, 'property': 17, '”': 18, 'for': 19, 'bleeding': 20, 'on': 21, 'their': 22, 'uniforms': 23, 'after': 24, 'they': 25, 'beat': 26, 'him': 27, 'would': 28, 'kick': 29, '’': 30, 's': 31, 'ass': 32, 'in': 33, 'a': 34, 'fight': 35, ',': 36, 'says': 37, 'george': 38, 'r.': 39, 'martin': 40, 'woman': 41, 'found': 42, 'she': 43, 'was': 44, 'farting': 45, 'through': 46, 'her': 47, 'vagina': 48, 'surgeons': 49, 'wrongly': 50, 'it': 51, 'to': 52, 'colon': 53, 'japanese': 54, 'restaurant': 55, \"'\": 56, 'ban': 57, 'overweight': 58, 'diners': 59, 'report': 60, ':': 61, 'lake': 62, 'school': 63, 'bans': 64, 'student': 65, 'from': 66, 'campus': 67, 'being': 68, 'shot': 69, 'georgia': 70, 'republican': 71, 'party': 72, 'chair': 73, 'straight': 74, 'people': 75, 'will': 76, 'enter': 77, 'gay': 78, 'marriages': 79, 'get': 80, '‘': 81, 'free': 82, 'ride': 83, 'jim': 84, 'harbaugh': 85, 'starts': 86, 'off': 87, 'day': 88, 'early': 89, 'morning': 90, '15-year-old': 91, 'schoolgirl': 92, 'died': 93, 'mistook': 94, '[': 95, 'x-post': 96, 'worldnews': 97, ']': 98, 'prince': 99, 'harry': 100, 'gets': 101, 'old': 102, 'suit': 103, 'wear': 104, 'wedding': 105, 'husband': 106, 'dead': 107, 'wife': 108, 'searched': 109, \"'how\": 110, 'kill': 111, 'someone': 112, 'and': 113, 'not': 114, 'caught': 115, 'lawyer': 116, 'who': 117, 'defends': 118, 'corporations': 119, 'accused': 120, 'creating': 121, 'toxic': 122, 'pollution': 123, 'sues': 124, 'neighbor': 125, 'smoking': 126, 'inside': 127, 'his': 128, 'own': 129, 'house': 130, 'broncos': 131, 'nate': 132, 'is': 133, 'spending': 134, 'super': 135, 'bowl': 136, 'week': 137, 'playing': 138, 'ben': 139, 'ends': 140, 'bbc': 141, 'interview': 142, 'scolds': 143, 'host': 144, \"'i\": 145, \"'m\": 146, 'popular': 147, 'no': 148, 'one': 149, 'has': 150, 'ever': 151, 'heard': 152, 'you': 153, 'breitbart': 154, 'declares': 155, 'war': 156, 'kellogg': 157, \"'s\": 158, 'cereal': 159, 'brand': 160, 'pulls': 161, 'advertising': 162, 'site': 163, 'australia': 164, 'new': 165, 'youth': 166, 'minister': 167, 'baby': 168, 'boomer': 169, 'cuts': 170, 'foot': 171, 'throws': 172, 'avoid': 173, 'job': 174, 'assignment': 175, 'los': 176, 'angeles': 177, 'sheriffs': 178, 'investigating': 179, 'kidnapping': 180, 'find': 181, 'music': 182, 'video': 183, 'shoot': 184, 'instead': 185, 'tyson': 186, 'foods': 187, 'executives': 188, 'assure': 189, 'critics': 190, 'chickens': 191, 'physically': 192, 'walking': 193, 'even': 194, 'if': 195, 'had': 196, 'room': 197, 'guard': 198, 'game': 199, 'under': 200, 'strict': 201, 'orders': 202, 'repeatedly': 203, 'pace': 204, 'same': 205, 'stretch': 206, 'hallway': 207, 'tourist': 208, 'faces': 209, 'death': 210, 'penalty': 211, 'north': 212, 'korea': 213, 'attempting': 214, 'overthrow': 215, 'government': 216, 'by': 217, 'taking': 218, 'photos': 219, 'homeless': 220, 'children': 221, '.': 222, 'every': 223, 'tweet': 224, 'lie': 225, 'birds': 226, 'aren': 227, 't': 228, 'real': 229, 'campaign': 230, 'spreads': 231, 'message': 232, 'billboard': 233, 'john': 234, 'oliver': 235, 'sued': 236, 'coal': 237, 'ceo': 238, 'over': 239, 'cause': 240, 'mine': 241, 'disaster': 242, 'squirrel': 243, 'spanish': 244, 'footballer': 245, 'banned': 246, '1': 247, 'year': 248, 'slap': 249, 'female': 250, 'referee': 251, 'penis': 252, 'convinces': 253, 'haunted': 254, 'tries': 255, 'rid': 256, 'ghosts': 257, 'removing': 258, 'an': 259, 'indian': 260, 'politician': 261, 'crashes': 262, 'the': 263, 'laptops': 264, 'that': 265, 'he': 266, 'students': 267, 'squad': 268, 'member': 269, 'canadian': 270, 'citizenship': 271, 'revoked': 272, 'fourth': 273, 'time': 274, 'men': 275, 'can': 276, 'eat': 277, 'wives': 278, 'severely': 279, 'hungry': 280, 'top': 281, 'saudi': 282, 'sheikh': 283, 'fatwa': 284, 'designers': 285, 'think': 286, 'color': 287, 'balls': 288, 'what': 289, 'puts': 290, 'women': 291, 'sports': 292, 'blog': 293, 'this': 294, 'internet': 295, 'article': 296, 'about': 297, 'how': 298, 'arnold': 299, 'hey': 300, '!': 301, 'be': 302, 'there': 303, 'nothing': 304, 'do': 305, 'stop': 306, 'me': 307, 'soccer': 308, 'fan': 309, 'dies': 310, 'reportedly': 311, 'staying': 312, 'awake': 313, '11': 314, 'days': 315, 'watch': 316, 'news': 317, 'historic': 318, 'donald': 319, 'trump': 320, 'just': 321, 'became': 322, 'first': 323, 'president': 324, 'place': 325, 'entire': 326, 'face': 327, 'bible': 328, 'during': 329, 'oath': 330, 'office': 331, 'teen': 332, 'steals': 333, 'bus': 334, 'friend': 335, 'zoo': 336, 'helps': 337, 'constipated': 338, 'monkey': 339, 'pass': 340, 'peanut': 341, 'licking': 342, 'its': 343, 'butt': 344, 'hour': 345, '57': 346, 'percent': 347, 'living': 348, 'ca': 349, \"n't\": 350, 'afford': 351, 'live': 352, 'having': 353, 'sex': 354, 'couch': 355, 'avoids': 356, 'jail': 357, 'but': 358, 'watching': 359, 'porn': 360, 'won': 361, 'when': 362, 'stopped': 363, 'heart': 364, 'tv': 365, 'confront': 366, 'hell': 367, 'sexual': 368, 'harassment': 369, 'allegations': 370, 'another': 371, 'attack': 372, 'grill': 373, 'customer': 374, 'collapses': 375, 'while': 376, 'eating': 377, 'burger': 378, 'gives': 379, 'birth': 380, 'cafe': 381, 'online': 382, 'annual': 383, '9': 384, '/': 385, '10': 386, 'anniversary': 387, 'supporter': 388, 'still': 389, 'planning': 390, 'at': 391, 'national': 392, 'convention': 393, 'anyway': 394, 'kim': 395, 'jong-un': 396, 'panics': 397, 'returning': 398, 'country': 399, 'populace': 400, 'escaped': 401, 'collapse': 402, 'narrowly': 403, 'horn': 404, 'car': 405, 'green': 406, 'light': 407, 'brexit': 408, 'admits': 409, 'set': 410, 'up': 411, 'second': 412, 'eu': 413, 'referendum': 414, 'petition': 415, 'signed': 416, 'three': 417, 'million': 418, 'blackberry': 419, 'owners': 420, 'admit': 421, 'feeling': 422, 'ashamed': 423, 'phone': 424, 'researchers': 425, 'question': 426, 'banning': 427, \"'killer\": 428, 'robots': 429, 'actually': 430, 'killing': 431, 'congressman': 432, 'explains': 433, 'rise': 434, 'rocks': 435, 'falling': 436, 'into': 437, 'sea': 438, 'mississippi': 439, '13th': 440, 'amendment': 441, 'autistic': 442, 'needed': 443, 'quiet': 444, 'work': 445, 'desk': 446, 'put': 447, 'bathroom': 448, 'stall': 449, 'chicago': 450, 'introduces': 451, 'stations': 452, 'boys': 453, 'gather': 454, 'comic': 455, 'books': 456, 'candy': 457, 'bars': 458, 'night': 459, 'hiding': 460, 'special': 461, 'prosecutors': 462, 'rose': 463, 'garden': 464, 'fort': 465, 'us': 466, 'accidentally': 467, 'replies': 468, 'all': 469, 'anonymous': 470, 'bitcoin': 471, 'auction': 472, 'email': 473, 'justin': 474, 'bieber': 475, '$': 476, 'screaming': 477, 'fans': 478, 'onion': 479, 'plays': 480, \"'baby\": 481, 'as': 482, 'fundraiser': 483, 'pay': 484, 'make': 485, 'fifa': 486, 'exhibit': 487, 'open': 488, 'america': 489, 'museum': 490, 'crime': 491, 'goes': 492, 'nearly': 493, 'without': 494, 'fatal': 495, 'shooting': 496, 'facebook': 497, 'ice': 498, 'cream': 499, 'thing': 500, 'life': 501, 'true': 502, 'hero': 503, 'pro': 504, 'bono': 505, 'anyone': 506, 'suing': 507, 'snow': 508, 'globe': 509, 'industry': 510, 'chinese': 511, 'factory': 512, 'worker': 513, 'believe': 514, 'shit': 515, 'makes': 516, 'americans': 517, 'must': 518, 'see': 519, 'radioshack': 520, 'international': 521, 'space': 522, 'station': 523, 'swingers': 524, 'club': 525, 'torture': 526, 'shutdown': 527, 'health': 528, 'safety': 529, 'concerns': 530, 'coolest': 531, 'pope': 532, 'half': 533, 'today': 534, 'francis': 535, 'followed': 536, 'twitter': 537, 'l': 538, 'oreal': 539, 'smart': 540, 'brush': 541, 'hair': 542, 'recommends': 543, 'luxury': 544, 'cincinnati': 545, 'food': 546, 'drinking': 547, 'beer': 548, 'poll': 549, 'needs': 550, 'should': 551, '?': 552, 'claims': 553, 'virgin': 554, 'births': 555, 'u.s.': 556, 'near': 557, 'per': 558, 'cent': 559, 'study': 560, 'official': 561, 'fired': 562, 'smiling': 563, 'too': 564, 'many': 565, 'reality': 566, 'never': 567, 'truly': 568, 'until': 569, 'held': 570, 'newborn': 571, 'son': 572, 'hospital': 573, 'bill': 574, 'bored': 575, 'california': 576, 'sentenced': 577, 'two': 578, 'years': 579, 'laser': 580, 'strike': 581, 'lisa': 582, 'thought': 583, 'senator': 584, 'mean': 585, 'deal': 586, 'bears': 587, 'we': 588, 'restore': 589, 'rule': 590, 'law': 591, 'aides': 592, 'out': 593, 'audience': 594, 'heartbreaking': 595, 'worst': 596, 'person': 597, 'know': 598, 'made': 599, 'great': 600, 'point': 601, 'notre': 602, 'dame': 603, 'turn': 604, 'cathedral': 605, 'roof': 606, 'urban': 607, 'farm': 608, 'incredible': 609, 'career': 610, 'halfway': 611, 'telling': 612, 'search': 613, 'drowned': 614, 'body': 615, 'corpse': 616, 'before': 617, 'teacher': 618, 'realizes': 619, 'isn': 620, 'anybody': 621, 'dad': 622, 'army': 623, 'veteran': 624, 'smashes': 625, 'window': 626, 'hot': 627, 'save': 628, 'dog': 629, 'arrested': 630, \"'re\": 631, 'youtube': 632, 'world': 633, 'leaders': 634, 'attend': 635, 'summit': 636, 'jeb': 637, 'bush': 638, 'hampshire': 639, 'heroin': 640, 'epidemic': 641, 'johnny': 642, 'forced': 643, 'cleveland': 644, 'browns': 645, 'jersey': 646, 'cruel': 647, 'rookie': 648, 'hazing': 649, 'incident': 650, 'does': 651, 'convinced': 652, 'himself': 653, 'loves': 654, 'could': 655, 'buying': 656, 'kids': 657, 'support': 658, 'clinton': 659, 'laugh': 660, 'public': 661, 'turkish': 662, 'deputy': 663, 'pm': 664, 'parents': 665, 'learn': 666, 'adopted': 667, 'daughter': 668, '6': 669, 'adult': 670, 'con': 671, 'artist': 672, '600,000': 673, 'damages': 674, 'barista': 675, 'injured': 676, 'milk': 677, 'fat': 678, 'fly': 679, 'team': 680, 'meetings': 681, 'dark': 682, 'right': 683, 'switch': 684, 'white': 685, 'powerball': 686, 'works': 687, 'raises': 688, 'hurricane': 689, 'florence': 690, 'couple': 691, 'takes': 692, 'pics': 693, 'star': 694, 'wars': 695, 'figure': 696, 'bought': 697, 'dmca': 698, 'notice': 699, 'icon': 700, 'protests': 701, 'nfl': 702, 'thursday': 703, 'football': 704, 'wednesday': 705, 'cdc': 706, 'warns': 707, 'spreading': 708, 'across': 709, 'rate': 710, 'seen': 711, 'since': 712, 'conservative': 713, 'obamacare': 714, 'romantic': 715, 'gesture': 716, 'expensive': 717, 'waste': 718, 'current': 719, 'girlfriend': 720, 'fbi': 721, 'chief': 722, 'policy': 723, 'hiring': 724, 'cyber': 725, 'experts': 726, 'rich': 727, 'californians': 728, 'limits': 729, 're': 730, 'equal': 731, 'comes': 732, 'water': 733, 'black': 734, 'fire': 735, '``': 736, 'kkk': 737, \"''\": 738, 'unsure': 739, 'whether': 740, 'hate': 741, 'absolutely': 742, 'editor': 743, 'listed': 744, 'marriage': 745, '28': 746, 'hoax': 747, 'theresa': 748, 'may': 749, 'crackdown': 750, 'leaks': 751, 'ministers': 752, 'civil': 753, 'leaked': 754, 'reveals': 755, 'player': 756, 'wishes': 757, 'sound': 758, 'horns': 759, 'entered': 760, 'castle': 761, 'gates': 762, 'once': 763, 'sheriff': 764, 'let': 765, 'drive': 766, 'drunk': 767, 'so': 768, 'killed': 769, 'announces': 770, 'orangutan': 771, 'pregnant': 772, '...': 773, 'registered': 774, 'target': 775, 'shower': 776, 'gifts': 777, 'theonion': 778, 'i': 779, 'am': 780, 'mary': 781, 'wait': 782, 'now': 783, 'my': 784, 'id': 785, 'preschool': 786, 'heat': 787, 'field': 788, 'trip': 789, 'gun': 790, 'range': 791, 'high': 792, 'hit': 793, 'massive': 794, 'budget': 795, 'these': 796, 'theater': 797, 'came': 798, 'together': 799, 'each': 800, 'other': 801, 'talk': 802, 'again': 803, 'train': 804, 'engine': 805, 'runs': 806, 'pilot': 807, 'staff': 808, 'chases': 809, 'down': 810, 'motorcycle': 811, 'fcc': 812, 'chairman': 813, 'ajit': 814, 'pai': 815, 'canceled': 816, 'appearance': 817, 'because': 818, 'threats': 819, 'nypd': 820, 'investigator': 821, 'called': 822, 'whistleblower': 823, 'rat': 824, 'lawsuit': 825, 'forget': 826, 'register': 827, 'vote': 828, 'cop': 829, 'slow': 830, 'mcdonald': 831, 'line': 832, 'ahead': 833, 'tokyo': 834, 'fires': 835, 'employee': 836, 'skipped': 837, '24': 838, 'obama': 839, 'republicans': 840, 'trainer': 841, 'squirts': 842, 'bottle': 843, 'kc': 844, 'masterpiece': 845, 'andy': 846, 'mouth': 847, 'lifeguard': 848, 'getting': 849, 'pretty': 850, 'fed': 851, 'kid': 852, 'always': 853, 'hanging': 854, 'lane': 855, 'krispy': 856, 'kreme': 857, 'apologizes': 858, 'doughnut': 859, 'potential': 860, 'shooter': 861, 'father': 862, 'stabs': 863, 'last': 864, 'marvel': 865, '7': 866, 'experiences': 867, 'addict': 868, 'remembers': 869, 'england': 870, 'squid': 871, 'championships': 872, 'farce': 873, 'declared': 874, 'winner': 875, 'fema': 876, 'frantically': 877, 'prepares': 878, 'apology': 879, 'screwing': 880, 'response': 881, 'beyoncé': 882, 'said': 883, 'convicted': 884, 'heavy': 885, 'metal': 886, 'christian': 887, 'singer': 888, 'atheist': 889, 'duped': 890, 'sell': 891, 'oxford': 892, \"'too\": 893, 'bright': 894, 'prison': 895, 'spared': 896, 'stabbing': 897, 'boyfriend': 898, 'heartwarming': 899, 'walk': 900, '20': 901, 'miles': 902, 'couldn': 903, 'drove': 904, 'cheer': 905, 'yorkshire': 906, 'toilet': 907, 'breaks': 908, 'romney': 909, 'kind': 910, 'ordering': 911, 'drone': 912, 'against': 913, 'self': 914, 'presidency': 915, 'assaults': 916, 'invited': 917, 'hang': 918, 'go': 919, 'girl': 920, 'left': 921, 'younger': 922, 'lost': 923, '80': 924, 'pounds': 925, 'them': 926, 'both': 927, 'thousands': 928, 'leaving': 929, 'germany': 930, 'such': 931, 'spaghetti': 932, 'wins': 933, 'diversity': 934, 'win': 935, 'created': 936, 'male': 937, 'superhero': 938, 'thinks': 939, 'bad': 940, 'got': 941, 'powers': 942, 'latina': 943, 'reince': 944, 'priebus': 945, 'hundreds': 946, 'steve': 947, 'bannon': 948, 'immigrants': 949, 'mom': 950, 'shaved': 951, 'head': 952, 'told': 953, 'dying': 954, 'scam': 955, 'champion': 956, 'arts': 957, 'neil': 958, 'diamond': 959, 'donating': 960, 'remaining': 961, 'wikipedia': 962, 'source': 963, 'care': 964, 'info': 965, 'doctors': 966, 'better': 967, 'than': 968, 'yankees': 969, 'pack': 970, 'stadium': 971, 'asshole': 972, 'heritage': 973, 'ideas': 974, 'ruining': 975, 'bullet': 976, 'only': 977, 'way': 978, 'knew': 979, 'unload': 980, 'princess': 981, 'pistol': 982, 'prime': 983, 'suffers': 984, 'hearing': 985, 'loss': 986, 'popeyes': 987, 'chicken': 988, 'evidence': 989, 'christ': 990, 'tomb': 991, 'extra': 992, 'finally': 993, 'rising': 994, 'grave': 995, '6th': 996, 'dui': 997, 'allegedly': 998, 'passing': 999, 'lawn': 1000, 'mower': 1001, 'michael': 1002, 'flynn': 1003, 'resigns': 1004, 'killer': 1005, 'issued': 1006, 'picture': 1007, 'master': 1008, 'key': 1009, 'locks': 1010, 'senate': 1011, 'seek': 1012, 'delay': 1013, 'kavanaugh': 1014, 'accuser': 1015, 'properly': 1016, 'family': 1017, 'rises': 1018, 'visit': 1019, 'home': 1020, 'referred': 1021, 'vacation': 1022, 'asks': 1023, 'sprite': 1024, 'dentist': 1025, 'ex-boyfriend': 1026, 'teeth': 1027, 'split': 1028, 'mafia': 1029, 'officers': 1030, 'disguised': 1031, 'pizza': 1032, 'delivery': 1033, 'italy': 1034, 'stepping': 1035, 'plate': 1036, 'announced': 1037, 'inject': 1038, 'little': 1039, 'league': 1040, 'series': 1041, 'marred': 1042, 'cutest': 1043, 'abuse': 1044, 'pbs': 1045, 'showing': 1046, 'fireworks': 1047, 'footage': 1048, 'july': 1049, '99': 1050, '%': 1051, 'related': 1052, 'cool': 1053, 'neo-nazi': 1054, 'explosives': 1055, 'guns': 1056, 'threat': 1057, 'community': 1058, 'judge': 1059, 'landlord': 1060, 'then': 1061, 'months': 1062, 'rent': 1063, 'giving': 1064, 'rare': 1065, 'coins': 1066, 'uses': 1067, 'change': 1068, 'machines': 1069, 'nightclub': 1070, 'shut': 1071, 'muslim': 1072, 'call': 1073, 'prayer': 1074, 'mexican': 1075, 'jihad': 1076, 'southern': 1077, 'quickly': 1078, 'emerging': 1079, '|': 1080, 'side': 1081, 'adolf': 1082, 'hitler': 1083, 'mein': 1084, 'kampf': 1085, 'sells': 1086, 'german': 1087, 'attorney': 1088, 'general': 1089, 'encryption': 1090, 'creates': 1091, 'security': 1092, 'risk': 1093, 'drama': 1094, 'have': 1095, 'happened': 1096, 'nazis': 1097, 'nba': 1098, 'finals': 1099, 'given': 1100, 'single': 1101, 'yes': 1102, 'any': 1103, 'invitation': 1104, 'received': 1105, 'tunnel': 1106, 'south': 1107, 'headquarters': 1108, 'paul': 1109, 'manafort': 1110, 'custody': 1111, '50': 1112, 'forgot': 1113, '700': 1114, 'bitcoins': 1115, '2014': 1116, 'album': 1117, ';': 1118, 'stake': 1119, 'worth': 1120, 'millions': 1121, 'university': 1122, 'fucking': 1123, 'deliver': 1124, 'tax': 1125, 'evasion': 1126, 'dolphins': 1127, 'deliberately': 1128, 'fish': 1129, 'nerve': 1130, 'carefully': 1131, 'chewing': 1132, 'around': 1133, 'powerful': 1134, 'flame': 1135, 'tied': 1136, 'angry': 1137, 'debuts': 1138, 'original': 1139, 'show': 1140, \"'the\": 1141, 'mother': 1142, '14': 1143, 'finds': 1144, 'inappropriate': 1145, 'owner': 1146, 'chased': 1147, 'classic': 1148, \"'death\": 1149, 'are': 1150, 'words': 1151, 'canadians': 1152, 'debating': 1153, 'best': 1154, 'donuts': 1155, 'tim': 1156, 'hortons': 1157, 'running': 1158, 'feed': 1159, 'pigeons': 1160, 'bid': 1161, 'numbers': 1162, 'store': 1163, 'flag': 1164, 'doesn': 1165, 'represent': 1166, 'racism': 1167, 'ties': 1168, 'employees': 1169, 'happiest': 1170, 'pretending': 1171, 'election': 1172, 'guide': 1173, 'arizona': 1174, 'refuses': 1175, 'serve': 1176, 'legislators': 1177, 'anti-gay': 1178, 'outfitters': 1179, 'selling': 1180, 'state': 1181, 'hoodies': 1182, 'complete': 1183, 'blood': 1184, '9-year-old': 1185, 'mistaken': 1186, 'western': 1187, 'pa': 1188, 'east': 1189, 'tennessee': 1190, 'felony': 1191, 'dipping': 1192, 'testicles': 1193, 'salsa': 1194, 'hollywood': 1195, 'voted': 1196, 'removed': 1197, 'longer': 1198, 'famous': 1199, 'nonprofit': 1200, 'debts': 1201, 'stops': 1202, 'poor': 1203, 'patients': 1204, 'cuban': 1205, 'honors': 1206, 'fidel': 1207, 'castro': 1208, 'firing': 1209, 'imperial': 1210, 'wizard': 1211, 'hates': 1212, 'klan': 1213, 'costumes': 1214, \"'there\": 1215, 'respect': 1216, 'thanks': 1217, 'tide': 1218, 'pod': 1219, 'challenge': 1220, 'warn': 1221, 'traffic': 1222, 'cones': 1223, 'giant': 1224, 'mysterious': 1225, 'poop': 1226, 'causes': 1227, 'explosions': 1228, 'hog': 1229, 'farms': 1230, 'alabama': 1231, 'gop': 1232, 'plans': 1233, 'major': 1234, 'setback': 1235, 'nasa': 1236, 'cancelled': 1237, 'mars': 1238, 'anything': 1239, 'cute': 1240, 'rabbi': 1241, 'guilty': 1242, 'money': 1243, 'laundering': 1244, 'blasting': 1245, 'k-pop': 1246, 'propaganda': 1247, 'along': 1248, 'border': 1249, 'otter': 1250, 'released': 1251, 'back': 1252, 'chain': 1253, 'paris': 1254, 'problem': 1255, 'african': 1256, 'flying': 1257, 'more': 1258, 'fake': 1259, 'license': 1260, 'grieving': 1261, 'widow': 1262, 'die': 1263, 'dakota': 1264, 'access': 1265, 'pipeline': 1266, 'leak': 1267, 'fully': 1268, 'itunes': 1269, 'u2': 1270, 'here': 1271, 'delete': 1272, 'chilean': 1273, 'praises': 1274, 'raped': 1275, 'going': 1276, 'pregnancy': 1277, 'boss': 1278, 'thinking': 1279, 'big': 1280, 'glowing': 1281, 'weak': 1282, 'spot': 1283, 'checked': 1284, 'hipster': 1285, 'possessions': 1286, \"'we\": 1287, 'need': 1288, 'alberta': 1289, 'end': 1290, 'daylight': 1291, 'saving': 1292, 'hold': 1293, 'jared': 1294, 'fogle': 1295, 'scores': 1296, 'cafeteria': 1297, 'serving': 1298, 'sandwiches': 1299, 'florida': 1300, 'using': 1301, 'cup': 1302, 'drink': 1303, 'soda': 1304, 'charged': 1305, 'social': 1306, 'media': 1307, 'applebee': 1308, 'apologized': 1309, 'tweeting': 1310, 'mood': 1311, 'hamburger': 1312, 'australian': 1313, 'billionaire': 1314, 'build': 1315, 'titanic': 1316, 'ii': 1317, 'russian': 1318, 'offers': 1319, 'tickets': 1320, 'leave': 1321, 'goldman': 1322, 'sachs': 1323, 'hired': 1324, 'russia': 1325, 'corporate': 1326, 'broker': 1327, 'boost': 1328, 'image': 1329, 'baltimore': 1330, 'named': 1331, 'city': 1332, 'quality': 1333, 'pigeon': 1334, 'democrats': 1335, 'accept': 1336, 'refugees': 1337, '-': 1338, 'aladdin': 1339, 'awakes': 1340, 'dressed': 1341, 'pirate': 1342, 'stalking': 1343, 'herself': 1344, 'vancouver': 1345, 'condo': 1346, 'developers': 1347, 'offer': 1348, 'wine': 1349, 'or': 1350, 'supply': 1351, 'avocado': 1352, 'toast': 1353, 'woo': 1354, 'buyers': 1355, 'market': 1356, 'texas': 1357, 'discovers': 1358, '70': 1359, 'ways': 1360, 'elk': 1361, 'completely': 1362, 'november': 1363, 'indiana': 1364, 'permanent': 1365, 'tattoo': 1366, 'promoting': 1367, '5000': 1368, 'reading': 1369, 'm': 1370, 'already': 1371, 'gone': 1372, 'partnership': 1373, 'eric': 1374, 'very': 1375, 'domestic': 1376, 'disturbance': 1377, 'young': 1378, 'building': 1379, 'ikea': 1380, 'furniture': 1381, 'airlines': 1382, 'installing': 1383, 'uncomfortable': 1384, 'bumps': 1385, 'responded': 1386, 'impeachment': 1387, 'probe': 1388, 'sans': 1389, 'font': 1390, 'creator': 1391, 'row': 1392, 'inmate': 1393, 'chance': 1394, 'try': 1395, 'execution': 1396, 'drug': 1397, 'most': 1398, 'serial': 1399, 'killers': 1400, 'did': 1401, 'receive': 1402, 'toy': 1403, 'went': 1404, 'group': 1405, 'girls': 1406, 'trap': 1407, 'alleged': 1408, 'pedophile': 1409, 'kidnapped': 1410, 'area': 1411, 'waiting': 1412, 'minutes': 1413, 'sharing': 1414, 'newspapers': 1415, 'protect': 1416, 'publisher': 1417, 'business': 1418, 'models': 1419, 'ar-15': 1420, 'benefit': 1421, 'arkansas': 1422, 'where': 1423, '5': 1424, 'were': 1425, '1998': 1426, 'seeing': 1427, 'banana': 1428, 'supermarket': 1429, 'voter': 1430, 'horse': 1431, 'track': 1432, 'rubber': 1433, 'trying': 1434, 'weight': 1435, 'kicking': 1436, 'warren': 1437, 'buffett': 1438, 'caesars': 1439, 'palace': 1440, 'losing': 1441, 'everything': 1442, 'roulette': 1443, 'wheel': 1444, 'raccoon': 1445, \"'erotic\": 1446, 'dispute': 1447, 'professor': 1448, 'hoping': 1449, 'some': 1450, 'leaves': 1451, 'behind': 1452, 'warm': 1453, 'pair': 1454, 'gloves': 1455, 'majority': 1456, 'approve': 1457, 'child': 1458, 'labor': 1459, 'laws': 1460, 'agree': 1461, 'carrying': 1462, 'least': 1463, 'reports': 1464, 'story': 1465, 'brides': 1466, 'kamala': 1467, 'harris': 1468, 'undergoes': 1469, 'surgery': 1470, 'positive': 1471, 'sanders': 1472, 'instagram': 1473, 'slams': 1474, 'filipino': 1475, 'workers': 1476, 'funding': 1477, 'step': 1478, 'added': 1479, 'scientific': 1480, 'method': 1481, 'sniper': 1482, 'penguins': 1483, 'stanley': 1484, 'beach': 1485, 'married': 1486, '16': 1487, 'radio': 1488, 'love': 1489, 'song': 1490, 'russell': 1491, 'dinosaur': 1492, 'leonardo': 1493, 'dicaprio': 1494, 'swedish': 1495, 'forgets': 1496, 'class': 1497, 'required': 1498, 'graduation': 1499, 'exploding': 1500, 'substance': 1501, 'minnesota': 1502, 'pigs': 1503, 'hear': 1504, 'vatican': 1505, 'hulk': 1506, 'catholic': 1507, 'former': 1508, 'spy': 1509, '(': 1510, 'xpost': 1511, 'r': 1512, 'newsofthestupid': 1513, ')': 1514, 'navy': 1515, 'pays': 1516, 'microsoft': 1517, 'keep': 1518, 'windows': 1519, 'xp': 1520, \"'no\": 1521, 'stickers': 1522, 'slapped': 1523, 'sale': 1524, 'signs': 1525, 'portland': 1526, 'gym': 1527, 'teachers': 1528, 'ranked': 1529, 'important': 1530, 'feel': 1531, 'motion': 1532, 'basketball': 1533, 'look': 1534, 'forward': 1535, 'ending': 1536, 'assisted': 1537, 'suicide': 1538, 'advocate': 1539, 'cannon': 1540, 'brick': 1541, 'wall': 1542, 'sarah': 1543, 'palin': 1544, '–': 1545, 'crowd': 1546, 'stunned': 1547, 'give': 1548, 'average': 1549, 'american': 1550, 'less': 1551, 'medieval': 1552, 'peasant': 1553, 'boy': 1554, 'grades': 1555, 'improved': 1556, 'bats': 1557, 'abusive': 1558, 'husbands': 1559, 'check': 1560, 'ryan': 1561, 'lochte': 1562, 'olympic': 1563, 'pool': 1564, 'much': 1565, 'remembered': 1566, 'nazi': 1567, 'treasure': 1568, 'hunters': 1569, 'following': 1570, 'realistic': 1571, 'retirement': 1572, 'plan': 1573, '86': 1574, 'gangster': 1575, 'rapper': 1576, 'cancels': 1577, 'shows': 1578, 'actual': 1579, 'quietly': 1580, 'rockets': 1581, 'doctor': 1582, 'throw': 1583, 'physical': 1584, 'york': 1585, 'times': 1586, 'amends': 1587, 'recent': 1588, 'would-be': 1589, 'headline': 1590, 'basement': 1591, 'plastic': 1592, 'nativity': 1593, 'scene': 1594, 'figures': 1595, 'auckland': 1596, 'council': 1597, 'funded': 1598, 'goat': 1599, 'hunt': 1600, 'goats': 1601, 'nerf': 1602, 'those': 1603, 'frozen': 1604, 'nc': 1605, 'alligators': 1606, 'really': 1607, 'era': 1608, 'texts': 1609, 'everyone': 1610, 'mission': 1611, 'storage': 1612, 'moose': 1613, 'rapist': 1614, 'victim': 1615, 'hiv': 1616, 'ftw': 1617, 'nanny': 1618, 'basically': 1619, 'part': 1620, 'sticking': 1621, 'decided': 1622, 'stay': 1623, 'costume': 1624, 'finish': 1625, 'barack': 1626, 'urged': 1627, 'condemn': 1628, 'affleck': 1629, 'batman': 1630, 'casting': 1631, 'creeped': 1632, 'older': 1633, 'constantly': 1634, 'lure': 1635, 'stem': 1636, 'company': 1637, 'able': 1638, 'respond': 1639, 'laying': 1640, 'philippines': 1641, 'duterte': 1642, 'threatens': 1643, 'canada': 1644, 'take': 1645, 'trash': 1646, 'bravely': 1647, 'stands': 1648, 'trans': 1649, 'unlimited': 1650, 'resources': 1651, 'bread': 1652, 'misconduct': 1653, 'quick': 1654, 'tips': 1655, 'loving': 1656, 'choking': 1657, 'your': 1658, 'apartment': 1659, 'alone': 1660, 'paying': 1661, 'college': 1662, 'finest': 1663, 'elon': 1664, 'musk': 1665, 'taliban': 1666, 'demands': 1667, 'coverage': 1668, 'attempted': 1669, 'murder': 1670, '14-year-old': 1671, 'successful': 1672, 'self-conscious': 1673, 'jet': 1674, 'sprays': 1675, 'crashed': 1676, 'jets': 1677, 'features': 1678, 'boeing': 1679, 'epa': 1680, 'climate': 1681, '75': 1682, 'huckabee': 1683, \"'d\": 1684, 'consider': 1685, 'federal': 1686, 'troops': 1687, 'abortions': 1688, 'conspiracy': 1689, 'theorist': 1690, 'punched': 1691, 'buzz': 1692, 'aldrin': 1693, 'insists': 1694, 'moon': 1695, 'landing': 1696, 'produces': 1697, 'decorative': 1698, 'gift': 1699, 'bag': 1700, 'thin': 1701, 'air': 1702, 'huge': 1703, 'either': 1704, 'amazon': 1705, 'discovered': 1706, 'largest': 1707, 'frog': 1708, 'luxurious': 1709, 'record': 1710, 'diana': 1711, 'gave': 1712, 'permission': 1713, 'play': 1714, 'beyond': 1715, 'tough': 1716, 'farewell': 1717, 'tearfully': 1718, 'cooks': 1719, 'breakfast': 1720, 'asteroid': 1721, 'landed': 1722, 'elderly': 1723, 'bids': 1724, 'tearful': 1725, 'season': 1726, 'begins': 1727, 'isis': 1728, 'saying': 1729, 'nude': 1730, 'local': 1731, 'tasered': 1732, 'arrest': 1733, 'collection': 1734, 'leads': 1735, 'sentence': 1736, 'fine': 1737, 'spent': 1738, '36': 1739, 'stealing': 1740, 'bakery': 1741, 'freed': 1742, 'meltdown': 1743, 'been': 1744, 'furiously': 1745, 'supposed': 1746, 'swallow': 1747, 'roll': 1748, 'crackers': 1749, 'pull': 1750, 'rapes': 1751, 'wonders': 1752, 'above': 1753, '30': 1754, 'sexually': 1755, 'abused': 1756, 'cousins': 1757, 'fair': 1758, 'uk': 1759, \"'to\": 1760, 'france': 1761, 'guy': 1762, 'paid': 1763, 'fact': 1764, 'case': 1765, 'order': 1766, 'restored': 1767, 'shoplifting': 1768, 'tried': 1769, 'size': 1770, 'nation': 1771, 'creepy': 1772, 'robot': 1773, 'taken': 1774, 'launching': 1775, 'china': 1776, 'communist': 1777, 'newspaper': 1778, 'hailed': 1779, 'naming': 1780, 'korean': 1781, 'dictator': 1782, 'jong': 1783, 'un': 1784, 'sexiest': 1785, 'alive': 1786, 'liberal': 1787, 'roy': 1788, 'moore': 1789, 'ted': 1790, 'nugent': 1791, 'concert': 1792, 'last-minute': 1793, 'buddhist': 1794, 'extremist': 1795, 'cell': 1796, 'vows': 1797, 'unleash': 1798, 'west': 1799, 'founder': 1800, 'sleeping': 1801, 'selfie': 1802, 'stick': 1803, 'lets': 1804, 'selfies': 1805, 'like': 1806, \"'ve\": 1807, 'wanted': 1808, 'assures': 1809, 'pittsburgh': 1810, 'done': 1811, 'yet': 1812, 'dismisses': 1813, 'hands': 1814, 'defence': 1815, 'healer': 1816, 'groping': 1817, 'victims': 1818, 'lying': 1819, 'bragging': 1820, 'lied': 1821, 'rename': 1822, 'mexico': 1823, 'seat': 1824, 'awareness': 1825, 'assault': 1826, 'metro': 1827, 'dubai': 1828, 'ruler': 1829, 'flees': 1830, 'europe': 1831, 'writes': 1832, 'furious': 1833, 'poem': 1834, 'return': 1835, 'kindergarten': 1836, 'quits': 1837, 'six': 1838, 'twerking': 1839, 'ohio': 1840, 'rape': 1841, 'guitarist': 1842, 'saved': 1843, 'spitting': 1844, 'eye': 1845, 'senior': 1846, 'holding': 1847, 'hope': 1848, 'internship': 1849, 'lead': 1850, 'poverty': 1851, 'cut': 1852, 'significant': 1853, 'iowa': 1854, 'emails': 1855, 'homework': 1856, 'scrap': 1857, 'thief': 1858, 'iron': 1859, 'bridge': 1860, 'accuses': 1861, 'google': 1862, 'elections': 1863, 'suspended': 1864, 'st.': 1865, 'louis': 1866, 'officer': 1867, 'everybody': 1868, 'sent': 1869, 'inflatable': 1870, 'confirms': 1871, 'present': 1872, 'alaska': 1873, 'butcher': 1874, 'rutgers': 1875, 'teach': 1876, 'suspends': 1877, 'hard': 1878, 'chris': 1879, 'pine': 1880, 'accompanied': 1881, 'terminally': 1882, 'ill': 1883, 'prom': 1884, 'pratt': 1885, 'willing': 1886, 'muslims': 1887, 'rights': 1888, 'necessary': 1889, 'safe': 1890, 'robber': 1891, 'returns': 1892, 'philly': 1893, 'enough': 1894, 'transplant': 1895, 'calling': 1896, 'ask': 1897, 'away': 1898, 'middle': 1899, 'jailed': 1900, 'court': 1901, 'judges': 1902, 'decide': 1903, 'which': 1904, 've': 1905, 'feminism': 1906, 'action': 1907, 'lives': 1908, 'compound': 1909, '17': 1910, 'confirm': 1911, 'anti-vaccine': 1912, 'sites': 1913, 'contain': 1914, 'facts': 1915, 'confiscate': 1916, 'biggest': 1917, 'joint': 1918, '4': 1919, 'rally': 1920, 'santa': 1921, 'cruz': 1922, 'panicked': 1923, 'kelly': 1924, 'podium': 1925, 'shouts': 1926, 'means': 1927, 'street': 1928, 'leaking': 1929, 'sure': 1930, 'guys': 1931, 'deer': 1932, 'swims': 1933, 'four': 1934, 'drowns': 1935, 'bungled': 1936, 'rescue': 1937, 'challenged': 1938, 'survive': 1939, 'minimum': 1940, 'wage': 1941, 'immediately': 1942, 'naked': 1943, 'fluid': 1944, 'voice': 1945, 'tale': 1946, 'stolen': 1947, 'fried': 1948, 'rice': 1949, 'viral': 1950, 'why': 1951, 'evolution': 1952, 'religion': 1953, 'biden': 1954, 'signature': 1955, 'executive': 1956, 'december': 1957, 'history': 1958, 'month': 1959, 'passionate': 1960, 'rest': 1961, 'nascar': 1962, 'race': 1963, 'ducks': 1964, 'angela': 1965, 'merkel': 1966, 'tells': 1967, 'asylum': 1968, 'holidays': 1969, 'origin': 1970, 'talks': 1971, 'edward': 1972, 'snowden': 1973, 'pleads': 1974, 'goal': 1975, 'become': 1976, 'christopher': 1977, 'chloe': 1978, 'acting': 1979, 'questions': 1980, 'abduction': 1981, 'fun': 1982, '3m': 1983, 'pot': 1984, 'bust': 1985, 'use': 1986, 'sliders': 1987, 'write': 1988, '#': 1989, 'comments': 1990, 'section': 1991, 'recipe': 1992, 'baked': 1993, 'charges': 1994, 'ma': 1995, 'threw': 1996, 'bacon': 1997, 'hunter': 1998, 'stole': 1999, 'sorry': 2000, 'boston': 2001, 'marathon': 2002, 'memories': 2003, 'raised': 2004, 'gofundme': 2005, 'increase': 2006, 'sales': 2007, 'result': 2008, 'speech': 2009, 'comet': 2010, 'looks': 2011, 'skull': 2012, 'past': 2013, 'earth': 2014, 'halloween': 2015, 'etiquette': 2016, 'sean': 2017, 'hannity': 2018, 'fox': 2019, 'carjacking': 2020, 'gunpoint': 2021, 'fails': 2022, 'shift': 2023, 'jeff': 2024, 'sessions': 2025, 'commit': 2026, 'london': 2027, 'commuters': 2028, 'force': 2029, 'doors': 2030, 'flee': 2031, 'onto': 2032, 'tracks': 2033, 'reads': 2034, 'calendar': 2035, 'ticket': 2036, 'std': 2037, 'kicked': 2038, 'tournament': 2039, 'looking': 2040, 'jesus': 2041, 'sold': 2042, 'contaminated': 2043, 'generic': 2044, 'drugs': 2045, 'responds': 2046, 'aids': 2047, 'africa': 2048, 'stating': 2049, 'cares': 2050, 'blacks': 2051, 'setting': 2052, 'unrealistic': 2053, 'standards': 2054, 'beauty': 2055, 'our': 2056, 'felons': 2057, 'criticizes': 2058, 'anime': 2059, 'throat': 2060, 'choked': 2061, 'offbeat': 2062, 'expert': 2063, 'jewish': 2064, '40': 2065, 'outside': 2066, 'hat': 2067, 'seagull': 2068, 'turns': 2069, 'orange': 2070, 'vat': 2071, 'curry': 2072, 'oregon': 2073, 'militant': 2074, 'challenges': 2075, 'christie': 2076, 'wrestling': 2077, 'standoff': 2078, 'controversial': 2079, 'heartbeat': 2080, 'passes': 2081, 'selena': 2082, 'gomez': 2083, 'ankle': 2084, 'mosque': 2085, 'players': 2086, 'stand': 2087, 'sunday': 2088, 'theme': 2089, 'announce': 2090, 'pick': 2091, 'sleepover': 2092, 'el': 2093, 'chapo': 2094, 'launch': 2095, 'clothing': 2096, 'lord': 2097, 'name': 2098, 'spelled': 2099, 'destroyed': 2100, '12': 2101, 'condition': 2102, 'reported': 2103, 'stable': 2104, 'inspiring': 2105, 'david': 2106, 'grow': 2107, 'stare': 2108, 'animals': 2109, 'describe': 2110, 'doing': 2111, 'spicy': 2112, 'terrible': 2113, 'effects': 2114, 'seven': 2115, 'ceos': 2116, 'taxes': 2117, 'scout': 2118, 'cookies': 2119, 'shop': 2120, \"'it\": 2121, 'rules': 2122, 'immigrant': 2123, 'apart': 2124, 'almost': 2125, 'members': 2126, 'membership': 2127, 'fee': 2128, '61-year-old': 2129, 'graffiti': 2130, 'led': 2131, 'chase': 2132, 'scooter': 2133, 'outraged': 2134, 'version': 2135, 'anthem': 2136, 'rock': 2137, 'bands': 2138, 'medical': 2139, 'marijuana': 2140, 'clinic': 2141, 'guest': 2142, 'nerds': 2143, 'degrasse': 2144, 'polish': 2145, 'nigel': 2146, 'farage': 2147, '18th': 2148, 'duel': 2149, 'complaint': 2150, 'w.': 2151, 'paintings': 2152, 'dogs': 2153, 'friends': 2154, 'ghost': 2155, 'iraqi': 2156, 'follows': 2157, 'everywhere': 2158, 'deeply': 2159, 'troubling': 2160, 'buried': 2161, 'mountains': 2162, \"'what\": 2163, 'trends': 2164, 'votes': 2165, 'abstinence-only': 2166, 'curriculum': 2167, 'education': 2168, 'five': 2169, 'road': 2170, '—': 2171, 'victoria': 2172, 'secret': 2173, 'patch': 2174, 'anywhere': 2175, 'dozens': 2176, 'countries': 2177, '2016': 2178, 'annoyed': 2179, 'credit': 2180, 'protest': 2181, 'protesters': 2182, 'caused': 2183, '13-year-old': 2184, 'nursing': 2185, 'farmers': 2186, 'glue': 2187, 'cotton': 2188, 'allowed': 2189, 'monks': 2190, 'buy': 2191, '600': 2192, 'lobster': 2193, 'release': 2194, 'ocean': 2195, 'human': 2196, 'dna': 2197, 'meat': 2198, 'silver': 2199, 'spend': 2200, 'next': 2201, 'making': 2202, 'easy': 2203, 'confidence': 2204, 'priest': 2205, 'revenge': 2206, 'god': 2207, 'poker': 2208, 'sunlight': 2209, 'ringtone': 2210, 'seals': 2211, 'fate': 2212, 'spokane': 2213, 'valley': 2214, 'evade': 2215, 'deputies': 2216, 'bank': 2217, 'loan': 2218, 'brother': 2219, 'smells': 2220, 'okay': 2221, '85': 2222, 'annually': 2223, 'television': 2224, 'program': 2225, 'depicting': 2226, 'wearing': 2227, 'clothes': 2228, 'apple': 2229, 'answer': 2230, 'siri': 2231, 'dunkin': 2232, '10-year': 2233, 'exclusive': 2234, 'vendor': 2235, 'united': 2236, 'states': 2237, '2': 2238, 'resort': 2239, 'dlc': 2240, 'quit': 2241, 'assassin': 2242, 'docs': 2243, 'botched': 2244, 'cat': 2245, 'town': 2246, 'mayor': 2247, 'mauled': 2248, 'beaten': 2249, 'offering': 2250, 'egg': 2251, 'demand': 2252, 'products': 2253, 'directly': 2254, 'skin': 2255, 'sue': 2256, 'yoga': 2257, 'classes': 2258, 'coffee': 2259, 'extends': 2260, 'system': 2261, 'oppression': 2262, 'recite': 2263, 'starbucks': 2264, 'training': 2265, 'photo': 2266, 'clerk': 2267, '100': 2268, 'masturbate': 2269, 'shameful': 2270, 'privilege': 2271, 'yale': 2272, 'donated': 2273, 'enormous': 2274, 'physics': 2275, 'forcing': 2276, 'christine': 2277, 'blasey': 2278, 'ford': 2279, 'publicly': 2280, 'apologize': 2281, 'sword': 2282, 'birthday': 2283, 'magazine': 2284, 'tell': 2285, 'cloned': 2286, 'pig': 2287, 'kosher': 2288, 'jews': 2289, '45': 2290, 'gallons': 2291, 'red': 2292, 'cross': 2293, 'insufferable': 2294, 'considered': 2295, 'coach': 2296, 'cash': 2297, '1.2': 2298, 'newest': 2299, 'duty': 2300, 'franchise': 2301, 'include': 2302, 'collector': 2303, 'package': 2304, 'want': 2305, 'chickenpox': 2306, 'vaccine': 2307, 'hammer': 2308, 'previous': 2309, 'generation': 2310, 'justified': 2311, 'insane': 2312, 'raid': 2313, 'dotcom': 2314, 'mansion': 2315, 'suspected': 2316, 'device': 2317, 'wipe': 2318, 'piracy': 2319, 'x': 2320, 'post': 2321, 'secretary': 2322, 'salary': 2323, 'yacht': 2324, 'dear': 2325, 'pictures': 2326, 'passenger': 2327, 'opens': 2328, 'plane': 2329, 'emergency': 2330, 'exit': 2331, 'mistaking': 2332, 'crash': 2333, 'survivor': 2334, 'completing': 2335, 'therapy': 2336, 'mount': 2337, 'everest': 2338, 'idea': 2339, 'sign': 2340, 'pledge': 2341, 'continue': 2342, 'strangers': 2343, 'marshal': 2344, 'bring': 2345, 'amazing': 2346, 'lucas': 2347, 'jar': 2348, 'favorite': 2349, 'character': 2350, 'reaffirms': 2351, 'commitment': 2352, 'things': 2353, 'recognize': 2354, 'inclusivity': 2355, 'mix': 2356, 'circle': 2357, 'wheelchair': 2358, 'wheels': 2359, 'rankings': 2360, 'masturbating': 2361, 'bobby': 2362, 'eggs': 2363, 'brought': 2364, 'challenger': 2365, 'leader': 2366, 'justice': 2367, 'full': 2368, 'equality': 2369, 'board': 2370, '--': 2371, 'qb': 2372, 'stepped': 2373, 'took': 2374, 'blame': 2375, 'pornography': 2376, 'computer': 2377, 'snake': 2378, 'forces': 2379, 'aussie': 2380, 'mills': 2381, 'releases': 2382, 'lucky': 2383, 'charms': 2384, '15': 2385, 'turkey': 2386, 'pardon': 2387, 'mishap': 2388, 'results': 2389, 'accidental': 2390, 'likes': 2391, 'vandals': 2392, 'racial': 2393, 'slurs': 2394, 'homes': 2395, 'bullies': 2396, 'calls': 2397, 'punish': 2398, 'warrior': 2399, 'thumb': 2400, 'tweeted': 2401, 'quotes': 2402, 'trust': 2403, 'admitting': 2404, 'burned': 2405, 'venezuela': 2406, 'aid': 2407, 'lunch': 2408, 'watermelon': 2409, 'cornbread': 2410, 'attacking': 2411, 'vending': 2412, 'machine': 2413, 'confused': 2414, 'sexy': 2415, 'chanting': 2416, 'gunfire': 2417, 'others': 2418, 'hurt': 2419, 'relaxing': 2420, 'tea': 2421, 'clearly': 2422, 'fishing': 2423, 'compliments': 2424, 'bernie': 2425, 'posted': 2426, 'sad': 2427, 'rant': 2428, '200,000': 2429, 'move': 2430, 'depressed': 2431, 'polar': 2432, 'bear': 2433, 'price': 2434, 'contestant': 2435, 'dryer': 2436, 'drew': 2437, 'carey': 2438, 'sister': 2439, \"'god\": 2440, 'happen': 2441, 'monk': 2442, 'imprisoned': 2443, 'gambling': 2444, 'temple': 2445, 'graduates': 2446, 'refused': 2447, 'threatened': 2448, 'grand': 2449, 'rapids': 2450, \"'that\": 2451, 'lady': 2452, 'dollar': 2453, 'charity': 2454, \"'fifty\": 2455, 'shades': 2456, 'grey': 2457, 'missed': 2458, 'opportunity': 2459, 'sleep': 2460, 'hotel': 2461, 'reagan': 2462, 'airport': 2463, 'juvenile': 2464, 'licked': 2465, 'tub': 2466, 'shelf': 2467, 'hits': 2468, 'bar': 2469, 'oops': 2470, 'o': 2471, 'association': 2472, 'nra': 2473, 'prefer': 2474, 'attractive': 2475, 'oklahoma': 2476, 'tucker': 2477, 'carlson': 2478, 'angrily': 2479, 'difference': 2480, 'between': 2481, 'good': 2482, 'lies': 2483, 'producers': 2484, 'reese': 2485, 'realizing': 2486, 'undercover': 2487, 'sandwich': 2488, 'burlington': 2489, 'courtroom': 2490, 'sketch': 2491, 'clear': 2492, 'piece': 2493, 'treadmill': 2494, 'jfk': 2495, 'coming': 2496, 'smithsonian': 2497, 'in-game': 2498, 'items': 2499, 'hitting': 2500, 'baseball': 2501, 'bat': 2502, 'date': 2503, 'oil': 2504, 'baron': 2505, 'cigarette': 2506, 'environmental': 2507, 'platform': 2508, 'unconscious': 2509, 'seaside': 2510, 'heights': 2511, 'coaster': 2512, 'sandy': 2513, 'replaced': 2514, 'grotesque': 2515, 'mass': 2516, 'slowly': 2517, 'forming': 2518, 'trail': 2519, 'neighbour': 2520, 'rival': 2521, 'potato': 2522, 'gas': 2523, 'kanye': 2524, 'designer': 2525, 'neck': 2526, 'copy': 2527, '72': 2528, 'grandmother': 2529, 'starting': 2530, 'app': 2531, 'icelanders': 2532, 'incest': 2533, 'net': 2534, 'neutrality': 2535, 'signing': 2536, 'wants': 2537, 'break': 2538, 'hours': 2539, 'solemnly': 2540, 'recalls': 2541, 'horrors': 2542, 'prostitute': 2543, 'arrives': 2544, 'read': 2545, 'handwriting': 2546, 'note': 2547, 'pulled': 2548, 'drown': 2549, 'e3': 2550, 'attendees': 2551, 'terror': 2552, 'bethesda': 2553, 'presentation': 2554, 'glitch': 2555, 'floor': 2556, 'archaeologists': 2557, 'nintendo': 2558, 'bug': 2559, 'allows': 2560, 'same-sex': 2561, 'couples': 2562, '911': 2563, 'terrorist': 2564, 'massacre': 2565, 'dj': 2566, 'india': 2567, '&': 2568, 'sucks': 2569, 'brett': 2570, 'robbery': 2571, 'crimes': 2572, 'murderer': 2573, 'beware': 2574, 'brown': 2575, 'armed': 2576, 'loose': 2577, 'siberian': 2578, 'region': 2579, 'putin': 2580, 'reason': 2581, 'jury': 2582, 'shaking': 2583, 'corruption': 2584, 'written': 2585, 'remove': 2586, 'identity': 2587, 'adele': 2588, 'wakes': 2589, 'coma': 2590, 'wells': 2591, 'fargo': 2592, 'homeowner': 2593, 'payments': 2594, 'working': 2595, 'sexist': 2596, 'construction': 2597, 'crew': 2598, 'tooth': 2599, 'blogger': 2600, 'due': 2601, 'identify': 2602, 'gene': 2603, 'fellow': 2604, 'researcher': 2605, 'carl': 2606, 'funny': 2607, 'chipotle': 2608, 'downgraded': 2609, 'concern': 2610, 'handcuffed': 2611, 'shoots': 2612, 'glass': 2613, 'french': 2614, 'pledges': 2615, 'rebuild': 2616, 'weather': 2617, 'agency': 2618, 'nuke': 2619, 'hurricanes': 2620, 'grandfather': 2621, 'picking': 2622, 'wrong': 2623, 'grandchild': 2624, 'cracking': 2625, 'emotional': 2626, 'casual': 2627, 'address': 2628, 'mistakenly': 2629, 'meth': 2630, 'regrets': 2631, 'choosing': 2632, 'supreme': 2633, 'nominee': 2634, 'keeps': 2635, 'talking': 2636, 'respects': 2637, 'pastor': 2638, 'exposed': 2639, 'grindr': 2640, 'professors': 2641, 'test': 2642, 'fifty': 2643, 'library': 2644, 'book': 2645, 'traces': 2646, 'herpes': 2647, 'erection': 2648, 'bionic': 2649, 'pressing': 2650, 'button': 2651, 'jack': 2652, 'dorsey': 2653, 'letting': 2654, 'intended': 2655, 'strings': 2656, 'thugs': 2657, 'patrick': 2658, 'activists': 2659, 'snaps': 2660, 'enters': 2661, 'minute': 2662, 'rambling': 2663, 'syria': 2664, 'holds': 2665, 'contempt': 2666, 'smartphone': 2667, 'strength': 2668, 'whatever': 2669, 'else': 2670, 'teenage': 2671, 'knife': 2672, 'deep': 2673, 'ferrari': 2674, 'keys': 2675, 'asking': 2676, 'arguing': 2677, 'benefits': 2678, 'please': 2679, 'come': 2680, 'trick-or-treating': 2681, 'seizes': 2682, 'christmas': 2683, 'toys': 2684, 'distribute': 2685, 'fears': 2686, '3-year-old': 2687, 'corn': 2688, 'maze': 2689, 'didn': 2690, 'realize': 2691, 'anti-abortion': 2692, 'legislation': 2693, 'requires': 2694, 'balloon': 2695, 'lifelong': 2696, 'battle': 2697, 'depression': 2698, 'egypt': 2699, 'shake': 2700, 'smoke': 2701, 'lingerie': 2702, 'backlash': 2703, 'independent.ie': 2704, 'mike': 2705, 'pence': 2706, 'lil': 2707, 'wayne': 2708, 'fought': 2709, 'unveils': 2710, 'crust': 2711, 'comic-con': 2712, 'guesses': 2713, 'enjoyed': 2714, 'panel': 2715, 'silently': 2716, 'practicing': 2717, 'magic': 2718, 'uber': 2719, 'update': 2720, 'users': 2721, 'file': 2722, 'panicking': 2723, 'learning': 2724, 'encrypted': 2725, 'communications': 2726, 'intercepted': 2727, 'administration': 2728, 'ready': 2729, 'depot': 2730, 'helping': 2731, 'gaga': 2732, 'rodent': 2733, 'throughout': 2734, 'meeting': 2735, 'hillary': 2736, 'appears': 2737, 'authenticity': 2738, 'draft': 2739, 'list': 2740, 'common': 2741, 'notes': 2742, 'greatly': 2743, 'borders': 2744, 'whatsoever': 2745, 'nigerians': 2746, 'allowing': 2747, 'individual': 2748, 'commencement': 2749, 'speakers': 2750, 'ceremony': 2751, 'acceptable': 2752, 'parent': 2753, 'nightmare': 2754, 'church': 2755, 'elizabeth': 2756, 'licence': 2757, 'kisses': 2758, 'omaha': 2759, 'walgreens': 2760, 'bang': 2761, 'whispers': 2762, 'random': 2763, 'newly': 2764, 'unemployed': 2765, 'enjoys': 2766, 'alien': 2767, 'continues': 2768, 'aliens': 2769, 'latest': 2770, 'mining': 2771, 'backed': 2772, 'execs': 2773, 'james': 2774, 'cameron': 2775, 'unveiled': 2776, 'movie': 2777, 'slaughterhouse': 2778, 'roam': 2779, 'videos': 2780, 'slamming': 2781, 'nuts': 2782, 'hoover': 2783, 'involve': 2784, 'knows': 2785, 'exactly': 2786, 'act': 2787, 'decriminalize': 2788, 'kiss': 2789, 'movement': 2790, 'sc': 2791, 'ruling': 2792, 'ninth': 2793, 'symphony': 2794, 'speeding': 2795, 'hungary': 2796, 'unfriends': 2797, 'dick': 2798, 'cheney': 2799, 'request': 2800, 'sacha': 2801, 'cohen': 2802, 'actor': 2803, 'steven': 2804, 'seagal': 2805, 'driving': 2806, 'tank': 2807, 'puppy': 2808, 'gitmo': 2809, 'guards': 2810, 'complain': 2811, 'harsh': 2812, 'treatment': 2813, 'inmates': 2814, 'anchors': 2815, 'pa.': 2816, 'script': 2817, 'reporters': 2818, 'sting': 2819, 'cow': 2820, 'trend': 2821, 'costs': 2822, '300': 2823, 'session': 2824, 'blames': 2825, 'hangover': 2826, 'drank': 2827, 'hacker': 2828, 'shield': 2829, 'uploading': 2830, 'clarifies': 2831, 'sweden': 2832, 'claim': 2833, 'conflict': 2834, 'grumpy': 2835, 'shitty': 2836, 'attitude': 2837, 'forever': 2838, 'celebrates': 2839, 'status': 2840, 'banner': 2841, 'sewage': 2842, 'pipe': 2843, 'rio': 2844, 'opening': 2845, 'aspiring': 2846, 'meme': 2847, 'success': 2848, 'kidney': 2849, 'privacy': 2850, 'levi': 2851, 'developed': 2852, 'jeans': 2853, 'contact': 2854, 'lenses': 2855, '18': 2856, 'beers': 2857, 'argument': 2858, 'confederate': 2859, 'monument': 2860, 'statue': 2861, 'elliot': 2862, 'understand': 2863, 'hipsters': 2864, 'b.c': 2865, 'ads': 2866, 'comment': 2867, 'mainstream': 2868, 'subway': 2869, 'meal': 2870, 'happiness': 2871, 'sought': 2872, 'suspect': 2873, 'choose': 2874, 'duck': 2875, 'offered': 2876, '10,000': 2877, 'eternal': 2878, 'proposed': 2879, 'replace': 2880, 'colombia': 2881, 'sen.': 2882, 'lindsey': 2883, 'graham': 2884, 'verizon': 2885, 'glad': 2886, 'nsa': 2887, 'data': 2888, 'terrorists': 2889, 'movies': 2890, 'violence': 2891, 'r-rated': 2892, 'films': 2893, 'exxon': 2894, 'joins': 2895, 'anti-fracking': 2896, 'drilling': 2897, 'value': 2898, 'small': 2899, 'declare': 2900, 'bankruptcy': 2901, 'accusers': 2902, 'candidate': 2903, 'officials': 2904, 'horoscopes': 2905, 'january': 2906, '3': 2907, '2017': 2908, 'jason': 2909, 'momoa': 2910, 'becoming': 2911, 'useless': 2912, 'dumbass': 2913, 'kfc': 2914, 'bibles': 2915, 'rooms': 2916, 'felt': 2917, 'modern': 2918, 'society': 2919, 'hospitals': 2920, 'share': 2921, 'patient': 2922, 'gamers': 2923, 'residents': 2924, 'mind-blowing': 2925, 'soldiers': 2926, 'impersonator': 2927, 'gulf': 2928, 'breath': 2929, 'regulations': 2930, 'power': 2931, 'plants': 2932, 'loopholes': 2933, 'don': 2934, 'politics': 2935, 'stories': 2936, 'agents': 2937, 'u-haul': 2938, 'rental': 2939, 'service': 2940, 'tackle': 2941, 'retired': 2942, 'tennis': 2943, 'sesame': 2944, 'showed': 2945, 'grover': 2946, 'ernie': 2947, 'hatch': 2948, 'explained': 2949, 'unclear': 2950, 'loud': 2951, 'supporters': 2952, 'arena': 2953, 'mueller': 2954, 'meets': 2955, 'robert': 2956, 'describing': 2957, 'congress': 2958, 'lockdown': 2959, 'cats': 2960, 'nice': 2961, 'enjoy': 2962, 'humans': 2963, 'groin': 2964, 'ninjas': 2965, 'lone': 2966, 'tampa': 2967, 'pete': 2968, 'also': 2969, 'queen': 2970, 'pink': 2971, 'floyd': 2972, 'airline': 2973, 'deemed': 2974, 'blind': 2975, 'disability': 2976, 'fraud': 2977, 'speed': 2978, 'boat': 2979, 'posing': 2980, 'dealers': 2981, 'genetic': 2982, 'appeal': 2983, 'tuesday': 2984, 'mitt': 2985, 'compare': 2986, 'debt': 2987, 'rapidly': 2988, 'growing': 2989, 'beautiful': 2990, 'tribute': 2991, 'purple': 2992, 'rain': 2993, 'opera': 2994, 'sing': 2995, 'similar': 2996, 'kept': 2997, 'private': 2998, 'mad': 2999, 'arabia': 3000, 'angers': 3001, 'kingdom': 3002, 'pornhub': 3003, 'plant': 3004, 'tree': 3005, 'front': 3006, 'crews': 3007, 'disappears': 3008, 'dropped': 3009, 'hickenlooper': 3010, 'drops': 3011, '2020': 3012, 'presidential': 3013, 'assumes': 3014, 'issues': 3015, 'victory': 3016, 'approaches': 3017, 'unfamiliar': 3018, 'breaking': 3019, 'wild': 3020, 'stallion': 3021, 'brewery': 3022, 'apologises': 3023, \"'gay\": 3024, 'lemonade': 3025, 'rifle': 3026, 'disney': 3027, 'shakespeare': 3028, 'favor': 3029, 'hunger': 3030, 'legal': 3031, 'nevada': 3032, \"'ll\": 3033, 'ufo': 3034, 'fetus': 3035, 'wreck': 3036, 'capitalism': 3037, 'shadows': 3038, 'administrator': 3039, 'railway': 3040, 'press': 3041, 'conference': 3042, 'probably': 3043, 'bullshit': 3044, 'scary': 3045, 'claiming': 3046, 'filled': 3047, 'pee': 3048, 'lays': 3049, 'vietnam': 3050, 'spends': 3051, 'classified': 3052, 'briefing': 3053, 'tornado': 3054, 'truck': 3055, 'filming': 3056, 'potentially': 3057, 'explosive': 3058, 'tinned': 3059, 'tomatoes': 3060, 'recalled': 3061, 'reunion': 3062, 'jimmy': 3063, 'page': 3064, 'spotted': 3065, 'guitar': 3066, 'center': 3067, 'zeppelin': 3068, 'send': 3069, 'parts': 3070, 'self-esteem': 3071, 'research': 3072, 'weekly': 3073, 'addresses': 3074, 'increasingly': 3075, 'harrison': 3076, 'memorial': 3077, 'beetles': 3078, 'fuck': 3079, 'suburban': 3080, 'moms': 3081, 'brilliant': 3082, 'financial': 3083, 'devastated': 3084, 'taco': 3085, 'bell': 3086, 'entirely': 3087, 'necklace': 3088, 'ku': 3089, 'klux': 3090, 'hispanic': 3091, 'gays': 3092, 'deletes': 3093, 'armor': 3094, 'cry': 3095, 'satanists': 3096, 'unveil': 3097, 'sculpture': 3098, 'detroit': 3099, 'rejection': 3100, 'capitol': 3101, 'drummer': 3102, 'carolina': 3103, 'healthy': 3104, 'bodies': 3105, 'definitely': 3106, 'shouldn': 3107, 'producing': 3108, 'feces': 3109, 'tail': 3110, 'opinion': 3111, 'ugly': 3112, 'word': 3113, 'currency': 3114, 'dollars': 3115, 'nuclear': 3116, 'started': 3117, '76': 3118, 'virginia': 3119, 'cousin': 3120, 'retweeting': 3121, 'stars': 3122, 'ottawa': 3123, 'exposure': 3124, 'park': 3125, 'olympics': 3126, 'based': 3127, 'hybrid': 3128, 'overdose': 3129, 'king': 3130, 'lose': 3131, 'dream': 3132, 'pocket': 3133, 'reflects': 3134, 'thwarted': 3135, 'discover': 3136, 'lack': 3137, 'language': 3138, 'skills': 3139, 'effectively': 3140, 'classmates': 3141, 'teenagers': 3142, 'gon': 3143, 'na': 3144, 'britain': 3145, 'evil': 3146, 'potter': 3147, 'demons': 3148, 'display': 3149, 'hut': 3150, 'march': 3151, 'utah': 3152, 'struck': 3153, 'lightning': 3154, 'accessibility': 3155, 'mints': 3156, '500': 3157, 'larger': 3158, 'impaired': 3159, 'failing': 3160, 'nine': 3161, 'ago': 3162, 'ed': 3163, 'sheeran': 3164, 'justices': 3165, 'ritual': 3166, 'stevens': 3167, 'ensure': 3168, 'burial': 3169, 'ultimate': 3170, 'experience': 3171, 'philadelphia': 3172, 'eagles': 3173, 'walked': 3174, 'whole': 3175, 'mice': 3176, 'belt': 3177, 'weird': 3178, 'close': 3179, 'product': 3180, 'taste': 3181, 'emo': 3182, 'arthur': 3183, 'episode': 3184, 'mr.': 3185, 'bottom': 3186, 'firms': 3187, 'shipped': 3188, 'pain': 3189, 'pills': 3190, 'scrambling': 3191, 'spilling': 3192, 'seeks': 3193, 'lethal': 3194, 'injection': 3195, 'painful': 3196, 'nancy': 3197, 'grace': 3198, 'parking': 3199, 'lot': 3200, 'british': 3201, 'airways': 3202, 'verdict': 3203, 'meant': 3204, 'garage': 3205, 'michelle': 3206, 'bachmann': 3207, 'relationship': 3208, 'israel': 3209, 'lebron': 3210, 'jam': 3211, 'sequel': 3212, 'slammed': 3213, 'turnover': 3214, 'sit': 3215, 'darkened': 3216, 'bedroom': 3217, 'roommate': 3218, 'zimmerman': 3219, 'used': 3220, 'trayvon': 3221, 'viewers': 3222, 'eaten': 3223, 'riding': 3224, 'turtle': 3225, 'booked': 3226, 'westboro': 3227, 'baptist': 3228, 'iraq': 3229, 'pakistani': 3230, 'culture': 3231, 'accepting': 3232, 'far': 3233, 'complaints': 3234, 'smash': 3235, 'phil': 3236, \"'in\": 3237, 'tonight': 3238, 'sons': 3239, 'reasons': 3240, 'slavery': 3241, 'sparks': 3242, 'lo': 3243, 'pregnancies': 3244, 'suv': 3245, 'driver': 3246, 'bike': 3247, 'vladimir': 3248, 'anti-putin': 3249, 'aims': 3250, 'logo': 3251, 'backup': 3252, 'dancer': 3253, 'bitten': 3254, 'mitch': 3255, 'mcconnell': 3256, 'pouch': 3257, 'dominance': 3258, 'congressional': 3259, 'males': 3260, 'toddler': 3261, 'active': 3262, 'washing': 3263, 'studying': 3264, 'genitalia': 3265, 'number': 3266, 'delta': 3267, 'lines': 3268, 'passengers': 3269, 'discount': 3270, '13': 3271, 'nervously': 3272, 'll': 3273, 'settle': 3274, 'nj': 3275, 'requests': 3276, 'obituary': 3277, 'lieu': 3278, 'organization': 3279, 'shocking': 3280, 'racist': 3281, 'tweets': 3282, 'follow': 3283, '5-year-old': 3284, 'feels': 3285, 'wasted': 3286, 'waving': 3287, 'recommend': 3288, 'bathing': 3289, 'stream': 3290, 'trees': 3291, 'alex': 3292, 'jones': 3293, 'inspires': 3294, 'erotic': 3295, 'novel': 3296, 'bags': 3297, 'cocaine': 3298, 'sets': 3299, 'limit': 3300, 'louder': 3301, 'quiz': 3302, 'extremely': 3303, 'personal': 3304, 'brings': 3305, 'emasculated': 3306, 'foul': 3307, 'likely': 3308, 'advisor': 3309, 'review': 3310, 'patrol': 3311, 'outrage': 3312, 'disturbing': 3313, 'shocked': 3314, 'reaches': 3315, 'columbus': 3316, 'rick': 3317, 'perry': 3318, 'suggests': 3319, 'fossil': 3320, 'fuels': 3321, 'help': 3322, 'gathers': 3323, 'parallel': 3324, 'brooks': 3325, 'brothers': 3326, 'middle-aged': 3327, 'tired': 3328, 'forth': 3329, 'divorced': 3330, 'removes': 3331, 'salad': 3332, 'towers': 3333, '8': 3334, 'dr.': 3335, 'oz': 3336, 'vital': 3337, 'brain': 3338, 'fighting': 3339, 'worried': 3340, 'insurance': 3341, 'fortnite': 3342, 'shkreli': 3343, 'seminar': 3344, 'prices': 3345, '4-year-old': 3346, 'assaulted': 3347, 'celebrity': 3348, 'tight': 3349, 'uncle': 3350, 'greg': 3351, 'attempt': 3352, 'comeback': 3353, 'barbecue': 3354, 'excited': 3355, 'bile': 3356, 'kaine': 3357, 'event': 3358, 'cognitive': 3359, 'ability': 3360, 'tent': 3361, 'uc': 3362, 'berkeley': 3363, 'arrests': 3364, 'chili': 3365, 'peppers': 3366, 'shittiest': 3367, 'pros': 3368, 'cons': 3369, 'helicopter': 3370, 'parenting': 3371, 'billed': 3372, 'confusing': 3373, 'murray': 3374, 'tom': 3375, 'hanks': 3376, 'jamaica': 3377, 'planted': 3378, 'voting': 3379, 'rejects': 3380, 'ballot': 3381, 'therapist': 3382, 'decade': 3383, 'trafficking': 3384, 'survivors': 3385, 'urges': 3386, 'client': 3387, 'sometimes': 3388, 'kitchen': 3389, 'hastily': 3390, 'altered': 3391, 'coworker': 3392, 'christians': 3393, 'wanting': 3394, 'county': 3395, 'schools': 3396, 'soon': 3397, 'satanist': 3398, 'pile': 3399, 'beans': 3400, 'kills': 3401, 'rolling': 3402, 'turning': 3403, 'sun': 3404, 'grocery': 3405, 'relief': 3406, 'floods': 3407, 'chef': 3408, 'cheddar': 3409, 'chalk': 3410, 'agencies': 3411, 'ex-girlfriend': 3412, 'receives': 3413, 'oral': 3414, 'spoke': 3415, 'climbing': 3416, 'lion': 3417, 'washington': 3418, 'rep.': 3419, 'matt': 3420, 'holy': 3421, '1,000': 3422, 'resign': 3423, 'topless': 3424, 'feminist': 3425, 'psychic': 3426, 'feeding': 3427, 'hats': 3428, 'empty': 3429, 'yellow': 3430, 'happily': 3431, 'attacked': 3432, 'pit': 3433, 'bulls': 3434, 'translate': 3435, 'feds': 3436, 'drivers': 3437, 'breasts': 3438, 'choice': 3439, 'cartel': 3440, 'junk': 3441, 'ship': 3442, 'anchor': 3443, 'survived': 3444, 'teens': 3445, 'marries': 3446, 'colorado': 3447, 'smell': 3448, 'douse': 3449, 'swarm': 3450, 'moves': 3451, 'registers': 3452, 'radar': 3453, 'pirating': 3454, 'tibetan': 3455, 'philosophy': 3456, 'substitute': 3457, 'box': 3458, 'purse': 3459, 'department': 3460, 'travel': 3461, 'warning': 3462, 'laundry': 3463, 'hacks': 3464, 'start': 3465, 'involved': 3466, 'purchase': 3467, '19': 3468, 'nailed': 3469, 'centre': 3470, 'neighbors': 3471, 'san': 3472, 'jose': 3473, 'causing': 3474, 'surprised': 3475, 'selves': 3476, 'priests': 3477, 'celibacy': 3478, 'vow': 3479, 'prosecutor': 3480, 'stupidity': 3481, 'wu-tang': 3482, 'clan': 3483, 'outfit': 3484, 'copyright': 3485, 'breach': 3486, 'threatening': 3487, 'citizens': 3488, 'repair': 3489, 'smartphones': 3490, 'harder': 3491, 'osama': 3492, 'bin': 3493, 'laden': 3494, 'smokes': 3495, 'jeopardy': 3496, 'stripped': 3497, 'contestants': 3498, 'bet': 3499, '69': 3500, 'final': 3501, 'suffering': 3502, 'anxiety': 3503, '000': 3504, 'dime': 3505, 'zimbabwe': 3506, 'mark': 3507, 'shark': 3508, 'reilly': 3509, 'conservatives': 3510, 'alternative': 3511, 'energy': 3512, 'root': 3513, 'tesla': 3514, 'souls': 3515, 'developing': 3516, 'breathalyzer': 3517, 'catch': 3518, 'stoned': 3519, 'singapore': 3520, 'nowhere': 3521, 'toddlers': 3522, 'u.s': 3523, 'realized': 3524, 'cars': 3525, 'destroys': 3526, 'cheese': 3527, 'headphones': 3528, 'anti-bullying': 3529, 'bullying': 3530, '900': 3531, 'writing': 3532, 'billions': 3533, 'illinois': 3534, 'entitled': 3535, 'swat': 3536, 'parody': 3537, 'account': 3538, 'electricity': 3539, 'reveal': 3540, 'economy': 3541, 'spirals': 3542, 'cigarettes': 3543, 'hand': 3544, 'jobs': 3545, 'faking': 3546, 'diaper': 3547, 'changed': 3548, 'frank': 3549, 'sample': 3550, 'combine': 3551, 'drill': 3552, 'places': 3553, 'wisdom': 3554, 'richard': 3555, 'nixon': 3556, 'appeared': 3557, 'amish': 3558, \"'stupid\": 3559, 'consumers': 3560, 'deserve': 3561, 'hefty': 3562, 'fees': 3563, '1930s': 3564, 'economists': 3565, 'fakes': 3566, 'blew': 3567, 'strip': 3568, 'resorts': 3569, 'knocking': 3570, 'door': 3571, 'thai': 3572, 'dummy': 3573, 'heads': 3574, 'course': 3575, 'towards': 3576, 'slapping': 3577, 'missouri': 3578, 'thailand': 3579, 'activist': 3580, 'royal': 3581, 'insults': 3582, 'balance': 3583, 'zero': 3584, 'tanker': 3585, 'dawn': 3586, 'soap': 3587, 'wildlife': 3588, 'clean': 3589, 'bond': 3590, 'concerned': 3591, 'film': 3592, 'locations': 3593, 'ramp': 3594, '1m': 3595, 'jackpot': 3596, 'co-worker': 3597, 'bikes': 3598, 'prove': 3599, 'ruled': 3600, \"'cruel\": 3601, 'unusual': 3602, 'punishment': 3603, 'lobsters': 3604, 'kinky': 3605, 'eddie': 3606, 'something': 3607, 'rude': 3608, '8-year-old': 3609, 'listen': 3610, 'yell': 3611, 'weeks': 3612, 'connect': 3613, 'rural': 3614, 'voters': 3615, 'mistakes': 3616, 'nhs': 3617, 'trade': 3618, 'firearms': 3619, 'boehner': 3620, 'primary': 3621, 'opponent': 3622, 'seriously': 3623, 'neighborhood': 3624, 'mugabe': 3625, 'appointed': 3626, 'envoy': 3627, 'tourism': 3628, 'lookout': 3629, 'grandma': 3630, 'wish': 3631, 'coward': 3632, 'afraid': 3633, 'cracker': 3634, 'innovation': 3635, 'exhausted': 3636, 'decides': 3637, 'breakthrough': 3638, 'possession': 3639, 'cold': 3640, 'romance': 3641, 'author': 3642, 'previously': 3643, 'wrote': 3644, 'espn': 3645, 'impressed': 3646, 'concentration': 3647, 'camp': 3648, 'maine': 3649, 'letters': 3650, 'healthcare': 3651, 'within': 3652, 'mouse': 3653, 'visible': 3654, 'slideshow': 3655, 'peppa': 3656, 'accent': 3657, 'owe': 3658, 'rhode': 3659, 'island': 3660, 'jelly': 3661, 'unlikely': 3662, 'allies': 3663, 'gate': 3664, 'agent': 3665, 'william': 3666, 'barr': 3667, 'agrees': 3668, 'visual': 3669, 'representation': 3670, 'breast': 3671, 'boob': 3672, 'soft': 3673, 'interest': 3674, 'walmart': 3675, 'nuisance': 3676, 'cast': 3677, 'priceless': 3678, 'raise': 3679, 'despite': 3680, 'dwi': 3681, 'violating': 3682, 'probation': 3683, 'playstation': 3684, 'legalized': 3685, 'weed': 3686, '39': 3687, 'tires': 3688, '79': 3689, 'minority': 3690, 'suspects': 3691, 'miranda': 3692, 'warner': 3693, 'bros.': 3694, 'flags': 3695, 'website': 3696, 'portal': 3697, 'among': 3698, 'promptly': 3699, 'surrenders': 3700, 'several': 3701, 'parkland': 3702, 'stances': 3703, 'reminds': 3704, 'bulletproof': 3705, 'vests': 3706, 'cover': 3707, 'authorities': 3708, 'austin': 3709, 'bomber': 3710, 'failed': 3711, 'sensitive': 3712, 'promising': 3713, 'leash': 3714, 'orgasm': 3715, 'wears': 3716, 'buggy': 3717, 'stereo': 3718, 'aging': 3719, 'lowering': 3720, 'turned': 3721, '40,000': 3722, 'aggressive': 3723, 'addicted': 3724, 'snacks': 3725, 'seattle': 3726, 'lawmaker': 3727, 'demanding': 3728, 'swear': 3729, 'allegiance': 3730, 'israeli': 3731, 'wi-fi': 3732, 'password': 3733, 'debate': 3734, 'nigeria': 3735, 'served': 3736, 'relevant': 3737, 'later': 3738, 'embarrassing': 3739, 'résumé': 3740, 'whistleblowers': 3741, 'targeted': 3742, 'insider': 3743, 'photographer': 3744, 'ran': 3745, 'fall': 3746, 'bosnia': 3747, 'robbed': 3748, 'posts': 3749, 'legend': 3750, 'giuliani': 3751, 'totally': 3752, 'blow': 3753, 'peace': 3754, 'process': 3755, 'begs': 3756, 'code': 3757, 'underground': 3758, 'realtor': 3759, 'proximity': 3760, 'nicer': 3761, 'deafening': 3762, 'journalist': 3763, 'explode': 3764, 'cnn': 3765, 'touching': 3766, 'rapists': 3767, '16-year-old': 3768, 'lizard': 3769, 'run': 3770, 'whites': 3771, 'equally': 3772, 'candidates': 3773, 'opened': 3774, 'parks': 3775, 'stuck': 3776, 'u.k.': 3777, 'josh': 3778, 'pushing': 3779, 'bones': 3780, \"'black\": 3781, 'dirty': 3782, 'lawmakers': 3783, '100,000': 3784, 'long': 3785, 'pointing': 3786, 'miracle': 3787, 'faulty': 3788, 'pulling': 3789, 'laughing': 3790, 'abortion': 3791, 'equifax': 3792, 'argentina': 3793, 'remain': 3794, 'displays': 3795, 'squirrels': 3796, 'steal': 3797, 'underwear': 3798, 'mtv': 3799, 'promises': 3800, 'covered': 3801, 'promise': 3802, 'writings': 3803, 'land': 3804, 'juggalos': 3805, 'cryptocurrency': 3806, 'gynecologist': 3807, 'art': 3808, 'iran': 3809, 'families': 3810, 'billion': 3811, 'gang': 3812, 'union': 3813, 'uncovers': 3814, 'beg': 3815, 'goals': 3816, 'visiting': 3817, 'denny': 3818, \"'a\": 3819, 'bunch': 3820, 'impression': 3821, 'ordered': 3822, 'table': 3823, 'italian': 3824, 'manslaughter': 3825, '2009': 3826, 'earthquake': 3827, 'commercial': 3828, 'secrets': 3829, 'mum': 3830, 'glenn': 3831, 'beck': 3832, 'nye': 3833, 'entirety': 3834, 'finger': 3835, 'smaller': 3836, 'highway': 3837, 'hearse': 3838, 'pointed': 3839, 'asked': 3840, \"'he\": 3841, 'count': 3842, 'dutch': 3843, 'crisis': 3844, 'shortage': 3845, 'prisoners': 3846, 'begin': 3847, 'agriculture': 3848, 'pepe': 3849, 'infowars': 3850, 'helicopters': 3851, 'essential': 3852, 'swiss': 3853, 'impersonating': 3854, 'kasich': 3855, '6,000': 3856, 'print': 3857, 'hidden': 3858, 'contest': 3859, 'fashion': 3860, 'wave': 3861, 'bow': 3862, 'slightly': 3863, 'listening': 3864, 'moving': 3865, 'crossing': 3866, 'indians': 3867, 'delayed': 3868, 'removal': 3869, 'tool': 3870, 'retirees': 3871, 'wet': 3872, 'beard': 3873, 'comparison': 3874, 'governor': 3875, 'vermont': 3876, 'science': 3877, 'announcing': 3878, 'eclipse': 3879, 'hostages': 3880, 'tense': 3881, 'biscuits': 3882, 'labels': 3883, 'nab': 3884, 'fleeing': 3885, 'fugitive': 3886, 'belly': 3887, 'progressive': 3888, 'acquaintance': 3889, 'backpack': 3890, 'qatar': 3891, 'mascot': 3892, 'reporting': 3893, 'missing': 3894, 'faster': 3895, 'putting': 3896, 'avatar': 3897, 'theory': 3898, 'bean': 3899, 'dude': 3900, 'bizarre': 3901, 'double': 3902, 'warcraft': 3903, 'critic': 3904, 'believes': 3905, 'poisoned': 3906, 'dove': 3907, 'requiring': 3908, 'violate': 3909, 'cemetery': 3910, 'completed': 3911, 'games': 3912, 'expresses': 3913, 'balloons': 3914, 'confetti': 3915, 'deadly': 3916, 'indonesian': 3917, 'discuss': 3918, 'rob': 3919, 'nature': 3920, 'irish': 3921, 'unable': 3922, 'avoiding': 3923, 'patrons': 3924, 'strips': 3925, 'mistress': 3926, 'title': 3927, 'efforts': 3928, 'indicted': 3929, 'fooled': 3930, 'yesterday': 3931, 'knowing': 3932, 'corps': 3933, 'solidarity': 3934, 'reporter': 3935, 'wtf': 3936, 'bias': 3937, 'different': 3938, 'colors': 3939, 'injuries': 3940, 'fda': 3941, 'taunts': 3942, 'cartoon': 3943, 'fighter': 3944, 'dreading': 3945, 'hometown': 3946, 'dumb': 3947, 'houston': 3948, 'heal': 3949, 'employs': 3950, 'migrants': 3951, 'wal-mart': 3952, 'donate': 3953, 'needy': 3954, \"'ghost\": 3955, 'cruises': 3956, 'fitness': 3957, 'tracker': 3958, 'happy': 3959, 'meals': 3960, 'investigators': 3961, 'outdated': 3962, 'purdue': 3963, 'pharma': 3964, 'type': 3965, 'oxycontin': 3966, 'ease': 3967, 'loved': 3968, 'decades': 3969, 'offender': 3970, 'manchester': 3971, 'inspire': 3972, 'unmarried': 3973, 'population': 3974, 'sugar': 3975, 'daddies': 3976, 'goldfish': 3977, 'serves': 3978, 'controversy': 3979, 'nhl': 3980, 'camps': 3981, 'april': 3982, '2018': 3983, 'cracks': 3984, 'cyclists': 3985, 'cyclist': 3986, 'ranger': 3987, 'samurai': 3988, 'iphone': 3989, 'themselves': 3990, 'protester': 3991, 'nephew': 3992, 'bigger': 3993, 'aunt': 3994, 'gotten': 3995, 'carjackers': 3996, 'discovering': 3997, 'manual': 3998, 'transmission': 3999, 'sky': 4000, 'bird': 4001, 'senators': 4002, 'flight': 4003, 'chip': 4004, 'bonus': 4005, 'belts': 4006, 'watchers': 4007, 'suspicious': 4008, 'mp': 4009, 'refuse': 4010, 'dallas': 4011, 'cowboys': 4012, 'harvey': 4013, 'devito': 4014, 'walks': 4015, 'files': 4016, 'approval': 4017, 'pretend': 4018, 'satellite': 4019, 'though': 4020, 'struggling': 4021, 'district': 4022, 'drag': 4023, 'queens': 4024, 'noah': 4025, 'flooding': 4026, 'discriminates': 4027, 'serena': 4028, 'williams': 4029, 'revealed': 4030, 'connection': 4031, 'jerusalem': 4032, 'infamous': 4033, 'gentleman': 4034, 'card': 4035, 'illegally': 4036, 'loser': 4037, 'cake': 4038, 'whale': 4039, 'norway': 4040, 'locals': 4041, 'gunman': 4042, 'kidnaps': 4043, 'activity': 4044, 'schooler': 4045, 'casually': 4046, 'switched': 4047, 'cheat': 4048, 'someday': 4049, 'millennials': 4050, 'unearth': 4051, 'hack': 4052, 'allow': 4053, 'pump': 4054, \"'straight\": 4055, 'pride': 4056, 'symbol': 4057, 'emmy': 4058, 'nomination': 4059, 'bradley': 4060, 'cooper': 4061, 'dnc': 4062, 'upset': 4063, 'birmingham': 4064, 'skip': 4065, 'phoenix': 4066, 'fallen': 4067, 'allergies': 4068, 'reconsider': 4069, 'hashtag': 4070, 'toronto': 4071, 'summer': 4072, 'hire': 4073, 'captain': 4074, 'dre': 4075, 'bucket': 4076, 'buys': 4077, 'records': 4078, 'trouble': 4079, 'blowing': 4080, 'icelandic': 4081, 'boulder': 4082, 'expect': 4083, 'proven': 4084, 'myself': 4085, 'saves': 4086, 'drowning': 4087, 'none': 4088, 'damn': 4089, 'driven': 4090, 'bristol': 4091, \"'for\": 4092, 'extinguisher': 4093, 'stein': 4094, 'cases': 4095, 'procedure': 4096, 'political': 4097, 'spell': 4098, \"'stop\": 4099, 'gps': 4100, 'flies': 4101, 'receipt': 4102, 'placed': 4103, 'covering': 4104, 'mayonnaise': 4105, \"'murder\": 4106, 'sends': 4107, '31': 4108, 'beaver': 4109, 'sixth': 4110, 'quarter': 4111, 'survey': 4112, 'lived': 4113, 'offenders': 4114, '51': 4115, 'stormy': 4116, 'cloud': 4117, 'spongebob': 4118, 'squarepants': 4119, 'housing': 4120, 'carson': 4121, 'confuses': 4122, 'estate': 4123, 'term': 4124, 'oreo': 4125, 'spite': 4126, 'shredding': 4127, 'fortune': 4128, 'network': 4129, 'gamestop': 4130, 'drake': 4131, 'stone': 4132, 'philip': 4133, 'hoffman': 4134, 'disgusted': 4135, 'mccain': 4136, 'captured': 4137, 'n.j.': 4138, 'millionaire': 4139, 'spiked': 4140, 'taxi': 4141, '5k': 4142, 'settles': 4143, 'kerry': 4144, 'shoves': 4145, 'democrat': 4146, 'meet': 4147, 'grows': 4148, 'evacuation': 4149, 'nationalists': 4150, 'streets': 4151, 'offices': 4152, 'tragic': 4153, 'attention': 4154, 'gaming': 4155, 'sailing': 4156, 'ps4': 4157, 'tila': 4158, 'tequila': 4159, 'walker': 4160, 'murdered': 4161, 'far-right': 4162, 'extremists': 4163, 'domino': 4164, 'russians': 4165, 'lifetime': 4166, 'pizzas': 4167, 'tattoos': 4168, \"'fire\": 4169, 'sauce': 4170, 'sears': 4171, 'tower': 4172, 'bold': 4173, 'groundbreaking': 4174, 'protagonist': 4175, 'bit': 4176, 'parole': 4177, 'bills': 4178, '3,000': 4179, 'mate': 4180, 'madden': 4181, 'chernobyl': 4182, 'coast': 4183, 'archbishop': 4184, 'cia': 4185, 'officially': 4186, 'denies': 4187, 'letter': 4188, 'horrifying': 4189, 'few': 4190, 'wisconsin': 4191, 'pours': 4192, 'roads': 4193, 'icy': 4194, 'conditions': 4195, 'fund': 4196, 'busted': 4197, 'marrying': 4198, 'divorcing': 4199, 'sudan': 4200, 'ebola': 4201, 'lands': 4202, 'picked': 4203, 'oversee': 4204, '250': 4205, 'acres': 4206, 'crown': 4207, 'mistake': 4208, 'hurting': 4209, 'nut': 4210, 'dessert': 4211, 'condemning': 4212, 'attacks': 4213, 'flush': 4214, 'teaching': 4215, 'sweating': 4216, 'relieved': 4217, 'tackled': 4218, 'jupiter': 4219, 'large': 4220, 'denuclearization': 4221, 'proposal': 4222, 'vegans': 4223, 'diet': 4224, 'juice': 4225, 'flavor': 4226, 'sonic': 4227, 'customers': 4228, 'create': 4229, 'taped': 4230, 'broken': 4231, 'southwest': 4232, 'regularly': 4233, 'happens': 4234, 'proud': 4235, 'trio': 4236, 'interior': 4237, 'ark': 4238, 'replica': 4239, 'damage': 4240, 'proposes': 4241, 'resolution': 4242, 'valuable': 4243, 'conditioning': 4244, '12-year-old': 4245, 'staring': 4246, 'yorkers': 4247, 'ticketed': 4248, 'dementia': 4249, 'hike': 4250, 'fights': 4251, '30k': 4252, 'locked': 4253, 'clearance': 4254, 'upside': 4255, 'sheep': 4256, 'grass': 4257, 'maintains': 4258, 'touch': 4259, 'ruins': 4260, 'dash': 4261, 'transgender': 4262, 'bathrooms': 4263, 'cupcakes': 4264, 'nike': 4265, 'runner': 4266, 'shoes': 4267, 'affordable': 4268, 'village': 4269, 'songs': 4270, 'testament': 4271, 'literally': 4272, 'thrones': 4273, 'content': 4274, 'suggesting': 4275, 'mobile': 4276, 'barely': 4277, 'escapes': 4278, '0': 4279, 'rotten': 4280, 'satisfied': 4281, 'conscience': 4282, 'ap': 4283, 'built': 4284, 'skyscrapers': 4285, 'replaces': 4286, 'octopus': 4287, 'seaworld': 4288, 'matter': 4289, 'dolphin': 4290, 'bankrupt': 4291, 'ancient': 4292, 'seinfeld': 4293, 'rogue': 4294, 'blamed': 4295, 'chaos': 4296, 'conversion': 4297, \"'cure\": 4298, 'jr.': 4299, 'elementary': 4300, 'dumps': 4301, 'cost': 4302, 'ontario': 4303, 'religious': 4304, 'beliefs': 4305, 'sunderland': 4306, 'trial': 4307, 'defeat': 4308, 'offensive': 4309, 'drain': 4310, 'infuriating': 4311, 'licks': 4312, 'cone': 4313, 'paper': 4314, 'simpson': 4315, 'chimp': 4316, 'planned': 4317, 'outage': 4318, 'switching': 4319, '80s': 4320, 'throwback': 4321, 'johnson': 4322, 'releasing': 4323, 'limited-edition': 4324, 'poison': 4325, 'puerto': 4326, 'rico': 4327, 'situation': 4328, 'remains': 4329, 'impossible': 4330, 'supporting': 4331, 'treaty': 4332, 'wo': 4333, 'fix': 4334, 'owned': 4335, 'honor': 4336, 'patriotic': 4337, 'spirit': 4338, 'english': 4339, 'bezos': 4340, 'divorce': 4341, 'settlement': 4342, 'successfully': 4343, 'trick': 4344, 'route': 4345, 'technology': 4346, 'snoop': 4347, 'dogg': 4348, 'antidepressant': 4349, 'expected': 4350, 'mess': 4351, 'a.m': 4352, 'rhetoric': 4353, 'except': 4354, 'control': 4355, 'demographic': 4356, 'daring': 4357, 'overnight': 4358, 'lifts': 4359, 'mop': 4360, 'cheeseburger': 4361, 'syrian': 4362, 'assad': 4363, 'parties': 4364, 'weapons': 4365, 'clickventure': 4366, 'chess': 4367, 'soup': 4368, 'swim': 4369, 'greet': 4370, 'travelers': 4371, 'francisco': 4372, 'chosen': 4373, 'publish': 4374, 'sources': 4375, 'finale': 4376, 'concludes': 4377, 'possessing': 4378, 'migrant': 4379, 'detention': 4380, 'penn': 4381, 'singing': 4382, 'sweet': 4383, 'lyrics': 4384, 'poses': 4385, 'dowry': 4386, 'swing': 4387, 'solitary': 4388, 'pretzel': 4389, 'gold': 4390, 'rush': 4391, '11-year-old': 4392, 'delivers': 4393, 'newt': 4394, 'gingrich': 4395, 'establish': 4396, 'colony': 4397, 'elected': 4398, 'dairy': 4399, 'rather': 4400, 'tossed': 4401, 'kansas': 4402, 'hq': 4403, 'bites': 4404, 'scots': 4405, 'bullied': 4406, 'apparently': 4407, 'losers': 4408, 'theories': 4409, 'buttigieg': 4410, 'speaking': 4411, 'manufacturing': 4412, 'gandhi': 4413, 'quote': 4414, 'saw': 4415, 'clickhole': 4416, 'feud': 4417, 'humanity': 4418, '26': 4419, 'athletes': 4420, 'closed': 4421, 'contractor': 4422, 'digging': 4423, 'hole': 4424, 'apparent': 4425, 'lined': 4426, 'frustrated': 4427, 'wildfire': 4428, 'l.a.': 4429, 'receiving': 4430, 'escape': 4431, 'scandal': 4432, '1970s': 4433, 'cheerleaders': 4434, 'eyed': 4435, 'peas': 4436, 'learned': 4437, 'points': 4438, 'businesses': 4439, 'operations': 4440, 'interrupted': 4441, 'bale': 4442, 'tory': 4443, 'indianapolis': 4444, 'pretended': 4445, 'rehab': 4446, 'al-qaeda': 4447, 'sydney': 4448, 'performance': 4449, 'proves': 4450, 'wings': 4451, 'supremacist': 4452, 'fined': 4453, 'snack': 4454, 'future': 4455, 'emma': 4456, 'watson': 4457, 'traveling': 4458, 'greek': 4459, 'trapped': 4460, 'illegal': 4461, 'uae': 4462, 'awakens': 4463, 'drifting': 4464, 'restroom': 4465, 'harvard': 4466, 'kennedy': 4467, 'colored': 4468, 'shirt': 4469, 'deter': 4470, 'nbc': 4471, 'bride': 4472, 'pooh': 4473, 'playground': 4474, 'protection': 4475, 'rep': 4476, 'worked': 4477, 'corner': 4478, 'presents': 4479, 'unpaid': 4480, 'beto': 4481, 'rourke': 4482, 'responsible': 4483, 'triangle': 4484, 'taser': 4485, 'nt': 4486, 'commissioner': 4487, 'camera': 4488, 'promotes': 4489, 'spain': 4490, 'submarine': 4491, 'dock': 4492, 'blockbuster': 4493, 'maple': 4494, 'syrup': 4495, 'recovered': 4496, 'easier': 4497, 'round': 4498, 'brazil': 4499, 'bolsonaro': 4500, 'pens': 4501, 'amid': 4502, 'spat': 4503, 'elephant': 4504, 'falls': 4505, 'snapchat': 4506, 'information': 4507, 'burgers': 4508, \"'are\": 4509, 'measles': 4510, 'outbreak': 4511, 'humiliated': 4512, 'bud': 4513, 'trespassing': 4514, 'budweiser': 4515, 'comcast': 4516, 'spying': 4517, 'ad': 4518, 'loses': 4519, 'grant': 4520, 'application': 4521, 'amc': 4522, 'rating': 4523, 'surface': 4524, 'grandpa': 4525, 'becomes': 4526, 'influencer': 4527, 'grandson': 4528, 'dresses': 4529, 'visitors': 4530, 'hairy': 4531, 'hill': 4532, 'facing': 4533, 'blaze': 4534, 'amherst': 4535, 'expelled': 4536, 'missile': 4537, 'defense': 4538, '30,000': 4539, 'feet': 4540, 'plumbers': 4541, '50,000': 4542, 'calgary': 4543, 'worse': 4544, 'felon': 4545, 'celebrities': 4546, 'venice': 4547, 'plunging': 4548, 'dmv': 4549, 'finishes': 4550, 'licenses': 4551, 'gender': 4552, 'stereotypes': 4553, 'age': 4554, 'slaves': 4555, 'pc': 4556, 'amok': 4557, 'fasting': 4558, 'punching': 4559, 'painting': 4560, 'rejoice': 4561, 'paramount': 4562, 'restoring': 4563, 'pockets': 4564, 'well': 4565, 'matching': 4566, 'playboy': 4567, 'available': 4568, 'exclusively': 4569, 'honey': 4570, 'boxes': 4571, 'tested': 4572, 'director': 4573, 'discrimination': 4574, 'belief': 4575, 'hospitalized': 4576, 'faith': 4577, 'emoji': 4578, 'tricked': 4579, 'blindfolded': 4580, 'eight': 4581, 'animal': 4582, 'counts': 4583, 'bully': 4584, 'usa': 4585, 'perform': 4586, 'khan': 4587, 'davis': 4588, 'begging': 4589, 'wyoming': 4590, 'reject': 4591, 'doomsday': 4592, 'lunches': 4593, 'soul': 4594, 'award': 4595, 'taylor': 4596, 'swift': 4597, 'ruin': 4598, 'memory': 4599, 'mediocre': 4600, 'afternoon': 4601, '1995': 4602, 'mentally': 4603, 'ken': 4604, 'doll': 4605, 'rotting': 4606, 'nose': 4607, 'angels': 4608, 'switzerland': 4609, 'wealthy': 4610, 'donors': 4611, 'last-ditch': 4612, 'effort': 4613, 'destroy': 4614, 'inconsiderate': 4615, 'smarter': 4616, 'investigation': 4617, 'steering': 4618, 'dating': 4619, 'popularity': 4620, 'soars': 4621, 'devotees': 4622, \"'an\": 4623, 'interesting': 4624, 'path': 4625, 'military': 4626, 'taiwan': 4627, 'funeral': 4628, 'miley': 4629, 'cyrus': 4630, 'flaming': 4631, 'finding': 4632, 'beyonce': 4633, 'tragedy': 4634, 'guinness': 4635, 'gin': 4636, 'pokemon': 4637, 'turf': 4638, 'prep': 4639, 'disneyland': 4640, 'rides': 4641, 'designed': 4642, 'cycle': 4643, 'monroe': 4644, 'donkey': 4645, 'lohan': 4646, 'arabic': 4647, 'readers': 4648, 'amber': 4649, 'alerts': 4650, 'option': 4651, 'text': 4652, 'yikes': 4653, \"'because\": 4654, 'eastern': 4655, 'insisting': 4656, 'sperm': 4657, '90s': 4658, 'expects': 4659, \"'just\": 4660, 'spin': 4661, 'willie': 4662, 'nelson': 4663, 'reserve': 4664, 'third-grader': 4665, 'biting': 4666, 'distracted': 4667, '5,000': 4668, 'melania': 4669, 'walls': 4670, 'chamber': 4671, 'itself': 4672, 'speaker': 4673, 'ain': 4674, 'tricks': 4675, 'dry': 4676, 'cleaner': 4677, 'conveyor': 4678, 'skeleton': 4679, 'acts': 4680, 'abc': 4681, 'corporation': 4682, 'semen': 4683, 'farted': 4684, 'pardons': 4685, 'epstein': 4686, 'level': 4687, 'countless': 4688, 'fifth': 4689, 'graders': 4690, 'damning': 4691, 'admitted': 4692, 'royalties': 4693, 'henry': 4694, 'sitting': 4695, 'keeping': 4696, 'deceased': 4697, 'messages': 4698, 'sponsor': 4699, 'argues': 4700, 'stores': 4701, \"'two\": 4702, 'van': 4703, 'lesson': 4704, 'detailed': 4705, 'upon': 4706, 'tactics': 4707, 'sponge': 4708, 'democracy': 4709, 'episodes': 4710, 'wing': 4711, 'creators': 4712, 'tased': 4713, 'stumped': 4714, 'live-in': 4715, 'grizzly': 4716, '4,000': 4717, 'wallace': 4718, \"'may\": 4719, 'agenda': 4720, 'surprises': 4721, 'craft': 4722, 'discussion': 4723, 'paypal': 4724, 'vegetarians': 4725, 'cheap': 4726, 'flood': 4727, 'patent': 4728, 'allergic': 4729, 'netflix': 4730, 'competition': 4731, 'reed': 4732, 'dangerous': 4733, 'dea': 4734, 'smuggle': 4735, 'spilled': 4736, 'services': 4737, 'sexting': 4738, 'photograph': 4739, 'explicit': 4740, 'lawyers': 4741, 'accountable': 4742, 'impeach': 4743, 'epic': 4744, 'ordeal': 4745, 'humiliation': 4746, 'cruelty': 4747, 'c': 4748, 'stabbed': 4749, 'tears': 4750, 'censors': 4751, 'responding': 4752, 'transparency': 4753, 'undocumented': 4754, 'powerless': 4755, 'buster': 4756, 'mlb': 4757, 'mumbai': 4758, 'murders': 4759, 'dancing': 4760, 'express': 4761, 'rescues': 4762, 'stranded': 4763, 'thankful': 4764, 'investigated': 4765, 'chuck': 4766, 'quarterback': 4767, 'ball': 4768, 'clock': 4769, 'lesbian': 4770, 'owl': 4771, 'admission': 4772, 'images': 4773, 'venus': 4774, 'horrified': 4775, 'column': 4776, 'holocaust': 4777, 'ny': 4778, 'daily': 4779, 'daughters': 4780, 'possessed': 4781, 'appreciation': 4782, 'organizer': 4783, 'honoring': 4784, 'legacy': 4785, 'numerals': 4786, 'taught': 4787, 'vs.': 4788, 'hookers': 4789, 'beats': 4790, 'kardashian': 4791, 'wolf': 4792, 'suggest': 4793, 'foster': 4794, 'paedophile': 4795, 'touched': 4796, 'glasgow': 4797, 'steam': 4798, 'launchers': 4799, 'achieve': 4800, 'donates': 4801, 'leg': 4802, 'explosion': 4803, 'hasn': 4804, 'element': 4805, 'roles': 4806, 'brews': 4807, 'cannabis': 4808, 'lauded': 4809, 'cowards': 4810, 'leadership': 4811, 'ceiling': 4812, 'tongue': 4813, 'fucks': 4814, 'names': 4815, 'cybersecurity': 4816, 'profile': 4817, 'scott': 4818, 'simultaneously': 4819, 'revealing': 4820, 'identities': 4821, 'nyc': 4822, 'replacing': 4823, 'bulbs': 4824, 'liberty': 4825, 'eyes': 4826, 'map': 4827, 'offence': 4828, 'remote': 4829, 'throwing': 4830, 'fries': 4831, 'farmer': 4832, 'branches': 4833, 'shaped': 4834, 'nutella': 4835, 'five-year-old': 4836, 'upcoming': 4837, 'role': 4838, 'raytheon': 4839, 'capable': 4840, 'poems': 4841, 'nutritionists': 4842, 'wouldn': 4843, 'ate': 4844, 'normal': 4845, 'stun': 4846, 'nottheonion': 4847, 'unhappy': 4848, 'haircut': 4849, 'barber': 4850, 'pd': 4851, 'leading': 4852, 'phony': 4853, 'squash': 4854, 'higher': 4855, 'cube': 4856, 'thrown': 4857, 'sink': 4858, 'restraining': 4859, 'kindergartner': 4860, '150': 4861, 'fucked-up': 4862, 'math': 4863, 'checkout': 4864, 'pompeo': 4865, 'tortured': 4866, 'crystal': 4867, 'dev': 4868, 'attempts': 4869, 'tensions': 4870, 'noting': 4871, 'anti-vaxxers': 4872, 'contains': 4873, 'gluten': 4874, 'make-a-wish': 4875, 'foundation': 4876, 'bon': 4877, 'jovi': 4878, 'chimney': 4879, 'ipad': 4880, 'urinal': 4881, 'watchdog': 4882, '1,500': 4883, 'secretly': 4884, 'satire': 4885, 'discovery': 4886, 'comfortable': 4887, 'position': 4888, 'mothers': 4889, 'closer': 4890, 'terrifying': 4891, 'resident': 4892, 'lions': 4893, 'scottish': 4894, 'pug': 4895, 'salute': 4896, 'lonely': 4897, 'bee': 4898, 'drones': 4899, '29': 4900, 'feature': 4901, 'wrap': 4902, 'imprison': 4903, 'oldest': 4904, 'pleased': 4905, 'born': 4906, 'patriot': 4907, 'tracking': 4908, 'excessive': 4909, 'immigration': 4910, 'apply': 4911, 'visa': 4912, 'luck': 4913, 'uganda': 4914, 'wastes': 4915, 'weekend': 4916, 'flips': 4917, '10m': 4918, 'arms': 4919, 'seatbelt': 4920, 'afterlife': 4921, 'televangelist': 4922, 'xi': 4923, 'jinping': 4924, 'bun': 4925, 'nervous': 4926, 'incompetent': 4927, 'doubles': 4928, 'squeeze': 4929, 'yourself': 4930, 'eminem': 4931, 'wind': 4932, 'occurred': 4933, 'vegetables': 4934, 'flash': 4935, 'stanford': 4936, 'tuition': 4937, 'whose': 4938, 'evangelical': 4939, 'megachurch': 4940, 'closing': 4941, 'miss': 4942, 'delaware': 4943, 'panini': 4944, 'pupil': 4945, 'violates': 4946, 'belonged': 4947, 'bouncer': 4948, 'inauguration': 4949, 'crowds': 4950, 'settling': 4951, 'partner': 4952, 'soulmate': 4953, 'instructed': 4954, 'barron': 4955, 'parade': 4956, 'float': 4957, '5th': 4958, 'holiday': 4959, 'kickstarter': 4960, 'legalizing': 4961, 'phelps': 4962, 'tasting': 4963, 'effective': 4964, 'knock': 4965, 'charlotte': 4966, 'unarmed': 4967, '37': 4968, 'contract': 4969, 'superheroes': 4970, 'functioning': 4971, 'anus': 4972, 'testing': 4973, 'promote': 4974, 'mailbox': 4975, 'mail': 4976, 'fucked': 4977, 'zebra': 4978, 'carry': 4979, 'vr': 4980, 'chat': 4981, 'babies': 4982, 'innocent': 4983, 'forest': 4984, 'proving': 4985, 'idiots': 4986, \"'died\": 4987, '27': 4988, 'liberals': 4989, 'counsel': 4990, 'fit': 4991, 'rnc': 4992, 'endorses': 4993, 'scumbag': 4994, 'enforcement': 4995, 'chocolate': 4996, 'phones': 4997, 'tone': 4998, 'patriots': 4999, 'beginning': 5000, 'huddle': 5001, 'ethical': 5002, 'identifies': 5003, 'accounts': 5004, 'seemingly': 5005, 'enjoying': 5006, 'curse': 5007, 'mrs.': 5008, 'ape': 5009, 'harambe': 5010, '100k': 5011, 'lawrence': 5012, 'motorist': 5013, 'rage': 5014, 'arson': 5015, 'ripping': 5016, '1950s': 5017, 'myth': 5018, 'sick': 5019, 'pathetic': 5020, 'maybe': 5021, 'sort': 5022, 'japan': 5023, 'brazilian': 5024, 'goalkeeper': 5025, 'alps': 5026, 'attraction': 5027, 'rainbow': 5028, 'lgbtq': 5029, 'cheering': 5030, 'biology': 5031, 'arresting': 5032, 'principal': 5033, 'disappointed': 5034, 'genetically': 5035, 'engineer': 5036, 'lab': 5037, 'adding': 5038, 'seal': 5039, 'surprising': 5040, 'perfect': 5041, 'tommy': 5042, 'hosts': 5043, 'exchange': 5044, 'compares': 5045, 'luther': 5046, 'wasting': 5047, 'screens': 5048, 'mandatory': 5049, 'harm': 5050, 'morgue': 5051, '450': 5052, 'firework': 5053, 'managed': 5054, 'deniers': 5055, 'seconds': 5056, 'dialogue': 5057, 'spread': 5058, '200': 5059, 'rushed': 5060, 'speak': 5061, 'bay': 5062, 'maintain': 5063, 'advantage': 5064, 'weighing': 5065, 'santorum': 5066, 'suspend': 5067, 'sense': 5068, 'monthly': 5069, 'confession': 5070, 'miraculously': 5071, 'surgically': 5072, 'hopefully': 5073, 'robin': 5074, 'hood': 5075, 'development': 5076, 'rip': 5077, 'whoever': 5078, 'towels': 5079, 'piano': 5080, 'ea': 5081, 'han': 5082, 'solo': 5083, 'dangers': 5084, 'veins': 5085, 'motorists': 5086, 'zone': 5087, 'hip-hop': 5088, 'spider': 5089, 'marshawn': 5090, 'lynch': 5091, 'trademark': 5092, 'digital': 5093, 'simulation': 5094, 'understanding': 5095, 'fill': 5096, 'demonic': 5097, 'lights': 5098, 'push': 5099, 'rebrand': 5100, 'alert': 5101, 'believed': 5102, 'porsche': 5103, 'commander': 5104, 'third': 5105, 'crocodile': 5106, 'operate': 5107, 'memo': 5108, 'kentucky': 5109, 'elects': 5110, 'python': 5111, 'amount': 5112, 'stress': 5113, 'carried': 5114, 'dept': 5115, 'scammed': 5116, 'gamer': 5117, 'witnesses': 5118, 'crack': 5119, 'smile': 5120, 'nurse': 5121, 'flu': 5122, 'attendance': 5123, 'pelosi': 5124, 'reputation': 5125, 'irs': 5126, 'period': 5127, 'golf': 5128, 'trophy': 5129, 'oceans': 5130, 'unless': 5131, 'condoms': 5132, 'homemade': 5133, 'firearm': 5134, 'sunscreen': 5135, 'ok': 5136, 'passed': 5137, 'asleep': 5138, 'theft': 5139, 'joy': 5140, 'bubble': 5141, 'misplaced': 5142, '20,000': 5143, 'excuse': 5144, '«': 5145, 'grade': 5146, 'bittorrent': 5147, 'dummies': 5148, 'stoner': 5149, 'forms': 5150, 'via': 5151, 'circus': 5152, 'clowns': 5153, 'offended': 5154, 'politicians': 5155, 'spanking': 5156, 'ejaculation': 5157, 'legendary': 5158, 'racehorse': 5159, 'nudist': 5160, 'issue': 5161, 'stumbles': 5162, 'childhood': 5163, 'drawings': 5164, 'graphic': 5165, 'trusted': 5166, 'cable': 5167, 'pirates': 5168, 'winners': 5169, 'surveillance': 5170, 'cameras': 5171, 'shootings': 5172, 'protecting': 5173, 'freedom': 5174, 'rex': 5175, \"'bad\": 5176, 'thieves': 5177, '25,000': 5178, 'festival': 5179, 't-shirts': 5180, 'opposes': 5181, 'citing': 5182, 'montana': 5183, 'bartender': 5184, 'tomato': 5185, 'seagulls': 5186, 'leftover': 5187, 'booze': 5188, 'firefighters': 5189, 'horses': 5190, 'disorder': 5191, 'miniature': 5192, 'burst': 5193, 'roger': 5194, 'ailes': 5195, 'cam': 5196, 'committing': 5197, 'screening': 5198, '19-year-old': 5199, 'committee': 5200, 'dinner': 5201, 'stunning': 5202, 'shrieking': 5203, 'crows': 5204, 'clips': 5205, 'magical': 5206, 'possible': 5207, 'blast': 5208, 'terrorism': 5209, 'cockroaches': 5210, 'hateful': 5211, 'trailer': 5212, 'stephen': 5213, 'professional': 5214, 'lock': 5215, 'exist': 5216, 'mayo': 5217, 'tour': 5218, '2010': 5219, 'spotting': 5220, 'sickness': 5221, 'elton': 5222, 'solid': 5223, 'pilots': 5224, 'complaining': 5225, 'needles': 5226, 'example': 5227, 'wolfgang': 5228, 'puck': 5229, 'monica': 5230, 'lewinsky': 5231, 'd': 5232, 'gown': 5233, 'warned': 5234, 'drought': 5235, 'armstrong': 5236, 'phrase': 5237, 'breakup': 5238, 'hilarious': 5239, 'booed': 5240, 'tony': 5241, 'abbott': 5242, 'bowling': 5243, 'barn': 5244, 'cans': 5245, 'tuna': 5246, 'belichick': 5247, 'greatest': 5248, 'drop': 5249, 'anxious': 5250, 'forgotten': 5251, 'ground': 5252, 'launched': 5253, 'complains': 5254, 'oscars': 5255, 'base': 5256, 'arctic': 5257, 'duncan': 5258, 'marine': 5259, 'lou': 5260, 'tons': 5261, 'weezer': 5262, 'soldier': 5263, 'twisting': 5264, 'impregnated': 5265, \"'women\": 5266, 'silence': 5267, 'injury': 5268, 'soviet': 5269, 'formed': 5270, 'combat': 5271, 'garbage': 5272, 'loaded': 5273, 'floating': 5274, 'apex': 5275, 'predator': 5276, 'rescued': 5277, 'rescuing': 5278, 'increases': 5279, 'productivity': 5280, 'malaysian': 5281, 'devotion': 5282, 'preacher': 5283, 'followers': 5284, 'pet': 5285, 'driveway': 5286, 'biblical': 5287, 'scholars': 5288, 'molested': 5289, 'exonerated': 5290, 'develop': 5291, 'apps': 5292, 'bureau': 5293, 'chemicals': 5294, 'fast': 5295, 'kevin': 5296, 'somebody': 5297, 'noticing': 5298, 'councilman': 5299, 'applies': 5300, '80-year-old': 5301, 'cane': 5302, 'surprise': 5303, 'hatred': 5304, 'sides': 5305, 'jay-z': 5306, 'whales': 5307, 'sight': 5308, 'catching': 5309, 'payout': 5310, 'italians': 5311, 'pieces': 5312, 'timeline': 5313, 'relationships': 5314, 'detective': 5315, 'zodiac': 5316, 'dealer': 5317, 'la': 5318, 'inn': 5319, 'naughty': 5320, 'f': 5321, 'bounces': 5322, 'theoretical': 5323, 'physicists': 5324, 'b': 5325, 'meaning': 5326, 'solely': 5327, 'dean': 5328, 'defensive': 5329, 'laura': 5330, 'prominent': 5331, 'including': 5332, 'supremacists': 5333, 'seems': 5334, 'complex': 5335, 'savings': 5336, 'helped': 5337, '25': 5338, 'peta': 5339, 'elephants': 5340, 'difficult': 5341, 'grisly': 5342, 'peter': 5343, 'jackson': 5344, 'pole': 5345, 'jigsaw': 5346, 'puzzles': 5347, 'dreams': 5348, 'web': 5349, 'underneath': 5350, 'yellowstone': 5351, \"'nobody\": 5352, 'extinct': 5353, 'weapon': 5354, 'gatorade': 5355, 'bottles': 5356, 'stairs': 5357, 'gorilla': 5358, 'hook': 5359, 'representative': 5360, 'michele': 5361, 'citizen': 5362, 'criticism': 5363, 'mar-a-lago': 5364, 'trips': 5365, 'spicer': 5366, 'searching': 5367, 'operator': 5368, 'nobody': 5369, 'hangs': 5370, 'explorer': 5371, 'booth': 5372, 'horrible': 5373, 'tillerson': 5374, 'withdraw': 5375, 'improve': 5376, 'underpaying': 5377, 'standing': 5378, 'whenever': 5379, '2015': 5380, 'committed': 5381, 'responsibility': 5382, 'zuckerberg': 5383, 'articles': 5384, 'generating': 5385, 'revenue': 5386, 'criminal': 5387, 'decision': 5388, 'sweat': 5389, 'miami': 5390, 'fell': 5391, 'flat': 5392, '35,000': 5393, 'beef': 5394, 'spacex': 5395, 'falcon': 5396, 'rocket': 5397, 'backyard': 5398, 'referring': 5399, 'paedophiles': 5400, 'warrants': 5401, 'watches': 5402, 'checks': 5403, 'waitress': 5404, 'naacp': 5405, 'first-ever': 5406, 'welcome': 5407, 'satanic': 5408, 'expose': 5409, 'infinite': 5410, 'bribery': 5411, 'warriors': 5412, 'seem': 5413, 'aldi': 5414, 'packets': 5415, 'rings': 5416, 'legs': 5417, '2001': 5418, 'immediate': 5419, 'grown': 5420, 'nsw': 5421, 'matters': 5422, 'stalls': 5423, 'shits': 5424, 'suspension': 5425, 'alt-right': 5426, 'papa': 5427, \"'super\": 5428, 'samaritan': 5429, 'ditch': 5430, 'pony': 5431, 'climbs': 5432, 'tall': 5433, 'poops': 5434, 'mannequin': 5435, 'river': 5436, 'tortoise': 5437, 'u.n.': 5438, 'ambassador': 5439, 'mandela': 5440, 'desperately': 5441, 'curiosity': 5442, 'rover': 5443, 'bucks': 5444, 'czech': 5445, 'burns': 5446, 'dildo': 5447, 'winning': 5448, '£30,000': 5449, '£100': 5450, 'burglars': 5451, 'high-speed': 5452, 'consumption': 5453, 'pop': 5454, 'duo': 5455, 'winter': 5456, 'counterfeit': 5457, 'herd': 5458, 'drunken': 5459, 'mixed-race': 5460, 'electronic': 5461, 'monitoring': 5462, 'escaping': 5463, 'schedule': 5464, 'total': 5465, 'mystery': 5466, 'ellen': 5467, 'degeneres': 5468, '500,000': 5469, 'poorly': 5470, 'require': 5471, 'document': 5472, \"'you\": 5473, 'flock': 5474, 'gods': 5475, 'add': 5476, 'pill': 5477, 'massachusetts': 5478, 'crocodiles': 5479, 'guarding': 5480, 'amsterdam': 5481, 'eve': 5482, 'spots': 5483, 'heaven': 5484, 'sucking': 5485, 'determine': 5486, 'joe': 5487, 'style': 5488, 'temporarily': 5489, 'closes': 5490, 'michigan': 5491, 'ignore': 5492, 'mic': 5493, 'nest': 5494, 'gear': 5495, 'bowie': 5496, 'dc': 5497, '120,000': 5498, 'attract': 5499, 'fail': 5500, 'filmed': 5501, 'stewart': 5502, 'accident': 5503, 'documents': 5504, 'tampons': 5505, 'currently': 5506, 'devastating': 5507, 'dipshit': 5508, 'idaho': 5509, 'vodka': 5510, 'label': 5511, 'natural': 5512, 'gross': 5513, 'spiders': 5514, 'pleasure': 5515, 'simply': 5516, 'youths': 5517, 'busy': 5518, 'reunification': 5519, 'eerie': 5520, 'soy': 5521, 'adidas': 5522, 'launches': 5523, 'vomit': 5524, 'punishing': 5525, 'cords': 5526, 'catches': 5527, 'wasn': 5528, 'positivity': 5529, 'alexandria': 5530, 'ocasio-cortez': 5531, 'pearl': 5532, 'punches': 5533, '47': 5534, 'terrified': 5535, 'rubio': 5536, 'rudy': 5537, 'investors': 5538, 'adults': 5539, 'maker': 5540, 'skeletons': 5541, 'installs': 5542, 'mirror': 5543, 'misery': 5544, 'calf': 5545, 'artwork': 5546, 'shots': 5547, 'breed': 5548, 'badass': 5549, 'seeking': 5550, 'unknown': 5551, 'actress': 5552, 'affair': 5553, 'strikes': 5554, 'xbox': 5555, 'suck': 5556, 'robs': 5557, 'ring': 5558, 'bury': 5559, 'butter': 5560, 'planet': 5561, 'lobbying': 5562, 'aryan': 5563, 'brotherhood': 5564, 'broadcast': 5565, 'panda': 5566, 'obese': 5567, 'manatees': 5568, 'burning': 5569, 'd.c.': 5570, 'nick': 5571, 'sir': 5572, 'classical': 5573, 'exam': 5574, 'pruitt': 5575, '1st': 5576, 'armored': 5577, 'division': 5578, 'orgy': 5579, 'disabled': 5580, 'drives': 5581, 'zealand': 5582, 'grip': 5583, 'sucked': 5584, 'regret': 5585, 'manhattan': 5586, 'handicapped': 5587, 'meditation': 5588, 'reduce': 5589, 'advice': 5590, 'basis': 5591, 'disqualified': 5592, '6-year-old': 5593, 'tantrum': 5594, 'stupid': 5595, 'ravens': 5596, 'endorsement': 5597, 'score': 5598, 'bugs': 5599, 'bunny': 5600, 'shape': 5601, 'recording': 5602, 'dolls': 5603, 'production': 5604, 'sadly': 5605, 'locker': 5606, 'patriothole': 5607, 'profit': 5608, 'clown': 5609, 'posse': 5610, 'organising': 5611, '98': 5612, 'personally': 5613, 'chances': 5614, 'charlie': 5615, 'sheen': 5616, \"'call\": 5617, 'denial': 5618, 'literary': 5619, 'historians': 5620, 'uncover': 5621, 'edgar': 5622, 'lego': 5623, 'detains': 5624, 'shopping': 5625, 'homophobic': 5626, 'bigots': 5627, 'ukraine': 5628, 'crimea': 5629, 'coworkers': 5630, 'drinks': 5631, 'lsd': 5632, 'negative': 5633, 'knowledge': 5634, 'staffer': 5635, 'influence': 5636, 'notices': 5637, 'zimbabwean': 5638, 'highest': 5639, 'e.': 5640, 'attendant': 5641, 'stockton': 5642, 'pro-beijing': 5643, 'considers': 5644, 'hong': 5645, 'kong': 5646, 'nobel': 5647, 'prize': 5648, 'redskins': 5649, 'departing': 5650, 'loyal': 5651, 'bail': 5652, 'nigerian': 5653, 'murderers': 5654, 'unit': 5655, 'queer': 5656, '92-year-old': 5657, 'trudeau': 5658, 'blackface': 5659, 'triggered': 5660, 'slogan': 5661, 'ruth': 5662, 'bader': 5663, 'ginsburg': 5664, \"'was\": 5665, 'sober': 5666, 'weinstein': 5667, 'lauer': 5668, 'starring': 5669, 'regular': 5670, 'circles': 5671, 'zombies': 5672, 'legally': 5673, 'swallowing': 5674, 'forgetting': 5675, 'billy': 5676, 'ray': 5677, 'guests': 5678, 'wonder': 5679, 'amtrak': 5680, 'elevator': 5681, 'handgun': 5682, 'pointer': 5683, 'foreign': 5684, 'delegates': 5685, 'cruiser': 5686, 'surgeon': 5687, 'collect': 5688, 'paycheck': 5689, 'printed': 5690, 'nato': 5691, 'handed': 5692, 'damon': 5693, 'urging': 5694, 'statistics': 5695, 'fear': 5696, 'sail': 5697, 'greece': 5698, 'urge': 5699, 'evolved': 5700, 'fingers': 5701, 'dropping': 5702, 'stuff': 5703, 'journalism': 5704, 'twin': 5705, 'climbed': 5706, 'unborn': 5707, 'meghan': 5708, 'markle': 5709, 'adoption': 5710, 'engaged': 5711, 'played': 5712, 'sacked': 5713, 'late': 5714, 'lottery': 5715, 'seized': 5716, 'certain': 5717, 'pacific': 5718, 'amelia': 5719, 'earhart': 5720, 'awkward': 5721, 'pork': 5722, 'avocados': 5723, 'tomorrow': 5724, 'define': 5725, 'gateway': 5726, 'prosthetic': 5727, 'arm': 5728, 'jazz': 5729, 'seats': 5730, 'slides': 5731, 'kremlin': 5732, 'carbon': 5733, 'repeal': 5734, 'achievement': 5735, 'prosecute': 5736, 'ecuadorian': 5737, 'julian': 5738, 'assange': 5739, 'dishes': 5740, 'embassy': 5741, 'mode': 5742, 'captures': 5743, 'model': 5744, 'hit-and-run': 5745, 'misuse': 5746, 'funds': 5747, '77': 5748, 'user': 5749, 'donations': 5750, 'entry': 5751, 'talked': 5752, 'suicidal': 5753, 'vegetarian': 5754, 'rave': 5755, 'rand': 5756, 'stage': 5757, 'below': 5758, 'pure': 5759, 'detail': 5760, 'bullets': 5761, 'athlete': 5762, 'prevented': 5763, '737': 5764, 'bombing': 5765, 'cursed': 5766, 'join': 5767, 'shipping': 5768, 'designated': 5769, 'interested': 5770, 'accusations': 5771, 'sees': 5772, 'perfectly': 5773, 'mayoral': 5774, \"'go\": 5775, 'honour': 5776, 'beings': 5777, 'low': 5778, 'poised': 5779, 'comedy': 5780, '2005': 5781, 'associated': 5782, 'considering': 5783, \"'do\": 5784, 'block': 5785, 'ambulance': 5786, 'drumpf': 5787, 'stripper': 5788, 'triggers': 5789, 'panic': 5790, 'frankfurt': 5791, 'celebrate': 5792, 'thanksgiving': 5793, 'upstate': 5794, 'dumping': 5795, 'bed': 5796, 'bath': 5797, 'often': 5798, 'hardest': 5799, 'demon': 5800, 'sidewalk': 5801, 'decline': 5802, 'churches': 5803, 'marco': 5804, 'cooking': 5805, 'rangers': 5806, 'ukip': 5807, 'hackers': 5808, 'censoring': 5809, 'voices': 5810, 'torrent': 5811, 'kobe': 5812, 'bryant': 5813, 'freak': 5814, 'scheme': 5815, 'daycare': 5816, 'encouraging': 5817, 'cows': 5818, 'mountain': 5819, 'cabin': 5820, 'pub': 5821, 'crisps': 5822, 'hogan': 5823, 'intersection': 5824, 'gary': 5825, 'irwin': 5826, 'passport': 5827, 'violent': 5828, 'instructions': 5829, 'gwyneth': 5830, 'paltrow': 5831, 'dedicated': 5832, 'doomed': 5833, 'rabbit': 5834, 'mix-up': 5835, 'ladder': 5836, 'academy': 5837, 'pie': 5838, 'trillion': 5839, 'interrogated': 5840, 'fyre': 5841, 'feral': 5842, 'speaks': 5843, 'berlin': 5844, 'barking': 5845, 'endless': 5846, 'peaceful': 5847, 'silent': 5848, 'infringement': 5849, 'criminals': 5850, 'genitals': 5851, 'barbie': 5852, 'proportions': 5853, 'execute': 5854, 'asian': 5855, 'match': 5856, 'suits': 5857, 'boom': 5858, 'coin': 5859, 'tosses': 5860, 'fascists': 5861, 'dozen': 5862, 'resigned': 5863, 'matrix': 5864, 'silicon': 5865, 'tech': 5866, 'non-white': 5867, 'defendant': 5868, 'teenager': 5869, 'alcohol': 5870, 'shops': 5871, 'views': 5872, 'blizzard': 5873, 'tribe': 5874, 'thrilled': 5875, 'jeffrey': 5876, 'lenient': 5877, 'plea': 5878, 'minecraft': 5879, 'recruiting': 5880, 'tools': 5881, 'nh': 5882, 'assumed': 5883, 'purity': 5884, 'mdma': 5885, 'freeway': 5886, 'milwaukee': 5887, 'monsters': 5888, 'permit': 5889, 'counter': 5890, 'damaging': 5891, 'recordings': 5892, 'confesses': 5893, 'orleans': 5894, 'atm': 5895, 'ammo': 5896, 'murdering': 5897, \"'my\": 5898, 'writer': 5899, 'separation': 5900, 'struggle': 5901, 'punch': 5902, 'homeopathy': 5903, 'treating': 5904, 'runaway': 5905, 'bull': 5906, 'jon': 5907, 'musicians': 5908, 'included': 5909, 'shaq': 5910, \"'racist\": 5911, 'legislator': 5912, 'detained': 5913, 'sanitary': 5914, 'theatre': 5915, 'pikachu': 5916, 'wondering': 5917, 'mental': 5918, 'tribunal': 5919, '90': 5920, 'hopes': 5921, 'global': 5922, 'warming': 5923, 'swearing': 5924, 'expectancy': 5925, '23': 5926, 'motor': 5927, 'explain': 5928, 'portrayed': 5929, 'tag': 5930, 'invented': 5931, 'sport': 5932, 'nuggets': 5933, 'jerry': 5934, \"'make\": 5935, 'yard': 5936, 'donation': 5937, 'buffalo': 5938, 'spill': 5939, 'crying': 5940, 'concussion': 5941, 'brains': 5942, 'dramatically': 5943, 'ninja': 5944, 'turtles': 5945, 'downing': 5946, 'larry': 5947, 'expand': 5948, 'philippine': 5949, 'mall': 5950, 'women-only': 5951, 'wider': 5952, '2024': 5953, 'scraps': 5954, 'adultery': 5955, 'condom': 5956, 'stock': 5957, 'limbaugh': 5958, 'rips': 5959, 'dragons': 5960, 'monster': 5961, '4th': 5962, 'parrot': 5963, 'cries': 5964, 'ministry': 5965, 'investigate': 5966, 'editors': 5967, 'jay': 5968, 'gruden': 5969, 'plus-size': 5970, 'pat': 5971, 'practice': 5972, 'antonio': 5973, 'termination': 5974, 'jonah': 5975, 'snorting': 5976, 'screen': 5977, 'featuring': 5978, 'oprah': 5979, 'invites': 5980, 'trophies': 5981, 'correcting': 5982, 'feminists': 5983, '2013': 5984, 'brags': 5985, 'disciplined': 5986, 'knife-wielding': 5987, 'litter': 5988, 'angered': 5989, 'curling': 5990, 'crazy': 5991, 'seller': 5992, 'scientology': 5993, 'premarital': 5994, 'ongoing': 5995, 'afghanistan': 5996, 'defending': 5997, 'handshake': 5998, 'flipping': 5999, 'surrounded': 6000, 'dumped': 6001, 'comparing': 6002, 'oscar': 6003, 'instructor': 6004, 'lindsay': 6005, 'spokesperson': 6006, 'lgbt': 6007, 'dance': 6008, 'advance': 6009, 'tape': 6010, 'wrongdoing': 6011, 'fools': 6012, 'disguise': 6013, 'obamas': 6014, 'strongly': 6015, 'malia': 6016, 'toward': 6017, 'witness': 6018, 'repeats': 6019, 'cope': 6020, 'impatient': 6021, 'starkist': 6022, 'boobs': 6023, 'convictions': 6024, 'ones': 6025, 'boomers': 6026, 'draining': 6027, 'openly': 6028, 'criticized': 6029, 'owns': 6030, 'bald': 6031, 'sewer': 6032, 'draw': 6033, 'deny': 6034, 'torches': 6035, 'carve': 6036, 'forehead': 6037, 'baker': 6038, 'fracking': 6039, 'coupons': 6040, 'vibrator': 6041, 'ashes': 6042, 'lazy': 6043, 'highlights': 6044, 'defend': 6045, 'imagine': 6046, 'dates': 6047, 'trauma': 6048, 'shoe': 6049, 'manager': 6050, 'hooters': 6051, 'blank': 6052, 'monday': 6053, 'nicolas': 6054, 'cage': 6055, 'in-flight': 6056, 'waldo': 6057, 'pothole': 6058, 'coat': 6059, 'accidents': 6060, 'upsets': 6061, 'seniors': 6062, 'stopping': 6063, 'scrambles': 6064, 'deals': 6065, 'justify': 6066, 'blaming': 6067, 'salt': 6068, 'lick': 6069, 'exxonmobil': 6070, 'species': 6071, 'seize': 6072, 'hedgehog': 6073, 'sausages': 6074, 'biscuit': 6075, 'doncaster': 6076, 'cookie': 6077, 'unfazed': 6078, 'peach': 6079, 'heroic': 6080, 'edge': 6081, 'purchasing': 6082, 'install': 6083, 'pcs': 6084, 'remembering': 6085, 'honorary': 6086, 'plotting': 6087, '94': 6088, 'upstairs': 6089, 'bosses': 6090, 'showers': 6091, 'peacock': 6092, 'mermaid': 6093, 'kidnapper': 6094, 'pleasantly': 6095, 'ransom': 6096, 'cutting': 6097, 'financially': 6098, 'fundraising': 6099, 'riot': 6100, 'till': 6101, 'forbidden': 6102, 'electric': 6103, 'vehicles': 6104, \"'like\": 6105, 'positions': 6106, 'threesome': 6107, 'volunteer': 6108, 'frat': 6109, 'intervention': 6110, 'programs': 6111, 'shelter': 6112, 'casino': 6113, 'heist': 6114, 'vegas': 6115, 'forgive': 6116, 'loans': 6117, 'brands': 6118, 'palestinians': 6119, 'gaza': 6120, 'screams': 6121, 'bitch': 6122, '7-year-old': 6123, 'nagging': 6124, 'usain': 6125, 'bolt': 6126, '43': 6127, 'simpsons': 6128, 'arab': 6129, 'unnecessary': 6130, 'mentions': 6131, 'nickname': 6132, 'comedian': 6133, 'roast': 6134, 'anne': 6135, 'bench': 6136, 'installed': 6137, 'changes': 6138, 'mind': 6139, 'arrive': 6140, 'grilled': 6141, 'monitor': 6142, 'complained': 6143, 'medal': 6144, 'bringing': 6145, 'penis-shaped': 6146, 'crusader': 6147, 'morris': 6148, 'raffle': 6149, 'sweepstakes': 6150, 'vulnerable': 6151, 'pressure': 6152, 'morale': 6153, 'worrying': 6154, 'washer': 6155, 'colleague': 6156, 'rectum': 6157, 'unicorn': 6158, 'lair': 6159, 'pyongyang': 6160, 'four-year-old': 6161, 'memes': 6162, '120': 6163, 'survival': 6164, 'paint': 6165, 'plead': 6166, 'barbra': 6167, 'streisand': 6168, 'dressing': 6169, 'bomb': 6170, 'adviser': 6171, 'anderson': 6172, 'grounds': 6173, 'confirmed': 6174, 'kit': 6175, 'treat': 6176, '6-day': 6177, 'sneak': 6178, 'planes': 6179, 'twice': 6180, 'tourists': 6181, 'suddenly': 6182, 'worry': 6183, 'shouting': 6184, 'loudly': 6185, 'outlaws': 6186, 'gluten-free': 6187, 'waits': 6188, 'duke': 6189, 'revolutionary': 6190, 'tiny': 6191, 'hawk': 6192, 'slur': 6193, 'radical': 6194, 'islamic': 6195, 'gap': 6196, 'weigh': 6197, 'counting': 6198, 'chasing': 6199, \"o'reilly\": 6200, 'kenyan': 6201, 'troopers': 6202, 'civilian': 6203, '3000': 6204, 'horseback': 6205, 'cabinet': 6206, 'absence': 6207, 'calm': 6208, 'apologise': 6209, 'shout': 6210, 'exercise': 6211, 'freezer': 6212, 'stored': 6213, 'whoa': 6214, 'morgan': 6215, 't-shirt': 6216, 'stamps': 6217, 'confuse': 6218, 'fines': 6219, 'tirade': 6220, 'feared': 6221, 'infinity': 6222, 'ak-47': 6223, 'ebay': 6224, 'complimentary': 6225, 'upgrades': 6226, 'biological': 6227, 'differences': 6228, 'cash-strapped': 6229, 'conduct': 6230, 'deaths': 6231, 'jake': 6232, 'wiped': 6233, 'koreans': 6234, 'relax': 6235, 'villain': 6236, 'coke': 6237, 'formula': 6238, 'intercourse': 6239, 'spike': 6240, 'cubs': 6241, 'montreal': 6242, 'regulation': 6243, 'pants': 6244, 'politically': 6245, 'stomach': 6246, 'er': 6247, 'gorsuch': 6248, 'showering': 6249, 'manufacture': 6250, 'laptop': 6251, 'chips': 6252, 'burglary': 6253, 'friendly': 6254, 'hears': 6255, 'ten': 6256, \"'trying\": 6257, 'saskatchewan': 6258, 'sings': 6259, 'unconstitutional': 6260, 'golden': 6261, '3d': 6262, 'printer': 6263, 'punxsutawney': 6264, 'beheaded': 6265, 'inaccurate': 6266, 'groundhog': 6267, 'proper': 6268, \"'told\": 6269, 'zach': 6270, '250,000': 6271, 'everyday': 6272, 'makeup': 6273, 'transform': 6274, 'austrian': 6275, 'hugging': 6276, 'steel': 6277, 'drum': 6278, 'refusing': 6279, 'oppose': 6280, 'hacked': 6281, 'definition': 6282, 'dam': 6283, 'annoying': 6284, 'steps': 6285, 'prophet': 6286, 'muhammad': 6287, 'so-called': 6288, 'incredibly': 6289, 'generous': 6290, 'auto': 6291, 'welfare': 6292, 'recipients': 6293, 'crooked': 6294, 'framed': 6295, 'dealing': 6296, 'legalize': 6297, 'nationwide': 6298, 'blue': 6299, 'uproar': 6300, 'extreme': 6301, 'right-wing': 6302, 'resistance': 6303, 'serious': 6304, 'kits': 6305, 'raw': 6306, 'twerk': 6307, 'hostage': 6308, 'usc': 6309, 'background': 6310, 'shocks': 6311, 'century': 6312, 'longtime': 6313, 'aaron': 6314, 'informed': 6315, 'costco': 6316, 'deploys': 6317, 'modern-day': 6318, 'vehicle': 6319, 'met': 6320, 'advises': 6321, 'marketers': 6322, 'remind': 6323, 'eats': 6324, 'slips': 6325, 'real-life': 6326, 'fleet': 6327, 'harness': 6328, 'debates': 6329, 'fuel': 6330, 'returned': 6331, 'cleared': 6332, 'fearing': 6333, 'anti-semitism': 6334, 'bison': 6335, 'herman': 6336, 'cain': 6337, 'colbert': 6338, 'self-driving': 6339, 'chairs': 6340, 'crow': 6341, 'pan': 6342, 'unaware': 6343, 'horribly': 6344, 'invents': 6345, 'cooker': 6346, 'tripping': 6347, 'cape': 6348, 'genocide': 6349, 'lincoln': 6350, 'evangelicals': 6351, 'motorcade': 6352, '400': 6353, 'creation': 6354, 'croatia': 6355, 'colleagues': 6356, 'femen': 6357, 'kidnap': 6358, 'gangs': 6359, 'hawking': 6360, 'programmed': 6361, 'flights': 6362, 'luggage': 6363, 'brief': 6364, 'entering': 6365, 'foreigners': 6366, 'hide': 6367, 'funerals': 6368, 'sailor': 6369, 'raping': 6370, 'witchcraft': 6371, 'cities': 6372, 'elsa': 6373, 'starving': 6374, 'rhino': 6375, 'out-of-control': 6376, 'angel': 6377, 'bystanders': 6378, 'virginity': 6379, 'never-ending': 6380, 'amputee': 6381, 'known': 6382, 'spiritual': 6383, 'broke': 6384, 'increasing': 6385, 'cap': 6386, 'gunshot': 6387, 'wounds': 6388, 'startup': 6389, 'dress': 6390, 'reptile': 6391, 'guess': 6392, 'thoughts': 6393, 'prayers': 6394, 'according': 6395, 'fertility': 6396, 'broccoli': 6397, 'diego': 6398, 'wooden': 6399, 'plumber': 6400, 'occupied': 6401, 'sausage': 6402, 'links': 6403, 'maps': 6404, 'secure': 6405, 'handle': 6406, 'tripadvisor': 6407, 'tesco': 6408, 'compensation': 6409, 'koch': 6410, 'bananas': 6411, 'rolls': 6412, 'hash': 6413, 'elite': 6414, 'loyalty': 6415, 'trigger': 6416, 'lessons': 6417, 'va': 6418, 'appointment': 6419, 'vet': 6420, 'cross-country': 6421, 'determined': 6422, 'yankee': 6423, 'candle': 6424, 'bite': 6425, 'trench': 6426, 'janitor': 6427, 'befriend': 6428, 'recall': 6429, 'fruit': 6430, 'wick': 6431, 'dudes': 6432, 'pursue': 6433, 'passion': 6434, 'unanimously': 6435, 'fault': 6436, 'militia': 6437, 'tsa': 6438, 'phase': 6439, 'brutally': 6440, 'square': 6441, 'mosquitoes': 6442, 'zika': 6443, 'shaggy': 6444, 'boarding': 6445, 'cheers': 6446, 'pitch': 6447, 'one-armed': 6448, 'one-legged': 6449, 'minneapolis': 6450, 'washes': 6451, 'fame': 6452, 'joke': 6453, 'hid': 6454, 'toilets': 6455, 'studios': 6456, \"'absolutely\": 6457, 'sustainable': 6458, 'dot': 6459, 'form': 6460, 'wire': 6461, 'mango': 6462, 'rum': 6463, 'exact': 6464, 'stds': 6465, 'continuing': 6466, 'opioid': 6467, 'crush': 6468, 'saga': 6469, 'orgies': 6470, 'rectory': 6471, 'heavily': 6472, 'pedestrians': 6473, 'all-male': 6474, 'orbit': 6475, 'crushed': 6476, 'blocks': 6477, 'confirmation': 6478, 'recommended': 6479, 'slide': 6480, 'vaginal': 6481, 'employer': 6482, 'bronze': 6483, 'criminalize': 6484, 'urine': 6485, '7-eleven': 6486, 'microwave': 6487, 'transit': 6488, 'vice': 6489, 'hunting': 6490, '7:11': 6491, 'ounces': 6492, 'attracts': 6493, 'fatally': 6494, 'nudes': 6495, 'abuses': 6496, 'diagnosis': 6497, 'distract': 6498, 'safari': 6499, 'endangered': 6500, 'gogh': 6501, 'vegan': 6502, 'diplomatic': 6503, 'demanded': 6504, 'controlling': 6505, 'capital': 6506, 'iranian': 6507, 'sorcery': 6508, 'edinburgh': 6509, 'piss': 6510, 'terms': 6511, 'covers': 6512, 'zombie': 6513, 's.c.': 6514, 'anonymously': 6515, '…': 6516, 'demonstrating': 6517, 'explodes': 6518, 'maryland': 6519, 'spray': 6520, 'denim': 6521, 'trained': 6522, 'aquarium': 6523, 'listing': 6524, 'hologram': 6525, 'bleach': 6526, 'destroying': 6527, 'northern': 6528, 'exorcism': 6529, '80,000': 6530, 'dig': 6531, 'bloomberg': 6532, 'shelters': 6533, 'dole': 6534, 'studio': 6535, 'welsh': 6536, 'relate': 6537, 'spectrum': 6538, 'disgraced': 6539, 'sepp': 6540, 'blatter': 6541, 'warrant': 6542, 'eliminate': 6543, 'injecting': 6544, 'smoothie': 6545, 'manufacturer': 6546, 'earning': 6547, 'medicaid': 6548, 'somali': 6549, 'predators': 6550, 'horny': 6551, 'bees': 6552, 'scrolling': 6553, 'f***': 6554, 'scotland': 6555, 'independence': 6556, 'villager': 6557, 'sobering': 6558, 'vp': 6559, 'pushed': 6560, 'midnight': 6561, 'arby': 6562, 'n': 6563, 'melt': 6564, 'detergent': 6565, 'pods': 6566, 'miller': 6567, 'peacefully': 6568, 'alcoholic': 6569, 'pose': 6570, 'mattel': 6571, 'inept': 6572, 'undecided': 6573, 'consecutive': 6574, 'u': 6575, 'stir': 6576, 'businessman': 6577, 'raising': 6578, 'prey': 6579, 'galaxy': 6580, 'initiative': 6581, 'klingon': 6582, 'chilling': 6583, 'blown': 6584, 'prematurely': 6585, 'spam': 6586, 'gymnastics': 6587, 'invade': 6588, 'invading': 6589, 'cure': 6590, 'autism': 6591, 'drawing': 6592, 'yang': 6593, 'shitting': 6594, 'norwegian': 6595, 'fends': 6596, 'faked': 6597, 'astronomers': 6598, 'lin-manuel': 6599, 'charles': 6600, 'linked': 6601, 'desire': 6602, 'silly': 6603, 'scared': 6604, 'fury': 6605, 'prank': 6606, 'backfires': 6607, 'inequality': 6608, 'geese': 6609, 'tanks': 6610, 'analyst': 6611, 'scarlett': 6612, 'johansson': 6613, 'super-rich': 6614, 'trains': 6615, 'organs': 6616, 'dioxide': 6617, 'duggar': 6618, 'cheating': 6619, 'anna': 6620, 'hypocrisy': 6621, 'supports': 6622, 'confessed': 6623, 'refers': 6624, 'boris': 6625, 'n.y.': 6626, 'careers': 6627, 'palmer': 6628, 'truth': 6629, 'ufos': 6630, 'adorable': 6631, 'cory': 6632, 'booker': 6633, 'velvet': 6634, 'lebanon': 6635, 'joining': 6636, 'wicked': 6637, 'compromise': 6638, 'columbia': 6639, 'slave': 6640, 'announcer': 6641, 'driverless': 6642, 'buses': 6643, 'slippery': 6644, 'slope': 6645, 'limp': 6646, 'bizkit': 6647, 'non-existent': 6648, 'gig': 6649, 'tragically': 6650, 'downtown': 6651, 'delorean': 6652, 'mph': 6653, 'eternity': 6654, 'short': 6655, 'skinny': 6656, 'vaccines': 6657, 'taps': 6658, 'ali': 6659, 'houses': 6660, 'vortex': 6661, 'changing': 6662, 'goodbye': 6663, 'rabbits': 6664, 'denied': 6665, 'frisbee': 6666, 'income': 6667, 'sailboat': 6668, 'internment': 6669, 'turnout': 6670, 'routine': 6671, 'implements': 6672, 'dinosaurs': 6673, 'declaring': 6674, 'confident': 6675, 'pro-life': 6676, 'urinates': 6677, '22-year-old': 6678, 'cheaper': 6679, 'wrapped': 6680, 'obvious': 6681, 'crunch': 6682, 'commercials': 6683, 'honestly': 6684, 'hosting': 6685, 'hints': 6686, 'vaccinate': 6687, 'fever': 6688, 'evacuated': 6689, 'swimming': 6690, '38': 6691, 'emerges': 6692, 'daniel': 6693, 'craig': 6694, 'location': 6695, 'sask': 6696, 'menu': 6697, 'comprehensive': 6698, 'debase': 6699, 'backs': 6700, 'iphones': 6701, 'teresa': 6702, 'saint': 6703, 'improving': 6704, 'efficiency': 6705, 'pickup': 6706, 'marry': 6707, 'behaviour': 6708, 'smith': 6709, 'channel': 6710, \"'fake\": 6711, '2004': 6712, 'sits': 6713, 'warden': 6714, 'striking': 6715, 'typical': 6716, 'overwhelmingly': 6717, 'bros': 6718, 'wide': 6719, 'kissing': 6720, 'dildos': 6721, 'finance': 6722, 'islam': 6723, '1985': 6724, 'coup': 6725, 'oust': 6726, 'lee': 6727, 'roth': 6728, 'halen': 6729, 'visitor': 6730, 'signal': 6731, 'imposter': 6732, 'hides': 6733, 'resume': 6734, 'carcass': 6735, 'yakuza': 6736, 'aside': 6737, 'psa': 6738, 'texting': 6739, 'hugh': 6740, 'ended': 6741, 'sentences': 6742, 'verses': 6743, 'noodle': 6744, 'firm': 6745, 'fence': 6746, 'us-mexico': 6747, 'decapitated': 6748, 'swaziland': 6749, '8,000': 6750, 'centaur': 6751, 'woods': 6752, 'cocks': 6753, 'brian': 6754, 'kushner': 6755, 'las': 6756, 'earlier': 6757, 'wood': 6758, 'indie': 6759, 'thriller': 6760, 'sanctions': 6761, 'participating': 6762, 'responders': 6763, 'inform': 6764, 'ugandan': 6765, 'netanyahu': 6766, 'easter': 6767, 'grenade': 6768, 'organizers': 6769, 'tests': 6770, 'liquid': 6771, 'naps': 6772, 'glitter': 6773, 'spirits': 6774, 'connects': 6775, 'types': 6776, 'footprint': 6777, 'colin': 6778, 'kaepernick': 6779, 'applicant': 6780, 'plain': 6781, 'bishop': 6782, 'ariana': 6783, 'grande': 6784, 'item': 6785, 'ink': 6786, 'pupils': 6787, 'boyfriends': 6788, 'massage': 6789, \"'happy\": 6790, 'tvs': 6791, 'tables': 6792, 'alarming': 6793, '60': 6794, 'homicide': 6795, 'appeals': 6796, 'smuggled': 6797, 'caged': 6798, 'explaining': 6799, 'kenya': 6800, 'historical': 6801, 'prostitutes': 6802, 'predicted': 6803, 'adam': 6804, 'sandler': 6805, 'companies': 6806, 'romanian': 6807, 'declaration': 6808, 'anti-semitic': 6809, '10-year-old': 6810, 'bachelor': 6811, 'pussy': 6812, 'lapd': 6813, 'manure': 6814, 'treasury': 6815, 'diplomat': 6816, 'crosses': 6817, 'affects': 6818, 'simulator': 6819, 'obnoxious': 6820, 'dave': 6821, 'franco': 6822, 'nor': 6823, 'rabid': 6824, 'mounting': 6825, 'oval': 6826, 'purge': 6827, 'scissors': 6828, 'drawer': 6829, 'confiscated': 6830, 'academic': 6831, 'dawkins': 6832, 'mile': 6833, 'pennsylvania': 6834, 'abandons': 6835, 'earn': 6836, 'joker': 6837, 'cups': 6838, 'runners': 6839, 'algorithm': 6840, 'indigenous': 6841, 'pumpkin': 6842, 'fondly': 6843, 'solution': 6844, 'phrases': 6845, 'agreement': 6846, 'gender-neutral': 6847, 'capsule': 6848, 'sludge': 6849, 'narcissists': 6850, 'portraying': 6851, 'wake': 6852, 'repeat': 6853, 'zones': 6854, 'polite': 6855, 'stance': 6856, 'urination': 6857, 'steak': 6858, 'muscle': 6859, 'rumors': 6860, 'prompt': 6861, '33': 6862, 'hawaii': 6863, 'intern': 6864, 'protected': 6865, 'glued': 6866, 'airplane': 6867, 'austria': 6868, 'compete': 6869, \"'good\": 6870, 'deserves': 6871, 'stroke': 6872, 'residency': 6873, 'taxpayer': 6874, 'hulu': 6875, 'cancel': 6876, 'blows': 6877, 'labour': 6878, 'concealed': 6879, 'log': 6880, 'seoul': 6881, 'mt': 6882, 'expedition': 6883, 'rockstar': 6884, 'redemption': 6885, 'sprayed': 6886, 'axe': 6887, 'mattress': 6888, 'experiments': 6889, 'lol': 6890, 'andrew': 6891, 'cackling': 6892, 'segment': 6893, 'authority': 6894, 'abolish': 6895, 'working-class': 6896, 'directors': 6897, 'handling': 6898, 'yards': 6899, 'preventing': 6900, 'trading': 6901, 'abandoned': 6902, 'duffel': 6903, 'tiger': 6904, 'refund': 6905, 'hamilton': 6906, 'writers': 6907, 'ruby': 6908, 'fantasy': 6909, 'packs': 6910, 'boycott': 6911, 'coca-cola': 6912, 'scare': 6913, \"'save\": 6914, 'mask': 6915, 'controlled': 6916, 'burn': 6917, '800': 6918, 'todd': 6919, 'legitimate': 6920, 'remarks': 6921, 'traveler': 6922, 'suitcase': 6923, 'informing': 6924, '2019': 6925, 'carter': 6926, 'crab': 6927, 'all-you-can-eat': 6928, 'buffet': 6929, 'oh': 6930, 'lit': 6931, 'dynamite': 6932, 'painted': 6933, 'carrot': 6934, 'junior': 6935, 'superman': 6936, 'stares': 6937, 'longingly': 6938, 'melbourne': 6939, 'jumped': 6940, 'cardinals': 6941, 'requirement': 6942, 'beneath': 6943, 'kettle': 6944, '1984': 6945, 'tops': 6946, 'bestseller': 6947, 'inadvertently': 6948, 'reboot': 6949, 'swimmers': 6950, 'beaches': 6951, 'grader': 6952, 'medicine': 6953, 'oppressor': 6954, 'awesome': 6955, 'volunteers': 6956, 'legos': 6957, 'diamonds': 6958, 'poet': 6959, 'prosecuted': 6960, 'clearing': 6961, 'browser': 6962, 'anger': 6963, 'ex-wife': 6964, 'admin': 6965, 'published': 6966, 'poo': 6967, 'survives': 6968, 'dew': 6969, 'kellyanne': 6970, 'conway': 6971, 'focus': 6972, 'approves': 6973, 'razor': 6974, 'miyazaki': 6975, 'boasts': 6976, 'robbing': 6977, 'assistant': 6978, 'da': 6979, 'assembly': 6980, 'importance': 6981, 'microwaving': 6982, 'vessel': 6983, 'transportation': 6984, 'reflect': 6985, 'vampire': 6986, 'garlic': 6987, 'memoir': 6988, 'lemons': 6989, 'copies': 6990, 'indicator': 6991, 'masturbation': 6992, 'six-year-old': 6993, 'intelligence': 6994, 'effect': 6995, 'denier': 6996, 'claimed': 6997, 'beak': 6998, 'motorized': 6999, 'migration': 7000, 'asia': 7001, 'creationist': 7002, 'interpretation': 7003, 'faced': 7004, 'sweets': 7005, 'escorts': 7006, 'preemptively': 7007, 'wheelchair-bound': 7008, 'scientist': 7009, 'cannibalism': 7010, '2.7': 7011, 'caves': 7012, 'warnings': 7013, 'lift': 7014, 'rewarding': 7015, 'inspired': 7016, 'j.k.': 7017, 'simmons': 7018, 'ryanair': 7019, 'seating': 7020, 'curious': 7021, 'straw': 7022, 'all-female': 7023, 'boxing': 7024, 'rallies': 7025, 'saturday': 7026, 'spoiled': 7027, 'beatles': 7028, 'interrupts': 7029, 'barred': 7030, 'legislature': 7031, 'ex': 7032, 'tie-in': 7033, 'horror': 7034, 'cena': 7035, 'x-ray': 7036, 'iguana': 7037, 'courthouse': 7038, 'devon': 7039, 'homosexuality': 7040, 'watched': 7041, 'genital': 7042, 'recognition': 7043, 'software': 7044, 'strippers': 7045, 'fewer': 7046, 'shares': 7047, 'bearing': 7048, 'swastikas': 7049, 'mock': 7050, 'brits': 7051, 'danger': 7052, 'potion': 7053, 'addiction': 7054, 'partly': 7055, 'sex-abuse': 7056, 'diarrhea': 7057, 'embarrassed': 7058, 'bolton': 7059, 'desperate': 7060, 'twins': 7061, 'badly': 7062, 'pakistan': 7063, 'smuggling': 7064, 'plot': 7065, 'uncovered': 7066, 'virus': 7067, 'dare': 7068, 'placing': 7069, 'bagels': 7070, 'travellers': 7071, 'mustache': 7072, 'transparent': 7073, 'skiing': 7074, 'deleted': 7075, 'cards': 7076, \"'fat\": 7077, 'counselor': 7078, 'recommendation': 7079, 'nasty': 7080, 'poster': 7081, 'earns': 7082, 'logging': 7083, 'wales': 7084, 'obviously': 7085, 'baffled': 7086, 'crap': 7087, 'cleric': 7088, 'grants': 7089, 'scalia': 7090, 'brussels': 7091, \"'if\": 7092, 'bathe': 7093, 'shave': 7094, 'dayton': 7095, 'invasion': 7096, 'scouts': 7097, 'obtained': 7098, 'roman': 7099, 'atheists': 7100, 'fred': 7101, \"'world\": 7102, 'skier': 7103, 'mccarthy': 7104, 'cleaning': 7105, 'unwanted': 7106, 'twist': 7107, 'dorm': 7108, 'waiter': 7109, 'jill': 7110, 'visionary': 7111, 'columnist': 7112, 'baldwin': 7113, 'nebraska': 7114, 'homosexuals': 7115, 'grad': 7116, 'syndrome': 7117, 'condemned': 7118, 'holes': 7119, 'preparing': 7120, 'tobacco': 7121, 'smokers': 7122, 'elder': 7123, 'parish': 7124, 'rams': 7125, 'great-grandmother': 7126, 'cbd': 7127, 'jurassic': 7128, 'standard': 7129, 'fare': 7130, 'surge': 7131, \"'alternative\": 7132, 'spraying': 7133, 'economic': 7134, 'yemen': 7135, 'beating': 7136, 'gordon': 7137, 'ramsay': 7138, 'dwarf': 7139, 'ejected': 7140, 'deported': 7141, 'handsome': 7142, 'cents': 7143, 'artistic': 7144, 'cambodia': 7145, 'alarm': 7146, 'cobra': 7147, 'command': 7148, 'aretha': 7149, 'franklin': 7150, 'diaz': 7151, 'cures': 7152, \"'free\": 7153, 'refrain': 7154, 'charleston': 7155, 'operation': 7156, 'inventor': 7157, '84': 7158, 'slept': 7159, 'commission': 7160, 'richest': 7161, '92': 7162, 'telescope': 7163, 'desert': 7164, 'moral': 7165, 'poachers': 7166, 'curses': 7167, 'celebrating': 7168, 'solve': 7169, 'surprisingly': 7170, 'freezing': 7171, 'degree': 7172, 'ships': 7173, 'eiffel': 7174, \"'this\": 7175, 'appreciate': 7176, 'claus': 7177, 'lists': 7178, 'freshman': 7179, 'perth': 7180, 'policies': 7181, 'erotica': 7182, 'jump': 7183, 'yolo': 7184, 'environment': 7185, 'legends': 7186, 'bricks': 7187, 'penises': 7188, 'grammar': 7189, 'interference': 7190, 'cambridge': 7191, 'analytica': 7192, 'illicit': 7193, 'boring': 7194, 'anal': 7195, 'seth': 7196, 'rogen': 7197, 'brawl': 7198, 'ai': 7199, 'ethics': 7200, 'libertarian': 7201, 'vegetable': 7202, 'blanket': 7203, 'assuming': 7204, 'domain': 7205, 'fiancée': 7206, 'jealous': 7207, 'airs': 7208, 'failure': 7209, 'jedi': 7210, 'howard': 7211, 'roseanne': 7212, 'opponents': 7213, 'unsafe': 7214, 'deaf': 7215, 'crestfallen': 7216, 'texan': 7217, 'doug': 7218, 'diplomacy': 7219, 'edmonton': 7220, 'builds': 7221, 'jams': 7222, 'ally': 7223, 'threaten': 7224, 'benedict': 7225, \"'hero\": 7226, 'gaining': 7227, 'ep': 7228, 'woody': 7229, 'allen': 7230, 'remember': 7231, 'frees': 7232, 'levels': 7233, 'travels': 7234, 'antivirus': 7235, 'malware': 7236, 'shame': 7237, 'irma': 7238, 'assaulting': 7239, 'struggles': 7240, 'r.r': 7241, 'anti-piracy': 7242, 'louisville': 7243, 'springfield': 7244, 'joined': 7245, 'jihadists': 7246, 'apologizing': 7247, 'precious': 7248, 'stealth': 7249, 'pentagon': 7250, 'nations': 7251, 'inviting': 7252, 'koala': 7253, 'crawling': 7254, 'conversation': 7255, 'acquitted': 7256, 'flirting': 7257, 'costly': 7258, 'defective': 7259, 'replacement': 7260, 'liked': 7261, 'feelings': 7262, 'carnival': 7263, 'cruise': 7264, 'charging': 7265, 'cellphones': 7266, 'policeman': 7267, 'bombs': 7268, 'celebration': 7269, 'sending': 7270, 'self-destruct': 7271, 'monitors': 7272, 'marketing': 7273, 'stash': 7274, 'spark': 7275, 'astronaut': 7276, 'frontman': 7277, 'skittles': 7278, 'dodge': 7279, 'sterling': 7280, 'harassed': 7281, 'warehouse': 7282, 'strange': 7283, 'parked': 7284, 'goodwill': 7285, '22': 7286, 'fattest': 7287, 'ddos': 7288, 'heimlich': 7289, 'milo': 7290, 'yiannopoulos': 7291, \"'white\": 7292, 'winds': 7293, 'signals': 7294, 'chinese-made': 7295, 'lobbyists': 7296, 'firefighter': 7297, 'goods': 7298, 'noisy': 7299, 'relentlessly': 7300, 'database': 7301, 'decisions': 7302, 'inch': 7303, 'jacket': 7304, 'diner': 7305, '89': 7306, 'interpret': 7307, 'recruitment': 7308, 'tattooed': 7309, '15,000': 7310, 'observing': 7311, 'setup': 7312, 'guidelines': 7313, 'p.m.': 7314, 'egyptian': 7315, 'purpose': 7316, 'freaking': 7317, 'woes': 7318, 'bob': 7319, 'treated': 7320, 'bribe': 7321, 'deport': 7322, 'innovative': 7323, 'sandusky': 7324, 'co-founder': 7325, 'anti-obama': 7326, 'whatsapp': 7327, 'mini': 7328, 'oldie': 7329, 'absolute': 7330, 'goodie': 7331, 'fulfilling': 7332, '32': 7333, 'customs': 7334, '4chan': 7335, 'systems': 7336, 'punished': 7337, 'injected': 7338, 'sharks': 7339, 'ukrainian': 7340, 'trolls': 7341, 'mugshot': 7342, 'stocks': 7343, 'wolves': 7344, 'honored': 7345, 'veterans': 7346, \"'all\": 7347, 'jordan': 7348, 'pepper': 7349, 'servers': 7350, 'containing': 7351, 'spoilers': 7352, 'praised': 7353, 'grim': 7354, 'civilians': 7355, 'grateful': 7356, 'immunity': 7357, 'autonomous': 7358, 'rome': 7359, 'ham': 7360, 'doom': 7361, 'rats': 7362, '25-year-old': 7363, \"'ok\": 7364, 'automatic': 7365, 'max': 7366, 'entertainment': 7367, 'yelp': 7368, 'trojan': 7369, 'urgent': 7370, 'ancestor': 7371, '64': 7372, 'develops': 7373, 'promised': 7374, 'cave': 7375, 'delivered': 7376, 'camping': 7377, 'censor': 7378, 'courage': 7379, 'waffle': 7380, 'nashville': 7381, 'potholes': 7382, 'spring': 7383, 'switches': 7384, 'solar': 7385, 'constant': 7386, 'shotgun': 7387, 'lurches': 7388, 'pattern': 7389, 'anthony': 7390, 'samsung': 7391, 'entrepreneur': 7392, 'advocates': 7393, 'rebellious': 7394, 'retrieve': 7395, 'praising': 7396, 'tattooing': 7397, 'universe': 7398, 'candles': 7399, 'gently': 7400, 'traditional': 7401, 'promotion': 7402, 'ear': 7403, 'heading': 7404, 'european': 7405, 'band': 7406, 'unreleased': 7407, 'smelly': 7408, 'airbnb': 7409, 'constitution': 7410, '3-year': 7411, 'tear': 7412, 'heated': 7413, 'lowers': 7414, 'maximum': 7415, 'volume': 7416, 'lots': 7417, 'nearby': 7418, 'amateur': 7419, 'nudists': 7420, 'comey': 7421, 'payment': 7422, 'aclu': 7423, 'teams': 7424, 'tallest': 7425, 'existence': 7426, 'voldemort': 7427, 'portrait': 7428, 'porch': 7429, 'unlicensed': 7430, 'climb': 7431, 'strategy': 7432, 'ta': 7433, 'copycat': 7434, 'takeout': 7435, 'burrito': 7436, 'container': 7437, 'discourage': 7438, 'stranger': 7439, 'shirtless': 7440, 'actors': 7441, 'flower': 7442, 'blunder': 7443, 'prepared': 7444, 'chapter': 7445, 'urinating': 7446, 'propose': 7447, 'friendship': 7448, 'ron': 7449, 'harper': 7450, 'suggested': 7451, 'smashing': 7452, 'ireland': 7453, 'illness': 7454, 'solved': 7455, 'alexa': 7456, 'textbooks': 7457, 'whiskey': 7458, 'pr': 7459, 'ferguson': 7460, 'mario': 7461, 'packages': 7462, 'african-american': 7463, 'filthy': 7464, 'waze': 7465, 'trucks': 7466, 'uh': 7467, 'reverse': 7468, 'welcomes': 7469, \"'not\": 7470, 'reasonable': 7471, 'feeds': 7472, 'lobby': 7473, 'relatives': 7474, 'reprimanded': 7475, 'reintroduces': 7476, 'beloved': 7477, 'bounty': 7478, 'chan': 7479, 'spree': 7480, 'zambia': 7481, 'viagra': 7482, 'adblock': 7483, 'plus': 7484, 'atlanta': 7485, 'cbs': 7486, 'anymore': 7487, 'translation': 7488, '150,000': 7489, 'prompting': 7490, 'clouds': 7491, 'floats': 7492, 'belarus': 7493, 'clapping': 7494, 'tactic': 7495, 'securing': 7496, 'strong': 7497, 'events': 7498, 'clip': 7499, 'hebdo': 7500, 'honest': 7501, 'hygiene': 7502, 'simple': 7503, 'checking': 7504, 'addicts': 7505, 'underage': 7506, '21': 7507, 'ah': 7508, 'appear': 7509, 'deportation': 7510, 'plague': 7511, 'inc.': 7512, 'attorneys': 7513, 'clients': 7514, 'beheads': 7515, '95': 7516, 'constituents': 7517, 'facial': 7518, 'affect': 7519, 'metric': 7520, 'cook': 7521, 'posting': 7522, '800,000': 7523, 'shadow': 7524, 'cadbury': 7525, 'computers': 7526, 'flew': 7527, 'restaurants': 7528, 'heartless': 7529, 'chooses': 7530, 'appoints': 7531, 'streaming': 7532, 'cites': 7533, 'judgment': 7534, 'dip': 7535, 'denver': 7536, 'perspective': 7537, 'reminding': 7538, 'dr': 7539, 'aged': 7540, 'bare': 7541, 'criticizing': 7542, 'developer': 7543, 'vision': 7544, 'advise': 7545, 'sightings': 7546, 'prostitution': 7547, 'interpreter': 7548, 'submit': 7549, 'cited': 7550, 'violation': 7551, 'penguin': 7552, '55': 7553, 'motorcyclist': 7554, 'protesting': 7555, 'helmet': 7556, '2011': 7557, 'disasters': 7558, 'shoulder': 7559, 'retriever': 7560, 'potatoes': 7561, 'melting': 7562, 'impact': 7563, 'dragon': 7564, 'divided': 7565, 'self-portraits': 7566, 'ribs': 7567, 'nutritious': 7568, 'intent': 7569, 'nine-year-old': 7570, 'hbo': 7571, 'hires': 7572, 'halftime': 7573, 'spice': 7574, 'knocked': 7575, 'goose': 7576, 'opinions': 7577, 'haven': 7578, 'mating': 7579, 'females': 7580, 'polling': 7581, 'moved': 7582, 'proof': 7583, 'error': 7584, 'casket': 7585, 'victorious': 7586, 'bangkok': 7587, 'shock': 7588, 'characters': 7589, 'mud': 7590, 'concluded': 7591, 'branch': 7592, 'branding': 7593, 'initials': 7594, 'converts': 7595, 'roommates': 7596, 'imaginary': 7597, 'chewbacca': 7598, 'cub': 7599, 'outer': 7600, 'manifesto': 7601, 'nsfw': 7602, 'costa': 7603, 'overzealous': 7604, 'gain': 7605, 'strongside': 7606, 'weakside': 7607, 'medication': 7608, \"'old\": 7609, 'ladies': 7610, 'accessible': 7611, 'hp': 7612, 'sealed': 7613, 'refusal': 7614, 'fresh': 7615, 'corrupt': 7616, 'brooklyn': 7617, 'mailman': 7618, 'off-duty': 7619, 'applicants': 7620, 'motherfucker': 7621, 'jr': 7622, 'injuring': 7623, 'mcdonalds': 7624, 'wandering': 7625, 'noble': 7626, 'humble': 7627, 'lyft': 7628, 'eagle': 7629, 'rolos': 7630, 'tablets': 7631, 'ipads': 7632, 'legislative': 7633, 'heterosexual': 7634, 'parenthood': 7635, 'graves': 7636, 'chose': 7637, 'fraternity': 7638, 'stood': 7639, 'fact-checking': 7640, 'integrated': 7641, 'visits': 7642, 'drive-thru': 7643, 'praise': 7644, 'dental': 7645, 'wikileaks': 7646, 'dump': 7647, 'exposes': 7648, 'classroom': 7649, 'kangaroo': 7650, 'indefinitely': 7651, 'jeremy': 7652, 'describes': 7653, 'jane': 7654, 'tarantula': 7655, 'cherry': 7656, 'produce': 7657, 'lifestyle': 7658, 'genius': 7659, 'crowdfunding': 7660, 'bailout': 7661, 'noise': 7662, 'banging': 7663, 'gov': 7664, 'friday': 7665, 'closure': 7666, 'hawaiian': 7667, 'volcano': 7668, 'malcolm': 7669, 'guantanamo': 7670, 'pastry': 7671, 'chic': 7672, 'hairstyles': 7673, 'crushes': 7674, 'battered': 7675, 'rihanna': 7676, 'advertise': 7677, 'usda': 7678, 'summoned': 7679, '18-year-old': 7680, 'obsessed': 7681, 'spacey': 7682, 'pillow': 7683, 'cosby': 7684, 'conviction': 7685, 'mob': 7686, 'perfume': 7687, '8th': 7688, 'postal': 7689, 'stamp': 7690, 'additional': 7691, 'spelling': 7692, 'fork': 7693, 'awards': 7694, 'plug': 7695, 'hiker': 7696, 'ponytail': 7697, 'hadn': 7698, 'crotch': 7699, 'half-marathon': 7700, 'correct': 7701, 'dish': 7702, 'nickelback': 7703, 'coax': 7704, 'testimony': 7705, 'sunglasses': 7706, '2-year-old': 7707, 'trader': 7708, 'cashier': 7709, 'compliment': 7710, 'selected': 7711, 'thrift': 7712, 'false': 7713, 'nipples': 7714, 'happening': 7715, 'gallery': 7716, 'areas': 7717, 'resembling': 7718, 'classmate': 7719, '666': 7720, 'mentor': 7721, 'styles': 7722, 'calif.': 7723, 'outlets': 7724, 'billionaires': 7725, 'til': 7726, 'reaper': 7727, 'staffers': 7728, 'safely': 7729, 'problems': 7730, 'a.m.': 7731, 'sushi': 7732, 'iq': 7733, 'communicating': 7734, 'gag': 7735, '2nd': 7736, 'competitive': 7737, 'wilson': 7738, 'mri': 7739, 'laid': 7740, 'acted': 7741, 'dispenser': 7742, 'chest': 7743, 'recovery': 7744, 'cock': 7745, 'euros': 7746, 'cinema': 7747, 'coastal': 7748, 'stiff': 7749, 'tip': 7750, 'cynthia': 7751, 'beheadings': 7752, 'jennifer': 7753, 'personality': 7754, 'adventure': 7755, 'sponsored': 7756, 'salman': 7757, 'uninspired': 7758, 'refugee': 7759, 'finland': 7760, 'dining': 7761, 'clutching': 7762, 'lynching': 7763, 'quite': 7764, 'louisiana': 7765, 'pushes': 7766, 'searches': 7767, 'excludes': 7768, 'darkness': 7769, 'reelection': 7770, 'visited': 7771, 'beijing': 7772, 'grills': 7773, 'informs': 7774, 'caller': 7775, 'native': 7776, 'bloody': 7777, 'metallica': 7778, 'camouflage': 7779, 'invisible': 7780, 'sinks': 7781, 'scammer': 7782, 'cheetos': 7783, 'mocks': 7784, 'brad': 7785, 'carpet': 7786, 'toe': 7787, 'captivity': 7788, 'shareholder': 7789, 'purchased': 7790, 'recovering': 7791, 'picks': 7792, 'shootout': 7793, 'panther': 7794, '68': 7795, 'fetuses': 7796, 'burglar': 7797, 'quarters': 7798, 'barnes': 7799, 'self-defense': 7800, 'transforms': 7801, 'somalia': 7802, 'dalai': 7803, 'lama': 7804, 'vacant': 7805, 'aisle': 7806, 'growth': 7807, 'focuses': 7808, 'pottery': 7809, 'infected': 7810, 'engineers': 7811, 'encourages': 7812, 'periods': 7813, 'pharrell': 7814, 'colossal': 7815, 'convince': 7816, 'tradition': 7817, 'torch': 7818, 'h.w': 7819, 'wistfully': 7820, 'shorts': 7821, 'cease': 7822, 'somewhere': 7823, 'idiot': 7824, 'shrinking': 7825, 'vest': 7826, 'breakdown': 7827, 'neo-nazis': 7828, 'chill': 7829, 'lesbians': 7830, 'barrel': 7831, 'transport': 7832, 'impress': 7833, 'edited': 7834, 'christianity': 7835, 'leftist': 7836, 'sounds': 7837, 'bombshell': 7838, 'assassination': 7839, 'exploded': 7840, 'figuring': 7841, 'modi': 7842, 'darth': 7843, 'vader': 7844, \"'game\": 7845, 'remake': 7846, 'severe': 7847, 'blessing': 7848, 'lamborghini': 7849, 'dreamed': 7850, 'cartoonist': 7851, 'temporary': 7852, 'cocktail': 7853, 'pitchfork': 7854, 'netherlands': 7855, 'rounds': 7856, 'incredibles': 7857, 'rank': 7858, 'jumps': 7859, 'ferry': 7860, 'diabetic': 7861, 'magnetic': 7862, 'banker': 7863, 'pancake': 7864, 'paramedics': 7865, 'extraordinary': 7866, 'hunted': 7867, 'extinction': 7868, 'reign': 7869, 'orca': 7870, 'carries': 7871, '@': 7872, 'february': 7873, 'interests': 7874, 'mcafee': 7875, 'spies': 7876, '24-year-old': 7877, 'prompts': 7878, 'grounded': 7879, 'providing': 7880, 'buzzfeed': 7881, 'cattle': 7882, '182': 7883, 'reward': 7884, 'heinz': 7885, 'ketchup': 7886, 'vulgar': 7887, 'kazakhstan': 7888, 'borat': 7889, 'disappointment': 7890, 'womb': 7891, 'atlantic': 7892, 'alleges': 7893, 'brutality': 7894, 'buildings': 7895, 'ian': 7896, 'provide': 7897, 'heels': 7898, 'furry': 7899, 'neighbours': 7900, 'cbc': 7901, 'legalization': 7902, 'meta': 7903, 'ebi': 7904, 'gusey': 7905, 'architect': 7906, 'disclose': 7907, '70,000': 7908, 'opposition': 7909, 'foiled': 7910, 'bass': 7911, 'fields': 7912, 'clap': 7913, 'central': 7914, 'cab': 7915, 'predicts': 7916, 'seahawks': 7917, 'seex': 7918, 'apocalypse': 7919, 'wwii': 7920, 'skies': 7921, 'creative': 7922, 'colleges': 7923, 'tube': 7924, 'delays': 7925, 'implanted': 7926, 'audition': 7927, 'brady': 7928, 'messed': 7929, 'beast': 7930, 'shutting': 7931, 'reviews': 7932, 'manning': 7933, 'passwords': 7934, '15k': 7935, 'oven': 7936, 'beneficial': 7937, 'meddling': 7938, 'catacombs': 7939, 'fundamental': 7940, 'ness': 7941, 'tinder': 7942, 'vaginas': 7943, 'acid': 7944, 'regretting': 7945, 'luis': 7946, 'suarez': 7947, 'rowling': 7948, 'flip': 7949, 'dan': 7950, 'explanation': 7951, 'theorists': 7952, 'swallowed': 7953, 'owning': 7954, 'marble': 7955, 'funnel': 7956, 'cured': 7957, 'humane': 7958, 'radiation': 7959, 'spinning': 7960, 'palestinian': 7961, 'confrontation': 7962, 'nominated': 7963, 'sat': 7964, 'proceeds': 7965, 'spontaneous': 7966, 'purchases': 7967, 'councillor': 7968, 'progress': 7969, '83': 7970, 'suffer': 7971, 'applications': 7972, 'knight': 7973, \"'having\": 7974, 'reduced': 7975, 'upscale': 7976, 'clone': 7977, 'unlock': 7978, 'marilyn': 7979, 'ingesting': 7980, 'boaty': 7981, 'mcboatface': 7982, 'banks': 7983, 'canal': 7984, 'morbidly': 7985, 'shed': 7986, 'samuel': 7987, 'detectives': 7988, 'cvs': 7989, 'statements': 7990, 'iconic': 7991, 'prepare': 7992, 'unsupervised': 7993, 'cult': 7994, 'thank': 7995, 'congressmen': 7996, 'reaching': 7997, 'neither': 7998, 'fixed': 7999, 'oreos': 8000, 'neo-nazism': 8001, 'reach': 8002, 'republic': 8003, 'pierce': 8004, 'habitat': 8005, 'dennis': 8006, 'rodman': 8007, 'pasta': 8008, 'august': 8009, 'reddit': 8010, 'selfish': 8011, 'yelling': 8012, 'located': 8013, 'demonstrate': 8014, 'pedophiles': 8015, 'premiere': 8016, 'alliance': 8017, 'supremacy': 8018, 'euthanized': 8019, 'wore': 8020, 'approved': 8021, 'biologists': 8022, 'omar': 8023, \"'she\": 8024, 'prevention': 8025, 'hotline': 8026, 'peanuts': 8027, 'bombers': 8028, 'orlando': 8029, 'analysts': 8030, 'chart': 8031, 'mustard': 8032, 'relative': 8033, 'pfizer': 8034, 'near-death': 8035, 'patents': 8036, 'coyotes': 8037, 'oppressed': 8038, 'leather': 8039, 'stuffed': 8040, 'packing': 8041, 'attending': 8042, 'thomas': 8043, 'whistle': 8044, \"'sexual\": 8045, 'awarded': 8046, 'analysis': 8047, 'performed': 8048, 'design': 8049, 'frantic': 8050, 'lowered': 8051, 'plates': 8052, '2,000': 8053, 'artificial': 8054, 'learns': 8055, '2012': 8056, 'macron': 8057, 'mushrooms': 8058, 'amanda': 8059, 'good-looking': 8060, \"'leave\": 8061, 'librarian': 8062, 'offends': 8063, 'worldwide': 8064, 'rapping': 8065, 'encourage': 8066, \"'can\": 8067, 'iceland': 8068, 'beheading': 8069, 'on-screen': 8070, 'fooling': 8071, 'breastfeeding': 8072, 'sony': 8073, 'sour': 8074, 'preferred': 8075, 'completes': 8076, 'magnets': 8077, 'bedtime': 8078, 'lay': 8079, 'possibly': 8080, 'record-breaking': 8081, 'headed': 8082, 'traveled': 8083, 'kotex': 8084, 'uss': 8085, 'harbor': 8086, 'tanning': 8087, 'softball': 8088, 'mi6': 8089, 'bathtub': 8090, 'swimmer': 8091, '105': 8092, 'claw': 8093, 'tie': 8094, 'de': 8095, 'blasio': 8096, 'pac': 8097, 'celebrations': 8098, 'musician': 8099, 'rainforest': 8100, 'adds': 8101, 'surgeries': 8102, 'exciting': 8103, 'believing': 8104, 'spielberg': 8105, 'direct': 8106, 'belgium': 8107, 'loot': 8108, 'peyton': 8109, 'ignored': 8110, 'reminder': 8111, 'flesh': 8112, 'yeast': 8113, 'shrimp': 8114, 'pissed': 8115, 'lame': 8116, 'postponed': 8117, 'involvement': 8118, 'hijack': 8119, 'nurses': 8120, 'hours-long': 8121, 'forbes': 8122, 'sacks': 8123, 'shifting': 8124, 'measure': 8125, 'murder-free': 8126, 'sack': 8127, 'diploma': 8128, 'subscribers': 8129, 'brace': 8130, 'chant': 8131, \"'who\": 8132, 'attire': 8133, 'occupy': 8134, 'spills': 8135, 'creek': 8136, 'quitting': 8137, 'messaging': 8138, 'pokémon': 8139, 'caribbean': 8140, 'millionaires': 8141, 'chick-fil-a': 8142, 'rap': 8143, 'raids': 8144, 'decries': 8145, 'metoo': 8146, 'chile': 8147, 'seasons': 8148, 'rebranding': 8149, 'onions': 8150, 'battery': 8151, 'wendy': 8152, 'fieri': 8153, '101': 8154, 'weddings': 8155, 'pastafarian': 8156, 'colander': 8157, 'reincarnated': 8158, '44': 8159, 'high-tech': 8160, 'organisms': 8161, 'details': 8162, 'clinging': 8163, 'airports': 8164, 'infrastructure': 8165, 'textbook': 8166, 'hamster': 8167, 'torn': 8168, 'somehow': 8169, 'al': 8170, 'ownership': 8171, 'diving': 8172, 'prescription': 8173, 'imagines': 8174, 'examine': 8175, 'hottest': 8176, 'gruesome': 8177, 'deformed': 8178, 'formally': 8179, 'kuwait': 8180, 'bikers': 8181, 'mta': 8182, 'unlocked': 8183, 'convenience': 8184, 'opium': 8185, 'greater': 8186, 'grammys': 8187, 'react': 8188, 'oakland': 8189, 'bassist': 8190, 'beekeeper': 8191, 'retires': 8192, \"'should\": 8193, 'reminded': 8194, 'brainwashed': 8195, 'bottoms': 8196, 'pray': 8197, 'lewis': 8198, 'shuts': 8199, 'clooney': 8200, 'leaf': 8201, 'homage': 8202, 'theaters': 8203, 'shown': 8204, 'founding': 8205, 'fathers': 8206, '58': 8207, 'nostalgic': 8208, 'recognizes': 8209, 'australians': 8210, 'numerous': 8211, 'blocking': 8212, 'animation': 8213, 'marshall': 8214, 'alpha': 8215, 'description': 8216, 'specifically': 8217, 'breathe': 8218, 'coffin': 8219, 'devoted': 8220, 'yells': 8221, 'unfair': 8222, 'hockey': 8223, 'introduce': 8224, \"'taco\": 8225, 'salts': 8226, 'urinate': 8227, 'bone': 8228, 'themed': 8229, 'subreddit': 8230, 'brownies': 8231, 'groups': 8232, 'abrams': 8233, 'flare': 8234, 'attracted': 8235, 'fridge': 8236, 'sunny': 8237, 'cd': 8238, 'link': 8239, 'malley': 8240, 'journal': 8241, 'conversations': 8242, 'relaxed': 8243, 'downs': 8244, 'smugglers': 8245, 'assistants': 8246, '105-year-old': 8247, 'perils': 8248, 'cargo': 8249, 'fecal': 8250, 'niece': 8251, 'usual': 8252, 'congratulations': 8253, 'hush': 8254, 'placenta': 8255, 'wash': 8256, 'handing': 8257, 'valet': 8258, '34-year-old': 8259, 'lately': 8260, 'wiretapping': 8261, 'cardboard': 8262, 'cutout': 8263, 'full-scale': 8264, 'takeover': 8265, 'dong': 8266, 'witch': 8267, 'trunk': 8268, 'ar-15s': 8269, 'duct': 8270, 'mit': 8271, 'android': 8272, 'compared': 8273, \"'they\": 8274, 'mug': 8275, 'tune': 8276, 'fest': 8277, 'renting': 8278, 'jumping': 8279, 'drains': 8280, 'represented': 8281, 'storms': 8282, 'foia': 8283, 'values': 8284, 'finished': 8285, \"'so\": 8286, 'offend': 8287, 'regime': 8288, 'cooler': 8289, '65': 8290, 'walter': 8291, 'groom': 8292, '7,000': 8293, 'recruiter': 8294, 'elaborate': 8295, 'palestine': 8296, 'journalists': 8297, 'doubts': 8298, 'swans': 8299, 'confusion': 8300, 'capture': 8301, 'filter': 8302, \"'will\": 8303, 'superior': 8304, 'rachel': 8305, 'rachael': 8306, 'tacos': 8307, 'polls': 8308, 'sexism': 8309, 'erased': 8310, 'baking': 8311, 'yahoo': 8312, 'minor': 8313, 'ballpark': 8314, 'unveiling': 8315, 'multiple': 8316, 'cellphone': 8317, 'chemical': 8318, 'verge': 8319, 'prisons': 8320, 'further': 8321, 'regains': 8322, 'papers': 8323, 'doritos': 8324, 'mac': 8325, 'devos': 8326, 'fighters': 8327, 'forgiveness': 8328, 'prisoner': 8329, 'graduating': 8330, 'gifted': 8331, 'wealth': 8332, 'cursing': 8333, 'nicotine': 8334, 'provider': 8335, 'amazed': 8336, 'clickhole.com': 8337, 'ranks': 8338, 'disguising': 8339, 'string': 8340, 'betty': 8341, 'shoppers': 8342, 'fig': 8343, 'weary': 8344, 'sodas': 8345, 'mixed': 8346, 'violations': 8347, 'faa': 8348, 'belgian': 8349, 'mps': 8350, 'parliament': 8351, 'conflicts': 8352, 'cheeseburgers': 8353, \"'very\": 8354, 'dominatrix': 8355, 'tumor': 8356, 'rodgers': 8357, 'opener': 8358, 'drunkenly': 8359, 'nonexistent': 8360, 'haircuts': 8361, '34': 8362, 'paula': 8363, 'deen': 8364, 'lineup': 8365, 'revelations': 8366, 'bmw': 8367, 'villagers': 8368, 'pop-tarts': 8369, 'floridians': 8370, 'rifles': 8371, 'atomic': 8372, 'limiting': 8373, 'psychologists': 8374, \"'but\": 8375, 'gangnam': 8376, 'delivering': 8377, 'documentary': 8378, 'watergate': 8379, 'includes': 8380, 'salmon': 8381, 'turkmenistan': 8382, '87': 8383, 'options': 8384, 'brew': 8385, 'slam': 8386, 'swears': 8387, 'harmful': 8388, 'handcuffs': 8389, 'mccartney': 8390, 'mankind': 8391, 'overturn': 8392, 'backwards': 8393, 'programmer': 8394, 'halo': 8395, 'grandmaster': 8396, 'lower': 8397, 'behavior': 8398, 'snakes': 8399, 'madison': 8400, 'praying': 8401, 'ancestors': 8402, 'butler': 8403, 'skips': 8404, 'fountain': 8405, \"'is\": 8406, 'undermine': 8407, 'websites': 8408, 'contained': 8409, 'nudity': 8410, '2,500': 8411, 'tupac': 8412, 'congresswoman': 8413, 'shooters': 8414, 'anti-smoking': 8415, 'vanilla': 8416, 'walnuts': 8417, 'trooper': 8418, 'focused': 8419, 'criticised': 8420, 'conscious': 8421, 'religions': 8422, 'biker': 8423, 'mick': 8424, 'intellectually': 8425, 'quarantine': 8426, 'courts': 8427, 'trials': 8428, 'scream': 8429, 'hobby': 8430, 'artifacts': 8431, 'verify': 8432, 'commenter': 8433, 'skyscraper': 8434, 'speeds': 8435, 'ronald': 8436, 'africans': 8437, 'pressured': 8438, 'reaction': 8439, 'kicks': 8440, 'hall': 8441, 'betsy': 8442, 'african-americans': 8443, 'tsarnaev': 8444, 'exec': 8445, 'certificate': 8446, 'retiring': 8447, 'teammates': 8448, 'socialist': 8449, 'empathy': 8450, 'clash': 8451, 'stones': 8452, 'helen': 8453, 'mirren': 8454, 'crowded': 8455, 'guardian': 8456, '3.5': 8457, 'bacteria': 8458, 'abuser': 8459, 'looked': 8460, 'mocked': 8461, '2008': 8462, 'statement': 8463, 'avengers': 8464, 'flames': 8465, 'studies': 8466, 'deleting': 8467, 'malaysia': 8468, 'direction': 8469, 'mourns': 8470, 'labeling': 8471, 'rates': 8472, 'increased': 8473, 'topic': 8474, 'granted': 8475, 'allowance': 8476, 'stumps': 8477, 'murals': 8478, 'quebec': 8479, 'lap': 8480, 'prints': 8481, 'steer': 8482, 'camel': 8483, 'parental': 8484, 'hello': 8485, 'influential': 8486, 'high-powered': 8487, 'zion': 8488, 'williamson': 8489, 'wipes': 8490, 'shia': 8491, 'labeouf': 8492, 'fueled': 8493, 'retire': 8494, 'credits': 8495, 'flushing': 8496, 'denounces': 8497, 'cliff': 8498, 'shopper': 8499, 'anti-vax': 8500, 'brake': 8501, 'eventually': 8502, 'reuters': 8503, 'depressing': 8504, 'lamar': 8505, 'babysitter': 8506, 'abducted': 8507, 'jewelry': 8508, 'infant': 8509, 'd.c': 8510, 'convert': 8511, 'transformers': 8512, 'cartoons': 8513, 'photoshop': 8514, 'hazard': 8515, 'fossils': 8516, 'o.j': 8517, '160,000': 8518, 'essay': 8519, 'bicycle': 8520, 'transition': 8521, 'tribes': 8522, 'sacred': 8523, 'protections': 8524, 'spokesman': 8525, 'assholes': 8526, '12-hour': 8527, 'misleading': 8528, 'bubonic': 8529, 'fascinating': 8530, 'lookalike': 8531, 'jacksonville': 8532, 'spurs': 8533, 'severed': 8534, 'emotionally': 8535, 'mature': 8536, 'poisoning': 8537, 'contractors': 8538, 'wwe': 8539, 'outcome': 8540, '140': 8541, 'realises': 8542, 'involves': 8543, 'inspiration': 8544, 'blitzer': 8545, 'arming': 8546, 'bbq': 8547, 'originally': 8548, 'yoshi': 8549, 'pew': 8550, 'anti-vaxx': 8551, 'pets': 8552, 'rodents': 8553, 'intel': 8554, 'console': 8555, 'takedown': 8556, 'subject': 8557, 'detector': 8558, 'unknowingly': 8559, 'stormtrooper': 8560, 'entrance': 8561, 'va.': 8562, 'unnoticed': 8563, 'telegraph': 8564, 'spouse': 8565, 'cremated': 8566, 'valentine': 8567, 'separate': 8568, 'editing': 8569, 'pedophilia': 8570, 'brothel': 8571, 'phoning': 8572, 'ourselves': 8573, 'highly': 8574, 'shields': 8575, 'v': 8576, 'knocks': 8577, 'maguire': 8578, 'echo': 8579, 'diver': 8580, 'view': 8581, 'karate': 8582, 'wallet': 8583, 'provides': 8584, 'discussing': 8585, 'equipment': 8586, 'devil': 8587, 'argue': 8588, 'fart': 8589, 'recruit': 8590, 'oncoming': 8591, 'sephora': 8592, 'lover': 8593, 'robotic': 8594, 'natalie': 8595, 'portman': 8596, '97': 8597, 'quest': 8598, 'lowe': 8599, 'pawn': 8600, 'presence': 8601, 'skype': 8602, 'powerpoint': 8603, 'expired': 8604, 'translator': 8605, 'engagement': 8606, 'mona': 8607, 'for-profit': 8608, 'designs': 8609, 'recorded': 8610, 'mocking': 8611, 'turner': 8612, 'uranium': 8613, 'blasted': 8614, 'denounced': 8615, 'defiant': 8616, 'grandkids': 8617, 'liquor': 8618, 'prez': 8619, 'waters': 8620, 'fast-food': 8621, 'ovation': 8622, 'msnbc': 8623, 'barbara': 8624, \"'most\": 8625, 'flamethrowers': 8626, 'exams': 8627, '2002': 8628, 'falsely': 8629, 'ambitious': 8630, 'arlington': 8631, 'consoles': 8632, 'dorian': 8633, 'salaries': 8634, 'condemns': 8635, 'ruined': 8636, 'traits': 8637, 'stunt': 8638, 'contributions': 8639, 'prompted': 8640, 'landscaping': 8641, 'pedestrian': 8642, 'conclude': 8643, 'addressed': 8644, 'ibm': 8645, 'traded': 8646, 'emotions': 8647, 'gestures': 8648, 'performing': 8649, \"'best\": 8650, 'swastika': 8651, 'scratch-off': 8652, 'publication': 8653, 'disgusting': 8654, 'defecating': 8655, '1.5': 8656, 'ecosystem': 8657, 'server': 8658, 'impressive': 8659, 'touts': 8660, 'minorities': 8661, 'reluctantly': 8662, 'democratic': 8663, 'notorious': 8664, 'mermaids': 8665, 'parasite': 8666, 'derby': 8667, '56': 8668, 'dylan': 8669, 'executed': 8670, 'sprawling': 8671, 'cellar': 8672, 'julius': 8673, 'weirdo': 8674, 'aide': 8675, 'roomba': 8676, \"'after\": 8677, 'psychopath': 8678, '49ers': 8679, 'dunk': 8680, 'pages': 8681, 'c-section': 8682, 'prodigy': 8683, 'degrees': 8684, 'coroner': 8685, 'contracts': 8686, 'usable': 8687, 'kayak': 8688, 'thefts': 8689, 'chops': 8690, 'lightly': 8691, 'fancy': 8692, 'pad': 8693, 'homelessness': 8694, 'homosexual': 8695, 'teaches': 8696, 'mention': 8697, 'disgruntled': 8698, 'unruly': 8699, 'pringles': 8700, \"'at\": 8701, 'invent': 8702, 'emissions': 8703, 'sin': 8704, 'ncaa': 8705, 'rack': 8706, 'hughes': 8707, 'denying': 8708, 'dangling': 8709, 'petty': 8710, 'gif': 8711, 'lennon': 8712, 'atheism': 8713, 'pooper': 8714, 'superintendent': 8715, 'pencils': 8716, 'battling': 8717, 'inner': 8718, \"'why\": 8719, 'convict': 8720, 'ski': 8721, 'draws': 8722, 'starwipe': 8723, 'daniels': 8724, 'illuminati': 8725, 'project': 8726, 'brock': 8727, 'experiment': 8728, 'shifts': 8729, 'conception': 8730, 'freaks': 8731, 'sheffield': 8732, 'reserves': 8733, 'sneaks': 8734, 'full-body': 8735, 'filed': 8736, 'spider-man': 8737, 'comfort': 8738, 'storm': 8739, 'bagel': 8740, 'craigslist': 8741, 'impregnate': 8742, 'coaches': 8743, 'garages': 8744, 'arrival': 8745, \"'only\": 8746, 'sand': 8747, 'apollo': 8748, 'burden': 8749, 'swan': 8750, 'household': 8751, 'blocked': 8752, 'tug-of-war': 8753, 'cancellation': 8754, 'explicitly': 8755, 'undergo': 8756, 'sensitivity': 8757, 'brave': 8758, '23-year-old': 8759, 'pineapple': 8760, 'slits': 8761, 'safer': 8762, 'hershey': 8763, 'cinnamon': 8764, \"'sick\": 8765, \"'nazi\": 8766, 'raccoons': 8767, 'boot': 8768, 'comply': 8769, 'worship': 8770, 'bingo': 8771, 'misspells': 8772, 'answers': 8773, 'craze': 8774, 'pencil': 8775, 'electronics': 8776, 'filling': 8777, 'improves': 8778, 'supermarkets': 8779, 'enemy': 8780, 'statues': 8781, 'mexicans': 8782, 'robertson': 8783, 'unemployment': 8784, 'testify': 8785, 'associates': 8786, 'white-hot': 8787, 'sphere': 8788, 'front-runner': 8789, 'stray': 8790, 'difficulty': 8791, 'spotify': 8792, 'surviving': 8793, 'viewed': 8794, 'material': 8795, 'bruno': 8796, 'staircase': 8797, 'youtuber': 8798, 'veterinarian': 8799, 'goddamn': 8800, 'uploaded': 8801, \"'get\": 8802, 'googled': 8803, 'testifies': 8804, 'disturbed': 8805, 'cougar': 8806, 'gm': 8807, 'durant': 8808, 'clears': 8809, 'realm': 8810, 'addictive': 8811, 'doubling': 8812, 'interracial': 8813, 'workshop': 8814, 'jerks': 8815, 'crumbling': 8816, 'happier': 8817, 'audio': 8818, 'werewolf': 8819, 'mummy': 8820, 'emily': 8821, 'olive': 8822, 'inclusive': 8823, 'ranch': 8824, 'races': 8825, 'accomplish': 8826, 'phuc': 8827, 'dat': 8828, 'bich': 8829, 'knot': 8830, 'statute': 8831, 'limitations': 8832, 'yeah': 8833, 'virgins': 8834, 'extended': 8835, 'wildly': 8836, 'shore': 8837, 'carly': 8838, 'fiorina': 8839, 'sacrifice': 8840, 'mild': 8841, 'marks': 8842, 'connecticut': 8843, 'accusing': 8844, 'katy': 8845, 'upskirting': 8846, 'protects': 8847, 'anti-nazi': 8848, '73': 8849, 'vuitton': 8850, 'underwater': 8851, 'sticker': 8852, '1993': 8853, 'fiction': 8854, 'parasitic': 8855, 'freddie': 8856, 'mercury': 8857, 'seeds': 8858, 'denmark': 8859, 'knee': 8860, 'aroused': 8861, 'appearing': 8862, 'tricking': 8863, 'evans': 8864, 'damaged': 8865, 'deranged': 8866, 'n-word': 8867, 'resemble': 8868, 'fetish': 8869, 'inventing': 8870, 'robe': 8871, 'workplace': 8872, 'premium': 8873, 'mailing': 8874, 'profits': 8875, 'fry': 8876, 'closet': 8877, 'awful': 8878, 'plugs': 8879, 'lovers': 8880, 'divorces': 8881, 'reader': 8882, 'safest': 8883, 'broadway': 8884, 'hardcore': 8885, 'lice': 8886, 'bp': 8887, 'revolution': 8888, 'latinos': 8889, 'panama': 8890, 'goodall': 8891, 'folks': 8892, 'announcement': 8893, 'incompetence': 8894, 'miracles': 8895, 'introducing': 8896, 'exists': 8897, 'hug': 8898, 'reference': 8899, 'reincarnation': 8900, 'wean': 8901, 'sam': 8902, 'souvenir': 8903, 'absent': 8904, 'comb': 8905, 'reunite': 8906, 'paraplegic': 8907, 'violated': 8908, 'assistance': 8909, 'missiles': 8910, 'petrol': 8911, 'crashing': 8912, 'butterfly': 8913, 'underrated': 8914, 'disease': 8915, 'fourth-grader': 8916, 'lotto': 8917, 'meters': 8918, 'stab': 8919, 'snowball': 8920, 'enemies': 8921, 'updated': 8922, 'closest': 8923, 'buttocks': 8924, 'tastes': 8925, 'plagiarism': 8926, 'metres': 8927, 'intelligent': 8928, 'scenes': 8929, 'campaigning': 8930, 'core': 8931, 'imam': 8932, 'chokes': 8933, 'vera': 8934, 'manuscript': 8935, 'renamed': 8936, 'indicate': 8937, 'nursery': 8938, 'knives': 8939, 'mailed': 8940, 'resignation': 8941, 'rewarded': 8942, 'poacher': 8943, 'longest': 8944, 'kojima': 8945, 'assume': 8946, 'facility': 8947, 'controls': 8948, 'zoos': 8949, 'crops': 8950, 'monsanto': 8951, 'gay-friendly': 8952, 'fax': 8953, 'musical': 8954, 'roller': 8955, 'moby': 8956, 'identified': 8957, 'aware': 8958, 'satan': 8959, 'monopoly': 8960, 'ginger': 8961, 'makers': 8962, 'hellmann': 8963, 'wow': 8964, 'tend': 8965, 'arriving': 8966, 'indonesia': 8967, 'sicily': 8968, 'elect': 8969, 'counseling': 8970, 'environmentalists': 8971, 'curing': 8972, 'honda': 8973, 'shaken': 8974, 'profiles': 8975, '48': 8976, 'knox': 8977, 'fetal': 8978, 'menstrual': 8979, 'accuse': 8980, 'evening': 8981, 'tap': 8982, 'tycoon': 8983, 'meryl': 8984, 'streep': 8985, 'acceptance': 8986, 'youngest': 8987, 'mowing': 8988, 'sweater': 8989, 'cooked': 8990, 'salesman': 8991, 'long-term': 8992, 'reunited': 8993, 'bigfoot': 8994, 'binge': 8995, 'jaw': 8996, 'portion': 8997, 'jockey': 8998, 'introduced': 8999, 'blasphemy': 9000, '246': 9001, 'treats': 9002, 'seafood': 9003, 'easily': 9004, 'chores': 9005, 'addition': 9006, 'shallow': 9007, 'joel': 9008, 'osteen': 9009, 'washed': 9010, 'moment': 9011, 'prized': 9012, 'masters': 9013, 'yelled': 9014, 'haunting': 9015, 'camels': 9016, 'panties': 9017, 'centers': 9018, 'saddam': 9019, 'performs': 9020, 'audi': 9021, 'modified': 9022, 'flop': 9023, 'elf': 9024, 'patron': 9025, 'monkeys': 9026, 'opposed': 9027, 'vaccinations': 9028, 'mega': 9029, 'ignoring': 9030, 'dodges': 9031, 'unrest': 9032, 'salvador': 9033, 'inspection': 9034, 'selection': 9035, 'producer': 9036, 'umpire': 9037, 'fingerprints': 9038, 'dems': 9039, 'grab': 9040, 'curb': 9041, 'astronauts': 9042, 'jokes': 9043, 'presidents': 9044, '750,000': 9045, 'surrender': 9046, 're-election': 9047, 'pier': 9048, 'blasts': 9049, 'brewer': 9050, 'nikki': 9051, 'viable': 9052, 'expands': 9053, 'adopts': 9054, 'renames': 9055, 'permits': 9056, 'ants': 9057, 'lb': 9058, 'scrotum': 9059, 'accounting': 9060, 'concept': 9061, 'father-in-law': 9062, 'hopeful': 9063, 'hail': 9064, 'bra': 9065, \"'look\": 9066, 'liam': 9067, 'accepts': 9068, 'roots': 9069, 'tearing': 9070, 'oks': 9071, 'hacking': 9072, 'category': 9073, 'alexander': 9074, 'telephone': 9075, \"'star\": 9076, 'trek': 9077, 'macy': 9078, 'shaquille': 9079, 'rivers': 9080, 'vicar': 9081, 'hospitalised': 9082, 'bum': 9083, 'consumer': 9084, 'unpopular': 9085, 'measures': 9086, 'socks': 9087, 'molesting': 9088, 'heroes': 9089, 'circumcision': 9090, 'sworn': 9091, 'aviv': 9092, 'scheduled': 9093, 'lean': 9094, 'debunk': 9095, 'circumstances': 9096, 'finnish': 9097, 'donor': 9098, 'consultant': 9099, 'whisperer': 9100, 'erupts': 9101, 'laughter': 9102, 'wages': 9103, 'muscles': 9104, 'identical': 9105, 'satirical': 9106, 'rpg': 9107, 'peers': 9108, 'striker': 9109, 'outback': 9110, '6-month': 9111, 'relations': 9112, 'filing': 9113, 'mutant': 9114, 'terminal': 9115, 'noticed': 9116, 'aurora': 9117, 'rotation': 9118, 'reform': 9119, 'westminster': 9120, 'repealed': 9121, 'goodell': 9122, 'vaccinating': 9123, 'modest': 9124, 'rub': 9125, 'accountant': 9126, 'advertises': 9127, 'mormon': 9128, 'naval': 9129, 'sporting': 9130, 'missionary': 9131, \"'ma'am\": 9132, 'handbag': 9133, 'sensation': 9134, 'pao': 9135, 'balanced': 9136, 'politely': 9137, 'partially': 9138, 'sole': 9139, 'g': 9140, 'reckless': 9141, 'caps': 9142, 'blunt': 9143, '45-minute': 9144, 'officiant': 9145, 'creep': 9146, 'panels': 9147, 'moscow': 9148, 'navalny': 9149, 'destination': 9150, 'savior': 9151, 'tirelessly': 9152, 'essex': 9153, 'cough': 9154, 'ominous': 9155, 'robbers': 9156, 'rejected': 9157, 'harass': 9158, '78': 9159, 'moderator': 9160, 'getaway': 9161, 'impoverished': 9162, 'toaster': 9163, 'figured': 9164, 'edition': 9165, '2021': 9166, '300,000': 9167, 'wake-up': 9168, 'harassing': 9169, 'ridiculous': 9170, 'mostly': 9171, 'exposing': 9172, 'randy': 9173, 'wa': 9174, 'adhd': 9175, 'flint': 9176, 'doping': 9177, 'paranoid': 9178, 'besides': 9179, 'lobbyist': 9180, 'understands': 9181, 'variety': 9182, 'utility': 9183, 'plots': 9184, 'dwayne': 9185, 'possibility': 9186, 'jew': 9187, 'buckets': 9188, 'collision': 9189, 'pitbull': 9190, 'particular': 9191, 'championship': 9192, 'viciously': 9193, 'pepsi': 9194, 'dazed': 9195, 'penetrated': 9196, 'references': 9197, 'worn': 9198, 'sliced': 9199, 'slice': 9200, 'pajamas': 9201, 'extensive': 9202, 'fills': 9203, 'sparking': 9204, 'ashton': 9205, 'kutcher': 9206, 'suspicion': 9207, 'bypass': 9208, 'coaching': 9209, 'barrier': 9210, 'reef': 9211, 'beverage': 9212, 'abraham': 9213, 'unofficial': 9214, 'messi': 9215, 'diagnosed': 9216, 'june': 9217, 'colombian': 9218, 'crushing': 9219, 'lip': 9220, 'stayed': 9221, 'restores': 9222, 'fla.': 9223, 'café': 9224, 'agreed': 9225, 'bowser': 9226, 'ant': 9227, 'updates': 9228, 'kissed': 9229, 'cctv': 9230, 'erdogan': 9231, 'universal': 9232, 'crabs': 9233, 'bengal': 9234, 'exorcists': 9235, 'nun': 9236, 'braces': 9237, '6-hour': 9238, 'vigil': 9239, 'waking': 9240, 'du': 9241, 'rappers': 9242, 'cpr': 9243, 'enlargement': 9244, 'projectiles': 9245, 'depicted': 9246, 'registration': 9247, 'cord': 9248, 'deez': 9249, 'lance': 9250, 'clogged': 9251, 'enchanted': 9252, \"'act\": 9253, 'fa': 9254, 'betting': 9255, 'arrow': 9256, 'goggles': 9257, \"'went\": 9258, 'deodorant': 9259, 'wrestler': 9260, 'first-grader': 9261, 'rugs': 9262, 'clarify': 9263, 'earliest': 9264, '1000': 9265, 'publishes': 9266, 'courageous': 9267, \"'unlimited\": 9268, 'enclosure': 9269, 'breivik': 9270, 'intruder': 9271, 'plymouth': 9272, 'deere': 9273, 'jerk': 9274, 'hated': 9275, 'proudly': 9276, 'tgi': 9277, 'fridays': 9278, 'shy': 9279, 'merger': 9280, 'gaffe': 9281, 'rodeo': 9282, 'motel': 9283, 'sisters': 9284, \"'air\": 9285, 'kardashians': 9286, 'low-income': 9287, 'lube': 9288, 'publishing': 9289, 'welcoming': 9290, 'nonstop': 9291, 'plagues': 9292, 'clues': 9293, 'deploy': 9294, 'cola': 9295, 'creatures': 9296, 'distant': 9297, 'tolerate': 9298, 'smallest': 9299, \"'miracle\": 9300, 'laboratory': 9301, 'particularly': 9302, 'johns': 9303, 'styrofoam': 9304, 'scrolls': 9305, 'shapes': 9306, '149': 9307, 'bombings': 9308, 'insanity': 9309, 'half-assed': 9310, 'attends': 9311, 'shovel': 9312, 'headstone': 9313, \"'did\": 9314, 'masked': 9315, 'gunmen': 9316, 'unsuspecting': 9317, 'organ': 9318, 'utilities': 9319, 'picnic': 9320, 'twitch': 9321, 'sized': 9322, 'residence': 9323, 'curtain': 9324, 'lasers': 9325, 'bts': 9326, 'communities': 9327, 'supportive': 9328, 'adobe': 9329, 'meaningless': 9330, 'editorial': 9331, 'upgrade': 9332, 'poland': 9333, 'trousers': 9334, 'dismembered': 9335, 'anxiously': 9336, 'targeting': 9337, 'drive-by': 9338, 'kart': 9339, 'hairstyle': 9340, 'abroad': 9341, 'swimsuit': 9342, 'scientifically': 9343, 'hails': 9344, 'ivy': 9345, 'startups': 9346, 'tums': 9347, 'thousand': 9348, 'hernandez': 9349, 'chants': 9350, 'hare': 9351, 'habit': 9352, 'alley': 9353, 'quoting': 9354, 'pyramids': 9355, 'crusade': 9356, 'schoolboy': 9357, 'testicle': 9358, 'kinda': 9359, 'weeps': 9360, 'kazakh': 9361, 'late-night': 9362, 'epipen': 9363, 'drawn': 9364, 'lengthy': 9365, '17-year-old': 9366, 'marked': 9367, 'marines': 9368, 'disappointing': 9369, 'humiliating': 9370, 'yours': 9371, 'danny': 9372, 'census': 9373, 'troubled': 9374, '3rd': 9375, 'chronotaur': 9376, 'contenders': 9377, 'implants': 9378, 'applying': 9379, 'rowdy': 9380, 'rail': 9381, 'canvas': 9382, 'suburb': 9383, 'charlottesville': 9384, 'merriam-webster': 9385, 'dictionary': 9386, 'indicates': 9387, 'lorraine': 9388, 'expecting': 9389, 'ward': 9390, 'owes': 9391, 'noam': 9392, 'chomsky': 9393, 'scotch': 9394, 'egging': 9395, 'inches': 9396, 'shameless': 9397, 'typing': 9398, 'hurts': 9399, 'afghan': 9400, 'simon': 9401, 'privileged': 9402, 'boyband': 9403, 'chlamydia': 9404, 'blockchain': 9405, 'consequences': 9406, 'recognized': 9407, 'sentencing': 9408, 'volkswagen': 9409, 'independent': 9410, 'critical': 9411, 'repeated': 9412, 'obesity': 9413, 'unsolicited': 9414, 'withholding': 9415, 'winfrey': 9416, 'ovechkin': 9417, 'bro': 9418, 'overjoyed': 9419, 'virtual': 9420, 'bottled': 9421, 'heir': 9422, 'markets': 9423, 'confess': 9424, 'carjacker': 9425, 'portable': 9426, 'reducing': 9427, 'smuggler': 9428, 'daytime': 9429, 'cp': 9430, 'hedgehogs': 9431, 'injures': 9432, 'moments': 9433, 'behaving': 9434, 'alligator': 9435, 'psychiatric': 9436, 'sneaking': 9437, 'vulnerabilities': 9438, 'start-up': 9439, 'delicious': 9440, 'tasty': 9441, 'screamed': 9442, '60,000': 9443, 'ups': 9444, 'nuns': 9445, 'surfing': 9446, 'odor': 9447, 'abomination': 9448, 'distraction': 9449, 'interviews': 9450, 'expectations': 9451, 'manti': 9452, 'civilization': 9453, 'ash': 9454, 'canned': 9455, 'deli': 9456, 'singles': 9457, 'exotic': 9458, 'mill': 9459, 'verse': 9460, 'awaiting': 9461, 'siblings': 9462, 'hopefuls': 9463, 'defamation': 9464, 'maid': 9465, 'homeland': 9466, 'miserable': 9467, 'sweeping': 9468, 'coco': 9469, 'procession': 9470, 'keystone': 9471, 'texans': 9472, 'actively': 9473, 'chelsea': 9474, 'spit': 9475, 'rope': 9476, 'unexpectedly': 9477, 'stan': 9478, 'witches': 9479, 'cannibal': 9480, 'ahmed': 9481, 'anecdote': 9482, 'interactions': 9483, 'existed': 9484, 'rushing': 9485, 'endorse': 9486, 'judy': 9487, 'escalates': 9488, 'employers': 9489, 'anti-corruption': 9490, 'solving': 9491, 'kittens': 9492, 'grudge': 9493, 'champ': 9494, 'legalizes': 9495, '420': 9496, '41': 9497, 'richer': 9498, 'pursuing': 9499, 'contemplating': 9500, '11,000': 9501, 'paso': 9502, 'bulge': 9503, 'd-day': 9504, 'mixes': 9505, 'chick': 9506, 'mia': 9507, 'embedded': 9508, 'participants': 9509, 'servant': 9510, 'climbers': 9511, \"'living\": 9512, 'kool-aid': 9513, 'october': 9514, 'import': 9515, \"'law\": 9516, 'revlon': 9517, '26-year-old': 9518, 'kay': 9519, 'f.b.i': 9520, 'frame': 9521, 'typo': 9522, 'gilmore': 9523, 'immortality': 9524, 'loitering': 9525, 'mushroom': 9526, 'glory': 9527, 'invasive': 9528, 'overdoses': 9529, 'retiree': 9530, 'amusement': 9531, 'hahah': 9532, 'spineless': 9533, 'weasel': 9534, 'willy': 9535, 'garland': 9536, 'worries': 9537}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1.4 Building a Dataset Class"
      ],
      "metadata": {
        "id": "5fCFfEHv1hnI"
      },
      "id": "5fCFfEHv1hnI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-qTQQa2FEIe"
      },
      "source": [
        "PyTorch has custom Dataset Classes that have very useful extentions, we want to turn our current pandas DataFrame into a subclass of Dataset so that we can iterate and sample through it for minibatch updates. **In the following cell, fill out the HeadlineDataset class.** Refer to PyTorch documentation on [Dataset Classes](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) \n",
        "for help."
      ],
      "id": "8-qTQQa2FEIe"
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "from torch.utils.data import Dataset\n",
        "# END - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "\n",
        "# HeadlineDataset\n",
        "# This class takes a Pandas DataFrame and wraps in a Torch Dataset.\n",
        "# Read more about Torch Datasets here: \n",
        "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "# \n",
        "class HeadlineDataset(Dataset):\n",
        "    \n",
        "    # initialize this class with appropriate instance variables\n",
        "    def __init__(self, vocab, df, max_length=50):\n",
        "        # For this method: We would *strongly* recommend storing the dataframe \n",
        "        #                  itself as an instance variable, and keeping this method\n",
        "        #                  very simple. Leave processing to __getitem__. \n",
        "        #              \n",
        "        #                  Sometimes, however, it does make sense to preprocess in \n",
        "        #                  __init__. If you are curious as to why, read the aside at the \n",
        "        #                  bottom of this cell.\n",
        "        # \n",
        "        \n",
        "        ## YOUR CODE STARTS HERE (~3 lines of code) ##\n",
        "        self.vocab = vocab\n",
        "        self.df = df\n",
        "        self.max_length = max_length\n",
        "        \n",
        "\n",
        "        return \n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "    \n",
        "    # return the length of the dataframe instance variable\n",
        "    def __len__(self):\n",
        "\n",
        "        df_len = None\n",
        "        ## YOUR CODE STARTS HERE (1 line of code) ##\n",
        "        df_len = self.df.shape[0]\n",
        "\n",
        "\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "        return df_len\n",
        "\n",
        "    # __getitem__\n",
        "    # \n",
        "    # Converts a dataframe row (row[\"tokenized\"]) to an encoded torch LongTensor,\n",
        "    # using our vocab map we created using generate_vocab_map. Restricts the encoded \n",
        "    # headline length to max_length.\n",
        "    # \n",
        "    # The purpose of this method is to convert the row - a list of words - into\n",
        "    # a corresponding list of numbers.\n",
        "    #\n",
        "    # i.e. using a map of {\"hi\": 2, \"hello\": 3, \"UNK\": 0}\n",
        "    # this list [\"hi\", \"hello\", \"NOT_IN_DICT\"] will turn into [2, 3, 0]\n",
        "    #\n",
        "    # returns: \n",
        "    # tokenized_word_tensor - torch.LongTensor \n",
        "    #                         A 1D tensor of type Long, that has each\n",
        "    #                         token in the dataframe mapped to a number.\n",
        "    #                         These numbers are retrieved from the vocab_map\n",
        "    #                         we created in generate_vocab_map. \n",
        "    # \n",
        "    #                         **IMPORTANT**: if we filtered out the word \n",
        "    #                         because it's infrequent (and it doesn't exist \n",
        "    #                         in the vocab) we need to replace it w/ the UNK \n",
        "    #                         token\n",
        "    # \n",
        "    # curr_label            - int\n",
        "    #                         Binary 0/1 label retrieved from the DataFrame.\n",
        "    # \n",
        "    def __getitem__(self, index: int):\n",
        "        tokenized_word_tensor = None\n",
        "        curr_label            = None\n",
        "        ## YOUR CODE STARTS HERE (~3-7 lines of code) ##\n",
        "        vocab = self.vocab\n",
        "        curr_data = self.df.iloc[index][\"tokenized\"]\n",
        "        tokenized_word_tensor = torch.LongTensor([vocab[word] for word in curr_data \n",
        "                                                  if word in vocab])\n",
        "\n",
        "        curr_label = self.df.iloc[index][\"label\"]\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "        return tokenized_word_tensor, curr_label\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# Completely optional aside on preprocessing in __init__.\n",
        "# \n",
        "# Sometimes the compute bottleneck actually ends up being in __getitem__.\n",
        "# In this case, you'd loop over your dataset in __init__, passing data \n",
        "# to __getitem__ and storing it in another instance variable. Then,\n",
        "# you can simply return the preprocessed data in __getitem__ instead of\n",
        "# doing the preprocessing.\n",
        "# \n",
        "# There is a tradeoff though: can you think of one?\n",
        "# "
      ],
      "metadata": {
        "id": "tqt9q92J1QKK"
      },
      "id": "tqt9q92J1QKK",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KuLtIOAZFEIe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import RandomSampler\n",
        "\n",
        "train_dataset = HeadlineDataset(train_vocab, train_df)\n",
        "val_dataset   = HeadlineDataset(train_vocab, val_df)\n",
        "test_dataset  = HeadlineDataset(train_vocab, test_df)\n",
        "\n",
        "# Now that we're wrapping our dataframes in PyTorch datsets, we can make use of PyTorch Random Samplers, they'll\n",
        "#   define how our DataLoaders sample elements from the HeadlineDatasets  \n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "val_sampler   = RandomSampler(val_dataset)\n",
        "test_sampler  = RandomSampler(test_dataset)"
      ],
      "id": "KuLtIOAZFEIe"
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataset[1][0]))\n",
        "print(train_dataset[1][0].dtype)\n",
        "print(train_dataset[1][1].dtype)\n",
        "print(len(train_dataset))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVVIwZh1IIdB",
        "outputId": "c8a713f7-ff9d-4ca6-a99c-6a19fe62b78b"
      },
      "id": "cVVIwZh1IIdB",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.int64\n",
            "int64\n",
            "19200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 1.5 Finalizing our DataLoader"
      ],
      "metadata": {
        "id": "n9iBiSKF1yXA"
      },
      "id": "n9iBiSKF1yXA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfXSbxoFFEIe"
      },
      "source": [
        "We can now use PyTorch DataLoaders to batch our data for us. **In the following cell fill out collate_fn.** Refer to PyTorch documentation on [DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) for help."
      ],
      "id": "lfXSbxoFFEIe"
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "# END - DO NOT CHANGE THESE IMPORTS/CONSTANTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "\n",
        "# collate_fn\n",
        "# This function is passed as a parameter to Torch DataSampler. collate_fn collects\n",
        "# batched rows, in the form of tuples, from a DataLoader and applies some final \n",
        "# pre-processing.\n",
        "#\n",
        "# Objective:\n",
        "# In our case, we need to take the batched input array of 1D tokenized_word_tensors, \n",
        "# and create a 2D tensor that's padded to be the max length from all our tokenized_word_tensors \n",
        "# in a batch. We're moving from a Python array of tuples, to a padded 2D tensor. \n",
        "#\n",
        "# *HINT*: you're allowed to use torch.nn.utils.rnn.pad_sequence (ALREADY IMPORTED)\n",
        "# \n",
        "# Finally, you can read more about collate_fn here: https://pytorch.org/docs/stable/data.html\n",
        "#\n",
        "# args: \n",
        "# batch - PythonArray[tuple(tokenized_word_tensor: 1D Torch.LongTensor, curr_label: int)]\n",
        "#         len(batch) == BATCH_SIZE\n",
        "# \n",
        "# returns:\n",
        "# padded_tokens - 2D LongTensor of shape (BATCH_SIZE, max len of all tokenized_word_tensor))\n",
        "# y_labels      - 1D FloatTensor of shape (BATCH_SIZE)\n",
        "# \n",
        "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
        "    padded_tokens, y_labels = None, None\n",
        "    ## YOUR CODE STARTS HERE (~4-8 lines of code) ##\n",
        "    y_labels = torch.FloatTensor([data[1] for data in batch])\n",
        "    \n",
        "    pre_tokens = [data[0] for data in batch]\n",
        "    padded_tokens = pad_sequence(pre_tokens, True, padding_value)    \n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return padded_tokens, y_labels"
      ],
      "metadata": {
        "id": "Zp1aQAvn1_mz"
      },
      "id": "Zp1aQAvn1_mz",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OayoJRTeFEIf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
        "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
        "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "id": "OayoJRTeFEIf"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pidbg12AFEIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45372ae8-0f53-4190-8669-d10a00de1866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 174, 2903, 9461,  321,  563,   36, 2202, 1845, 2854,   12,  223,   33,\n",
            "         7473,    0,    0,    0,    0,    0,    0],\n",
            "        [  11, 1086,  829, 6476,  411,   36,   37,   51,  158, 3298,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [2698, 8440,   33,  321,   33,  274,   52,   41,  617, 4959,   12, 1017,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [  25,  883,  289,  552,  301,   61,  181,  593,  289, 2774, 2775,   36,\n",
            "         4604, 5446,   36,  113, 1095,   52,    3],\n",
            "        [3472, 4372, 1332, 2430,   52,   57, 8872,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [4223,  120,   15,  431,  217, 5503,   24,  608,   52,  926,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [3019,   61, 3210, 2774, 6017, 6636, 4447,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [3123, 4184, 3475,  217, 5633, 8439,   52, 8594, 5089,   21,  605,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [3283,  411,   61, 2461,  158,  476, 3157,  940, 3310, 2128, 6877,  411,\n",
            "           33,  343,  327,   21, 7368,  301,    0],\n",
            "        [  68,  147, 2389,   33, 7046,  952, 8886,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [1642, 5893,   61, 5898,  977, 8704,  133,  263,   56,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [2710,  165,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [  11,   21, 1022, 6182,  619,  148,  149, 3427,  128, 3880,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [5754, 4651,  321,   21, 1652,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [7450, 6727,  770, 5105, 3296,   36,   81,  784, 6871,  784,  326, 4128,\n",
            "           30,    0,    0,    0,    0,    0,    0],\n",
            "        [1281,   36, 6892, 3256, 1753, 1011,   24, 2486, 4671,   30,   31, 2122,\n",
            "          977, 5918,    0,    0,    0,    0,    0]]) tensor([1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.])\n",
            "x: torch.Size([16, 19])\n",
            "y: torch.Size([16])\n",
            "150\n"
          ]
        }
      ],
      "source": [
        "# Use this to test your collate_fn implementation.\n",
        "# You can look at the shapes of x and y or put print statements in collate_fn while running this snippet\n",
        "\n",
        "for x, y in test_iterator:\n",
        "     print(x, y)\n",
        "     print(f'x: {x.shape}')\n",
        "     print(f'y: {y.shape}')\n",
        "     print(len(test_iterator))\n",
        "     break\n",
        "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "id": "pidbg12AFEIf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWLK7T1uFEIg"
      },
      "source": [
        "### Part 2: Modeling [10 pts]\n",
        "Let's move to modeling, now that we have dataset iterators that batch our data for us. In the following code block, you'll build a feed-forward neural network implementing a neural bag-of-words baseline, NBOW-RAND, described in section 2.1 of [this paper](https://www.aclweb.org/anthology/P15-1162.pdf). You'll find [this](https://pytorch.org/docs/stable/nn.html) page useful for understanding the different layers and [this](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html) page useful for how to put them into action.\n",
        "\n",
        "The core idea behind this baseline is that after we embed each word for a document, we average the embeddings to produce a single vector that hopefully captures some general information spread across the sequence of embeddings. This means we first turn each document of length *n* into a matrix of *nxd*, where *d* is the dimension of the embedding. Then we average this matrix to produce a vector of length *d*, summarizing the contents of the document and proceed with the rest of the network. \n",
        "\n",
        "While you're working through this implementation, keep in mind how the dimensions change and what each axes represents, as documents will be passed in as minibatches requiring careful selection of which axes you apply certain operations too. You're more than welcome to experiment with the architecture of this network as well outside of the basic setup we describe below, such as adding in other layers, to see how this changes your results."
      ],
      "id": "BWLK7T1uFEIg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2.1 Define the NBOW model class"
      ],
      "metadata": {
        "id": "pZDPs0Sf-H3V"
      },
      "id": "pZDPs0Sf-H3V"
    },
    {
      "cell_type": "code",
      "source": [
        "# BEGIN - DO NOT CHANGE THESE IMPORTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "import torch.nn as nn\n",
        "# END - DO NOT CHANGE THESE IMPORTS OR IMPORT ADDITIONAL PACKAGES.\n",
        "\n",
        "class NBOW(nn.Module):\n",
        "    # Instantiate layers for your model-\n",
        "    # \n",
        "    # Your model architecture will be a feed-forward neural network.\n",
        "    #\n",
        "    # You'll need 3 nn.Modules at minimum\n",
        "    # 1. An embeddings layer (see nn.Embedding)\n",
        "    # 2. A linear layer (see nn.Linear)\n",
        "    # 3. A sigmoid output (see nn.Sigmoid)\n",
        "    #\n",
        "    # HINT: In the forward step, the BATCH_SIZE is the first dimension.\n",
        "    # \n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        ## YOUR CODE STARTS HERE (~4 lines of code) ##\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
        "        self.W = nn.Linear(embedding_dim, 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "        \n",
        "    # Complete the forward pass of the model.\n",
        "    #\n",
        "    # Use the output of the embedding layer to create\n",
        "    # the average vector, which will be input into the \n",
        "    # linear layer.\n",
        "    # \n",
        "    # args:\n",
        "    # x - 2D LongTensor of shape (BATCH_SIZE, max len of all tokenized_word_tensor))\n",
        "    #     This is the same output that comes out of the collate_fn function you completed\n",
        "    def forward(self, x):\n",
        "        ## YOUR CODE STARTS HERE (~4-5 lines of code) ##\n",
        "        embedded = self.embedding(x)\n",
        "        output = self.W(embedded)\n",
        "        output = self.activation(output)\n",
        "        \n",
        "        \n",
        "\n",
        "        return output\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "    "
      ],
      "metadata": {
        "id": "jzGx2q0jLqyU"
      },
      "execution_count": 17,
      "outputs": [],
      "id": "jzGx2q0jLqyU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2.2 Initialize the NBOW classification model\n",
        "\n",
        "Since the NBOW model is rather basic, assuming you haven't added any additional layers, there's really only one hyperparameter for the model architecture: the size of the embedding dimension. \n",
        "\n",
        "The vocab_size parameter here is based on the number of unique words kept in the vocab after removing those occurring too infrequently, so this is determined by our dataset and is in turn not a true hyperparameter (though the cutoff we used previously might be). The embedding_dim parameter dictates what size vector each word can be embedded as. \n",
        "\n",
        "If you added additional linear layers to the NBOW model then the input/output dimensions of each would be considered a hyperparameter you might want to experiment with. While the sizes are constrained based on previous & following layers (the number of dimensions need to match for the matrix multiplication), whatever sequence you used could still be tweaked in various ways. \n",
        "\n",
        "A special note concerning the model initialization: We're specifically sending the model to the device set in Part 1, to speed up training if the GPU is available. **Be aware**, you'll have to ensure other tensors are on the same device inside your training and validation loops. "
      ],
      "metadata": {
        "id": "xltosIzM-SP2"
      },
      "id": "xltosIzM-SP2"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_HQWUu-ZFEIg"
      },
      "outputs": [],
      "source": [
        "model = NBOW(vocab_size    = len(train_vocab.keys()),\n",
        "             embedding_dim = 300).to(device)"
      ],
      "id": "_HQWUu-ZFEIg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 2.3 Instantiate the loss function and optimizer"
      ],
      "metadata": {
        "id": "C4CZnj1f-da-"
      },
      "id": "C4CZnj1f-da-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aXi8nA0FEIh"
      },
      "source": [
        "In the following cell, **select and instantiate an appropriate loss function and optimizer.** \n",
        "\n",
        "Hint: we already use sigmoid in our model. What loss functions are availible for binary classification? Feel free to look at [PyTorch docs](https://pytorch.org/docs/stable/nn.html#loss-functions) for help!"
      ],
      "id": "9aXi8nA0FEIh"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "w98UvlXxFEIh"
      },
      "outputs": [],
      "source": [
        "#while Adam is already imported, you can try other optimizers as well\n",
        "from torch.optim import Adam\n",
        "\n",
        "criterion, optimizer = None, None\n",
        "### YOUR CODE GOES HERE ###\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "id": "w98UvlXxFEIh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, we have a NBOW model to classify headlines as being real or fake and a loss function/optimizer to train the model using the training dataset."
      ],
      "metadata": {
        "id": "hUXBtqPEjiRe"
      },
      "id": "hUXBtqPEjiRe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLeTa8wFEIh"
      },
      "source": [
        "### Part 3: Training and Evaluation [10 Points]\n",
        "The final part of this HW involves training the model, and evaluating it at each epoch. **Fill out the train and test loops below. Treat real headlines as True, and Onion headlines as False.**  Feel free to look at [PyTorch docs](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html) for help!"
      ],
      "id": "bVLeTa8wFEIh"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vganx5fCFEIh"
      },
      "outputs": [],
      "source": [
        "# returns the total loss calculated from criterion\n",
        "def train_loop(model, criterion, optim, iterator):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(iterator):\n",
        "        ### YOUR CODE STARTS HERE (~6 lines of code) ###\n",
        "    \n",
        "        # move data from cpu to gpu\n",
        "        gold_labels = y.unsqueeze(1).to(device)\n",
        "        headlines = x.to(device)\n",
        "        # clear gradients\n",
        "        optim.zero_grad()\n",
        "        # predict headlines\n",
        "        predicted_outputs = model(headlines)\n",
        "        # compute loss\n",
        "        loss = criterion(predicted_outputs, gold_labels)\n",
        "        total_loss += loss\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # weight updates\n",
        "        optim.step()\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "    return total_loss\n",
        "\n",
        "# returns:\n",
        "# - true: a Python boolean array of all the ground truth values \n",
        "#         taken from the dataset iterator\n",
        "# - pred: a Python boolean array of all model predictions. \n",
        "def val_loop(model, iterator):\n",
        "    true, pred = [], []\n",
        "    ### YOUR CODE STARTS HERE (~8 lines of code) ###\n",
        "    for x, y in iterator:\n",
        "        predicted_outputs = model(x.to(device))\n",
        "        gold_labels = y.to(device)\n",
        "        \n",
        "        for predicted_output, gold_label in zip(predicted_outputs, gold_labels):\n",
        "            if predicted_output >= 0.5: \n",
        "                pred.append(True)\n",
        "            else:\n",
        "                pred.append(False)\n",
        "            if gold_label: \n",
        "                true.append(True)\n",
        "            else: \n",
        "                true.append(False)\n",
        "\n",
        "    ### YOUR CODE ENDS HERE ###\n",
        "    return true, pred"
      ],
      "id": "vganx5fCFEIh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 3.1 Define the evaluation metrics"
      ],
      "metadata": {
        "id": "JNXJevTu-tDZ"
      },
      "id": "JNXJevTu-tDZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IsZQs3rFEIi"
      },
      "source": [
        "We also need evaluation metrics that tell us how well our model is doing on the validation set at each epoch and later how well the model does on the held-out test set. **Complete the functions in the following cell.** You'll find subsection 4.4.1 of Eisenstein useful for this task."
      ],
      "id": "7IsZQs3rFEIi"
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT IMPORT ANYTHING IN THIS CELL. You shouldn't need any external libraries.\n",
        "\n",
        "# accuracy\n",
        "#\n",
        "# What percent of classifications are correct?\n",
        "# \n",
        "# true: ground truth, Python list of booleans.\n",
        "# pred: model predictions, Python list of booleans.\n",
        "# return: percent accuracy bounded between [0, 1]\n",
        "#\n",
        "def accuracy(true, pred):\n",
        "    acc = None\n",
        "    ## YOUR CODE STARTS HERE (~2-5 lines of code) ##\n",
        "    number_of_correct_predictions = sum(1 for prediction, label in zip(pred, true)\n",
        "                                    if prediction == label)\n",
        "    number_of_total_predictions = len(pred)\n",
        "\n",
        "    acc = (number_of_correct_predictions)/(number_of_total_predictions)\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return acc\n",
        "\n",
        "# binary_f1 \n",
        "#\n",
        "# A method to calculate F-1 scores for a binary classification task.\n",
        "# \n",
        "# args -\n",
        "# true: ground truth, Python list of booleans.\n",
        "# pred: model predictions, Python list of booleans.\n",
        "# selected_class: Boolean - the selected class the F-1 \n",
        "#                 is being calculated for.\n",
        "# \n",
        "# return: F-1 score between [0, 1]\n",
        "#\n",
        "def binary_f1(true, pred, selected_class=True):\n",
        "    f1 = None\n",
        "    ## YOUR CODE STARTS HERE (~10-15 lines of code) ##\n",
        "    # recall = (# True Positive)/(# True Positive + # of False Negative)\n",
        "    # precision = (# True Positive)/(# True Positive + # of False Positive)\n",
        "    # f1_measure = (2*recall*precision)/(recall + precision)\n",
        "    number_of_true_pos = 0\n",
        "    number_of_false_neg = 0\n",
        "    number_of_false_pos = 0\n",
        "\n",
        "    for predicted, label in zip(pred, true):\n",
        "        if selected_class == label == predicted:\n",
        "            # true positive case\n",
        "            number_of_true_pos += 1\n",
        "\n",
        "        if (selected_class == label) and (label != predicted):\n",
        "            # false negative case\n",
        "            number_of_false_neg += 1\n",
        "\n",
        "        if (selected_class == predicted) and (label != predicted):\n",
        "            # false positive case\n",
        "            number_of_false_pos += 1\n",
        "    #print(f'##########{number_of_true_pos}###########')\n",
        "\n",
        "    # recall\n",
        "    recall = number_of_true_pos/(number_of_true_pos + number_of_false_neg)\n",
        "    # precision\n",
        "    precision = number_of_true_pos/(number_of_true_pos + number_of_false_pos)\n",
        "    # f1 measure\n",
        "    f1 = (2*recall*precision)/(recall + precision)\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return f1\n",
        "\n",
        "# binary_macro_f1\n",
        "# \n",
        "# Averaged F-1 for all selected (true/false) classes.\n",
        "#\n",
        "# args -\n",
        "# true: ground truth, Python list of booleans.\n",
        "# pred: model predictions, Python list of booleans.\n",
        "#\n",
        "#\n",
        "def binary_macro_f1(true, pred):\n",
        "    averaged_macro_f1 = None\n",
        "    ## YOUR CODE STARTS HERE (1 line of code) ##\n",
        "    averaged_macro_f1 = (binary_f1(true, pred, True) + binary_f1(true, pred, False))/2\n",
        "\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return averaged_macro_f1"
      ],
      "metadata": {
        "id": "gMQDg9Vy-wY0"
      },
      "id": "gMQDg9Vy-wY0",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Yw79JFieFEIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b4807e-70e3-4c21-cb39-2038a597eca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Macro F1: 0.3003225288732167\n",
            "Accuracy: 0.37958333333333333\n"
          ]
        }
      ],
      "source": [
        "# To test your eval implementation, let's see how well the untrained model does on our dev dataset.\n",
        "# It should do pretty poorly, but this can be random because of the initialization of the parameters of the model.\n",
        "true, pred = val_loop(model, val_iterator)\n",
        "print()\n",
        "print(f'Binary Macro F1: {binary_macro_f1(true, pred)}')\n",
        "print(f'Accuracy: {accuracy(true, pred)}')"
      ],
      "id": "Yw79JFieFEIi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, we have our datasets defined and split, our model and training tools/loops, and evaluation metrics so we can finally move on to train our model and see how it does!"
      ],
      "metadata": {
        "id": "BerBx-T3kZtC"
      },
      "id": "BerBx-T3kZtC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2to0kWVFEIi"
      },
      "source": [
        "### Part 4: Actually training the model [1 point]\n",
        "Watch your model train :D You should be able to achieve a validation F-1 score of at least .8 if everything went correctly. **Feel free to adjust the number of epochs to prevent overfitting or underfitting and to play with your model hyperparameters/optimizer & loss function.**"
      ],
      "id": "Q2to0kWVFEIi"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "N-iuqkKCFEIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3ec24c-03b7-4487-b578-015e8a51376b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 127.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n",
            "TRAIN LOSS: 9851.23828125\n",
            "VAL F-1: 0.8417898582054177\n",
            "VAL ACC: 0.8470833333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 127.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n",
            "TRAIN LOSS: 9745.8603515625\n",
            "VAL F-1: 0.8409777212588689\n",
            "VAL ACC: 0.84625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 128.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 2\n",
            "TRAIN LOSS: 9772.53515625\n",
            "VAL F-1: 0.839304226072674\n",
            "VAL ACC: 0.8445833333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 128.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 3\n",
            "TRAIN LOSS: 9861.9794921875\n",
            "VAL F-1: 0.8401658656111581\n",
            "VAL ACC: 0.8454166666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 128.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 4\n",
            "TRAIN LOSS: 9834.3984375\n",
            "VAL F-1: 0.8388482099511949\n",
            "VAL ACC: 0.8441666666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 130.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 5\n",
            "TRAIN LOSS: 9801.4853515625\n",
            "VAL F-1: 0.8405217095210695\n",
            "VAL ACC: 0.8458333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 128.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 6\n",
            "TRAIN LOSS: 9811.625\n",
            "VAL F-1: 0.8392033163777134\n",
            "VAL ACC: 0.8445833333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 127.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 7\n",
            "TRAIN LOSS: 9841.8662109375\n",
            "VAL F-1: 0.841483052398897\n",
            "VAL ACC: 0.8466666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 127.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 8\n",
            "TRAIN LOSS: 9829.8232421875\n",
            "VAL F-1: 0.8374789551592439\n",
            "VAL ACC: 0.8429166666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:09<00:00, 128.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 9\n",
            "TRAIN LOSS: 9827.75390625\n",
            "VAL F-1: 0.8388985369488791\n",
            "VAL ACC: 0.8441666666666666\n"
          ]
        }
      ],
      "source": [
        "TOTAL_EPOCHS = 10\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_loss = train_loop(model, criterion, optimizer, train_iterator)\n",
        "    true, pred = val_loop(model, val_iterator)\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    print(f\"TRAIN LOSS: {train_loss}\")\n",
        "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
        "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
      ],
      "id": "N-iuqkKCFEIj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l91F4ooFEIj"
      },
      "source": [
        "We can also look at the models performance on the held-out test set, using the same val_loop we wrote earlier."
      ],
      "id": "_l91F4ooFEIj"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vs8Fy_ncFEIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c250c5e-5b17-4fb0-9fdb-66894eed3c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST F-1: 0.8259199962769858\n",
            "TEST ACC: 0.83375\n"
          ]
        }
      ],
      "source": [
        "true, pred = val_loop(model, test_iterator)\n",
        "print()\n",
        "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
        "print(f\"TEST ACC: {accuracy(true, pred)}\")"
      ],
      "id": "vs8Fy_ncFEIo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMPWmorEFEIp"
      },
      "source": [
        "### Part 5: Analysis [5 points]\n",
        "Answer the following questions:\n",
        "\n"
      ],
      "id": "rMPWmorEFEIp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. What happens to the vocab size as you change the cutoff in the cell below? Can you explain this in the context of [Zipf's Law](https://en.wikipedia.org/wiki/Zipf%27s_law)?\n",
        "\n",
        "Answer: "
      ],
      "metadata": {
        "id": "fnjKlKt352hQ"
      },
      "id": "fnjKlKt352hQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI0fM4oMFEIp"
      },
      "outputs": [],
      "source": [
        "tmp_vocab, _ = generate_vocab_map(train_df, cutoff = 1)\n",
        "len(tmp_vocab)"
      ],
      "id": "pI0fM4oMFEIp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0x54B1lFEIp"
      },
      "source": [
        "#### 2. Can you describe what cases the model is getting wrong in the witheld test-set? \n",
        "\n",
        "Answer:"
      ],
      "id": "d0x54B1lFEIp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do this, you'll need to create a new val_train_loop (``val_train_loop_incorrect``) so it returns incorrect sequences **and** you'll need to decode these sequences back into words. \n",
        "Thankfully, you've already created a map that can convert encoded sequences back to regular English: you will find the ``reverse_vocab`` variable useful.\n",
        "\n",
        "```\n",
        "# i.e. using a reversed map of {\"hi\": 2, \"hello\": 3, \"UNK\": 0}\n",
        "# we can turn [2, 3, 0] into this => [\"hi\", \"hello\", \"UNK\"]\n",
        "```"
      ],
      "metadata": {
        "id": "_yiIZov-583w"
      },
      "id": "_yiIZov-583w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfohtPF8FEIp"
      },
      "outputs": [],
      "source": [
        "# Implement this however you like! It should look very similar to val_loop.\n",
        "# Pass the test_iterator through this function to look at errors in the test set.\n",
        "def val_train_loop_incorrect(model, iterator):\n",
        "  \n",
        "   "
      ],
      "id": "TfohtPF8FEIp"
    },
    {
      "cell_type": "code",
      "source": [
        "val_train_loop_incorrect(model, test_iterator)"
      ],
      "metadata": {
        "id": "6-azPje88iU0"
      },
      "id": "6-azPje88iU0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 6: LSTM Model [Extra-Credit, 5 points]"
      ],
      "metadata": {
        "id": "Ie9VqRbg78Ty"
      },
      "id": "Ie9VqRbg78Ty"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 6.1 Define the RecurrentModel class\n",
        "Something that has been overlooked so far in this project is the sequential structure to language: a word typically only has a clear meaning because of its relationship to the words before and after it in the sequence, and the feed-forward network of Part 2 cannot model this type of data. A solution to this, is the use of [recurrent neural networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). These types of networks not only produce some output given some step from a sequence, but also update their internal state, hopefully \"remembering\" some information about the previous steps in the input sequence. Of course, they do have their own faults, but we'll cover this more thoroughly later in the semester. \n",
        "\n",
        "Your task for the extra credit portion of this assignment, is to implement such a model below using a LSTM. Instead of averaging the embeddings as with the FFN in Part 2, you'll instead feed all of these embeddings to a LSTM layer, get its final output, and use this to make your prediction for the class of the headline. "
      ],
      "metadata": {
        "id": "gXWSfPfBA4XU"
      },
      "id": "gXWSfPfBA4XU"
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentModel(nn.Module):\n",
        "    # Instantiate layers for your model-\n",
        "    # \n",
        "    # Your model architecture will be an optionally bidirectional LSTM,\n",
        "    # followed by a linear + sigmoid layer.\n",
        "    #\n",
        "    # You'll need 4 nn.Modules\n",
        "    # 1. An embeddings layer (see nn.Embedding)\n",
        "    # 2. A bidirectional LSTM (see nn.LSTM)\n",
        "    # 3. A Linear layer (see nn.Linear)\n",
        "    # 4. A sigmoid output (see nn.Sigmoid)\n",
        "    #\n",
        "    # HINT: In the forward step, the BATCH_SIZE is the first dimension.\n",
        "    # HINT: Think about what happens to the linear layer's hidden_dim size\n",
        "    #       if bidirectional is True or False.\n",
        "    # \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \\\n",
        "                 num_layers=1, bidirectional=True):\n",
        "        super().__init__()\n",
        "        ## YOUR CODE STARTS HERE (~4 lines of code) ##\n",
        "\n",
        "        \n",
        "\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "        \n",
        "    # Complete the forward pass of the model.\n",
        "    #\n",
        "    # Use the last timestep of the output of the LSTM as input\n",
        "    # to the linear layer. This will only require some indexing \n",
        "    # into the correct return from the LSTM layer. \n",
        "    # \n",
        "    # args:\n",
        "    # x - 2D LongTensor of shape (BATCH_SIZE, max len of all tokenized_word_tensor))\n",
        "    #     This is the same output that comes out of the collate_fn function you completed-\n",
        "    def forward(self, x):\n",
        "        ## YOUR CODE STARTS HERE (~4-5 lines of code) ##\n",
        "\n",
        "        \n",
        "\n",
        "        #return x\n",
        "        ## YOUR CODE ENDS HERE ##\n",
        "    "
      ],
      "metadata": {
        "id": "YN8zvhLJ-MVJ"
      },
      "id": "YN8zvhLJ-MVJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the RecurrentModel is defined, we'll reinitialize our dataset iterators so they're back at the start. "
      ],
      "metadata": {
        "id": "HprkOm-fAVyj"
      },
      "id": "HprkOm-fAVyj"
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
        "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
        "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "6-uftfXEAqOi"
      },
      "id": "6-uftfXEAqOi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 6.2 Initialize the LSTM classification model\n",
        "\n",
        "Next we need to initialize our new model, as well as define it's optimizer and loss function as we did for the FFN. Feel free to use the same optimizer you did above, or see how this model reacts to different optimizers/learning rates than the FFN.  "
      ],
      "metadata": {
        "id": "2qROtRw3AtZy"
      },
      "id": "2qROtRw3AtZy"
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = RecurrentModel(vocab_size    = len(train_vocab.keys()),\n",
        "                            embedding_dim = 300,\n",
        "                            hidden_dim    = 300,\n",
        "                            num_layers    = 1,\n",
        "                            bidirectional = True).to(device)"
      ],
      "metadata": {
        "id": "LNWcLJpsBRzg"
      },
      "id": "LNWcLJpsBRzg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_criterion, lstm_optimizer = None, None\n",
        "### YOUR CODE STARTS HERE ###\n",
        "\n",
        "\n",
        "\n",
        "### YOUR CODE ENDS HERE ###"
      ],
      "metadata": {
        "id": "OdTxe0bFBqnP"
      },
      "id": "OdTxe0bFBqnP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part 6.3 Training and Evaluation\n",
        "\n",
        "Because the only difference between this model and the FFN is the internal structure, we can use the same methods as above to evaluate and train it. You should be able to achieve a validation F-1 score of at least .8 if everything went correctly. **Feel free to adjust the number of epochs to prevent overfitting or underfitting and to play with your model hyperparameters/optimizer & loss function.**"
      ],
      "metadata": {
        "id": "NFvV7H7OBzWl"
      },
      "id": "NFvV7H7OBzWl"
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-training to see what accuracy we can get with random parameters\n",
        "true, pred = val_loop(lstm_model, val_iterator)\n",
        "print()\n",
        "print(f'Binary Macro F1: {binary_macro_f1(true, pred)}')\n",
        "print(f'Accuracy: {accuracy(true, pred)}')"
      ],
      "metadata": {
        "id": "SdkEpedxDopv"
      },
      "id": "SdkEpedxDopv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Watch the model train!\n",
        "TOTAL_EPOCHS = 10\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_loss = train_loop(lstm_model, lstm_criterion, lstm_optimizer, train_iterator)\n",
        "    true, pred = val_loop(lstm_model, val_iterator)\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    print(f\"TRAIN LOSS: {train_loss}\")\n",
        "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
        "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
      ],
      "metadata": {
        "id": "6p2dF9X4DyIR"
      },
      "id": "6p2dF9X4DyIR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#See how your model does on the held out data\n",
        "true, pred = val_loop(lstm_model, test_iterator)\n",
        "print()\n",
        "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
        "print(f\"TEST ACC: {accuracy(true, pred)}\")"
      ],
      "metadata": {
        "id": "OR8Dl5DLEQwd"
      },
      "id": "OR8Dl5DLEQwd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 7: Submit Your Homework\n",
        "This is the end. Congratulations!  \n",
        "\n",
        "Now, follow the steps below to submit your homework in [Gradescope](https://www.gradescope.com/courses/345683):\n",
        "\n",
        "1. Rename this ipynb file to 'CS4650_p1_GTusername.ipynb'. We recommend ensuring you have removed any extraneous cells & print statements, clearing all outputs, and using the Runtime --> Run all tool to make sure all output is update to date. Additionally, leaving comments in your code to help us understand your operations will assist the teaching staff in grading. It is not a requirement, but is recommended. \n",
        "2. Click on the menu 'File' --> 'Download' --> 'Download .py'.\n",
        "3. Click on the menu 'File' --> 'Download' --> 'Download .ipynb'.\n",
        "4. Download the notebook as a .pdf document. Make sure the output from Parts 4 & 6.3 are captured so we can see how the loss, F1, & accuracy changes while training.\n",
        "5. Upload all 3 files to GradeScope.\n"
      ],
      "metadata": {
        "id": "mY8S9ZK9zuVs"
      },
      "id": "mY8S9ZK9zuVs"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "CS4650_p1_ykim713.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}